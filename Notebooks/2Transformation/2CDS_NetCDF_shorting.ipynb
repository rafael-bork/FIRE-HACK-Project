{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05b51045",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from shapely.geometry import box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "39a93e71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset> Size: 497MB\n",
      "Dimensions:      (valid_time: 2486, latitude: 61, longitude: 41)\n",
      "Coordinates:\n",
      "  * valid_time   (valid_time) datetime64[ns] 20kB 2015-08-03T14:00:00 ... 202...\n",
      "  * latitude     (latitude) float64 488B 43.0 42.9 42.8 42.7 ... 37.2 37.1 37.0\n",
      "  * longitude    (longitude) float64 328B -10.0 -9.9 -9.8 ... -6.2 -6.1 -6.0\n",
      "Data variables: (12/21)\n",
      "    u100         (valid_time, latitude, longitude) float32 25MB ...\n",
      "    v100         (valid_time, latitude, longitude) float32 25MB ...\n",
      "    cbh          (valid_time, latitude, longitude) float32 25MB ...\n",
      "    hcc          (valid_time, latitude, longitude) float32 25MB ...\n",
      "    lcc          (valid_time, latitude, longitude) float32 25MB ...\n",
      "    mcc          (valid_time, latitude, longitude) float32 25MB ...\n",
      "    ...           ...\n",
      "    t2m          (valid_time, latitude, longitude) float32 25MB ...\n",
      "    u10          (valid_time, latitude, longitude) float32 25MB ...\n",
      "    v10          (valid_time, latitude, longitude) float32 25MB ...\n",
      "    sp           (valid_time, latitude, longitude) float32 25MB ...\n",
      "    z            (valid_time, latitude, longitude) float32 25MB ...\n",
      "    spatial_ref  int32 4B ...\n",
      "Attributes:\n",
      "    GRIB_centre:             ecmf\n",
      "    GRIB_centreDescription:  European Centre for Medium-Range Weather Forecasts\n",
      "    GRIB_subCentre:          0\n",
      "    Conventions:             CF-1.7\n",
      "    institution:             European Centre for Medium-Range Weather Forecasts\n",
      "    history:                 2025-11-03T17:39 GRIB to CDM+CF via cfgrib-0.9.1...\n"
     ]
    }
   ],
   "source": [
    "ds = xr.open_dataset(\"..\\..\\Data\\Interim\\Meteorological_data\\ERA5_NetCDF\\ERA5_meteo_SL_c.nc\")\n",
    "print(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "abe89ee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset> Size: 746MB\n",
      "Dimensions:         (valid_time: 2486, pressure_level: 5, latitude: 61,\n",
      "                     longitude: 41)\n",
      "Coordinates:\n",
      "  * valid_time      (valid_time) datetime64[ns] 20kB 2015-08-03T14:00:00 ... ...\n",
      "  * pressure_level  (pressure_level) float64 40B 950.0 850.0 700.0 500.0 300.0\n",
      "  * latitude        (latitude) float64 488B 43.0 42.9 42.8 ... 37.2 37.1 37.0\n",
      "  * longitude       (longitude) float64 328B -10.0 -9.9 -9.8 ... -6.2 -6.1 -6.0\n",
      "Data variables:\n",
      "    z               (valid_time, pressure_level, latitude, longitude) float32 124MB ...\n",
      "    r               (valid_time, pressure_level, latitude, longitude) float32 124MB ...\n",
      "    t               (valid_time, pressure_level, latitude, longitude) float32 124MB ...\n",
      "    u               (valid_time, pressure_level, latitude, longitude) float32 124MB ...\n",
      "    v               (valid_time, pressure_level, latitude, longitude) float32 124MB ...\n",
      "    w               (valid_time, pressure_level, latitude, longitude) float32 124MB ...\n",
      "    spatial_ref     int32 4B ...\n",
      "Attributes:\n",
      "    GRIB_centre:             ecmf\n",
      "    GRIB_centreDescription:  European Centre for Medium-Range Weather Forecasts\n",
      "    GRIB_subCentre:          0\n",
      "    Conventions:             CF-1.7\n",
      "    institution:             European Centre for Medium-Range Weather Forecasts\n",
      "    history:                 2025-10-14T11:20 GRIB to CDM+CF via cfgrib-0.9.1...\n"
     ]
    }
   ],
   "source": [
    "ds_PL = xr.open_dataset(r\"../../Data/Interim/Meteorological_data/ERA5_NetCDF/ERA5_meteo_PL_c.nc\", engine=\"netcdf4\")\n",
    "print(ds_PL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f559875",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dias3\\AppData\\Local\\Temp\\ipykernel_7636\\2028578943.py:8: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  shp[\"edate\"] = pd.to_datetime(shp[\"edate\"], errors=\"coerce\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de combina√ß√µes geradas: 15890\n",
      "N√∫mero de pol√≠gonos processados: 1715\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 1. Ler shapefile e NetCDF\n",
    "# ============================================================\n",
    "shp = gpd.read_file(r\"../../Data/Interim/PT-FireSprd_v2.1/L2_FireBehavior/PT-FireProg_v2.1_L2_valid.shp\")\n",
    "# shp = gpd.read_file(r\"..\\..\\PT-FireProg_v2.1_L2_p_meteo_short.shp\")\n",
    "\n",
    "shp[\"sdate\"] = pd.to_datetime(shp[\"sdate\"], errors=\"coerce\")\n",
    "shp[\"edate\"] = pd.to_datetime(shp[\"edate\"], errors=\"coerce\")\n",
    "shp = shp.dropna(subset=[\"sdate\", \"edate\"])\n",
    "\n",
    "# ============================================================\n",
    "# 2. PREPARAR C√âLULAS DA GRADE\n",
    "# ============================================================\n",
    "shp_4326 = shp.to_crs(\"EPSG:4326\")\n",
    "lats = ds.latitude.values\n",
    "lons = ds.longitude.values\n",
    "lat_res = 0.1\n",
    "lon_res = 0.1\n",
    "\n",
    "cell_polys = []\n",
    "for lat in lats:\n",
    "    for lon in lons:\n",
    "        cell_poly = box(lon - lon_res/2, lat - lat_res/2, \n",
    "                        lon + lon_res/2, lat + lat_res/2)\n",
    "        cell_polys.append(cell_poly)\n",
    "\n",
    "cells_gdf = gpd.GeoDataFrame({\n",
    "    \"latitude\": np.repeat(lats, len(lons)),\n",
    "    \"longitude\": np.tile(lons, len(lats)),\n",
    "    \"geometry\": cell_polys\n",
    "}, crs=\"EPSG:4326\")\n",
    "\n",
    "# ============================================================\n",
    "# 3. GERAR COMBINA√á√ïES PARA TODOS OS POL√çGONOS + EXTENT\n",
    "# ============================================================\n",
    "all_times = pd.to_datetime(ds.valid_time.values)\n",
    "all_combinations = []\n",
    "\n",
    "for polygon_id, polygon_row in shp_4326.iterrows():\n",
    "    \n",
    "    # >>> calcular extent do pol√≠gono\n",
    "    minx, miny, maxx, maxy = polygon_row.geometry.bounds\n",
    "    \n",
    "    # Encontrar c√©lulas que intersectam\n",
    "    intersecting_cells = cells_gdf[cells_gdf.intersects(polygon_row.geometry)]\n",
    "    \n",
    "    # Se n√£o houver interse√ß√£o direta, usar buffer\n",
    "    if len(intersecting_cells) == 0:\n",
    "        buffered_poly = polygon_row.geometry.buffer(0.05)\n",
    "        intersecting_cells = cells_gdf[cells_gdf.intersects(buffered_poly)]\n",
    "    \n",
    "    # Extrair intervalo de tempo\n",
    "    sdate = polygon_row[\"sdate\"]\n",
    "    edate = polygon_row[\"edate\"]\n",
    "    \n",
    "    # Filtrar tempos dentro do intervalo com minutos = 0\n",
    "    polygon_times = [\n",
    "        time for time in all_times\n",
    "        if sdate <= time <= edate and time.minute == 0\n",
    "    ]\n",
    "    \n",
    "    # Gerar combina√ß√µes\n",
    "    for _, cell in intersecting_cells.iterrows():\n",
    "        lat = cell.latitude\n",
    "        lon = cell.longitude\n",
    "        \n",
    "        for time in polygon_times:\n",
    "            all_combinations.append({\n",
    "                'latitude': lat,\n",
    "                'longitude': lon,\n",
    "                'time': time,\n",
    "                'polygon_id': polygon_id,\n",
    "                'minx': minx,\n",
    "                'miny': miny,\n",
    "                'maxx': maxx,\n",
    "                'maxy': maxy\n",
    "            })\n",
    "\n",
    "# ============================================================\n",
    "# 4. OUTPUT FINAL\n",
    "# ============================================================\n",
    "print(f\"Total de combina√ß√µes geradas: {len(all_combinations)}\")\n",
    "print(f\"N√∫mero de pol√≠gonos processados: {len(shp_4326)}\")\n",
    "\n",
    "'''print(\"\\nPrimeiras 5 combina√ß√µes:\")\n",
    "for i, combo in enumerate(all_combinations):\n",
    "    print(\n",
    "        f\"{i+1}: Polygon {combo['polygon_id']} - \"\n",
    "        f\"lat={combo['latitude']:.3f}, lon={combo['longitude']:.3f}, \"\n",
    "        f\"time={combo['time'].strftime('%Y-%m-%d %H:%M')}, \"\n",
    "        f\"extent=({combo['minx']:.3f}, {combo['miny']:.3f}, {combo['maxx']:.3f}, {combo['maxy']:.3f})\"\n",
    "    )'''\n",
    "\n",
    "'''# Salvar em CSV\n",
    "df_combinations = pd.DataFrame(all_combinations)\n",
    "df_combinations.to_csv(r\"PT-FireProg_v2.1_L2_combinations_with_extent.csv\", index=False)'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b0387ac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processando 1715 pol√≠gonos...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combina√ß√µes a manter: 11091\n",
      "Combina√ß√µes a descartar: 6206395\n",
      "Aplicando NaN a 20 vari√°veis...\n",
      "Processando u100...\n",
      "Processando v100...\n",
      "Processando cbh...\n",
      "Processando hcc...\n",
      "Processando lcc...\n",
      "Processando mcc...\n",
      "Processando tcc...\n",
      "Processando blh...\n",
      "Processando cape...\n",
      "Processando cin...\n",
      "Processando swvl1...\n",
      "Processando swvl2...\n",
      "Processando swvl3...\n",
      "Processando swvl4...\n",
      "Processando d2m...\n",
      "Processando t2m...\n",
      "Processando u10...\n",
      "Processando v10...\n",
      "Processando sp...\n",
      "Processando z...\n",
      "\n",
      "‚úÖ PROCESSO CONCLU√çDO!\n",
      "Dataset original: 474.4 MB\n",
      "Dataset filtrado: 474.4 MB\n",
      "u100: 11091/6217486 valores n√£o-NaN (0.18%)\n",
      "v100: 11091/6217486 valores n√£o-NaN (0.18%)\n",
      "cbh: 3490/6217486 valores n√£o-NaN (0.06%)\n",
      "\n",
      "üìä DATASET FILTRADO:\n",
      "<xarray.Dataset> Size: 497MB\n",
      "Dimensions:     (valid_time: 2486, latitude: 61, longitude: 41)\n",
      "Coordinates:\n",
      "  * valid_time  (valid_time) datetime64[ns] 20kB 2015-08-03T14:00:00 ... 2025...\n",
      "  * latitude    (latitude) float64 488B 43.0 42.9 42.8 42.7 ... 37.2 37.1 37.0\n",
      "  * longitude   (longitude) float64 328B -10.0 -9.9 -9.8 -9.7 ... -6.2 -6.1 -6.0\n",
      "Data variables: (12/20)\n",
      "    u100        (valid_time, latitude, longitude) float32 25MB nan nan ... nan\n",
      "    v100        (valid_time, latitude, longitude) float32 25MB nan nan ... nan\n",
      "    cbh         (valid_time, latitude, longitude) float32 25MB nan nan ... nan\n",
      "    hcc         (valid_time, latitude, longitude) float32 25MB nan nan ... nan\n",
      "    lcc         (valid_time, latitude, longitude) float32 25MB nan nan ... nan\n",
      "    mcc         (valid_time, latitude, longitude) float32 25MB nan nan ... nan\n",
      "    ...          ...\n",
      "    d2m         (valid_time, latitude, longitude) float32 25MB nan nan ... nan\n",
      "    t2m         (valid_time, latitude, longitude) float32 25MB nan nan ... nan\n",
      "    u10         (valid_time, latitude, longitude) float32 25MB nan nan ... nan\n",
      "    v10         (valid_time, latitude, longitude) float32 25MB nan nan ... nan\n",
      "    sp          (valid_time, latitude, longitude) float32 25MB nan nan ... nan\n",
      "    z           (valid_time, latitude, longitude) float32 25MB nan nan ... nan\n",
      "Attributes:\n",
      "    GRIB_centre:             ecmf\n",
      "    GRIB_centreDescription:  European Centre for Medium-Range Weather Forecasts\n",
      "    GRIB_subCentre:          0\n",
      "    Conventions:             CF-1.7\n",
      "    institution:             European Centre for Medium-Range Weather Forecasts\n",
      "    history:                 2025-11-03T17:39 GRIB to CDM+CF via cfgrib-0.9.1...\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# ============================================================\n",
    "# CRIAR M√ÅSCARA PARA AS COMBINA√á√ïES QUE VAMOS MANTER\n",
    "# ============================================================\n",
    "\n",
    "# Criar um array booleano inicializado com False\n",
    "keep_mask = xr.full_like(ds.u100, False, dtype=bool)  # usa u100 como template\n",
    "\n",
    "# Converter os tempos do dataset para pandas Timestamp\n",
    "ds_times = pd.to_datetime(ds.valid_time.values)\n",
    "\n",
    "print(f\"Processando {len(shp_4326)} pol√≠gonos...\")\n",
    "\n",
    "# Para cada pol√≠gono no shapefile\n",
    "for polygon_id, polygon_row in shp_4326.iterrows():\n",
    "    # Intervalo de tempo do pol√≠gono\n",
    "    sdate = polygon_row[\"sdate\"]\n",
    "    edate = polygon_row[\"edate\"]\n",
    "    \n",
    "    # Filtrar apenas os tempos que est√£o dentro do intervalo do pol√≠gono e minutos=0\n",
    "    polygon_times = [time for time in ds_times if sdate <= time <= edate and time.minute == 0]\n",
    "\n",
    "    # Encontrar c√©lulas da grade NetCDF que intersectam o pol√≠gono\n",
    "    intersecting_cells = cells_gdf[cells_gdf.intersects(polygon_row.geometry)]\n",
    "    \n",
    "    # Se n√£o houver interse√ß√£o direta, usar buffer opcional\n",
    "    if len(intersecting_cells) == 0:\n",
    "        buffered_poly = polygon_row.geometry.buffer(0.05)\n",
    "        intersecting_cells = cells_gdf[cells_gdf.intersects(buffered_poly)]\n",
    "    \n",
    "    # Marcar as c√©lulas intersectantes na m√°scara\n",
    "    for _, cell in intersecting_cells.iterrows():\n",
    "        # Encontrar √≠ndices exatos da c√©lula no NetCDF\n",
    "        lat_idx = np.where(ds.latitude.values == cell['latitude'])[0][0]\n",
    "        lon_idx = np.where(ds.longitude.values == cell['longitude'])[0][0]\n",
    "\n",
    "        for time in polygon_times:\n",
    "            time_idx = np.where(ds_times == time)[0]\n",
    "            if len(time_idx) > 0:\n",
    "                keep_mask[time_idx[0], lat_idx, lon_idx] = True\n",
    "            else:\n",
    "                # Se n√£o encontrar o tempo exato, usar o mais pr√≥ximo\n",
    "                time_diff = np.abs(ds_times - time)\n",
    "                closest_time_idx = time_diff.argmin()\n",
    "                keep_mask[closest_time_idx, lat_idx, lon_idx] = True\n",
    "                print(f\"‚ö†Ô∏è Tempo n√£o encontrado exatamente: {time}. Usando mais pr√≥ximo: {ds_times[closest_time_idx]}\")\n",
    "\n",
    "print(f\"Combina√ß√µes a manter: {keep_mask.sum().values}\")\n",
    "print(f\"Combina√ß√µes a descartar: {(~keep_mask).sum().values}\")\n",
    "\n",
    "# ============================================================\n",
    "# APLICAR NAN √ÄS COMBINA√á√ïES QUE N√ÉO VAMOS USAR\n",
    "# ============================================================\n",
    "\n",
    "# Criar uma c√≥pia do dataset original\n",
    "ds_filtered = ds.copy()\n",
    "\n",
    "# Lista de vari√°veis meteorol√≥gicas (excluindo coordenadas e spatial_ref)\n",
    "data_vars = [var for var in ds.data_vars if var not in ['spatial_ref']]\n",
    "\n",
    "print(f\"Aplicando NaN a {len(data_vars)} vari√°veis...\")\n",
    "\n",
    "# Aplicar NaN apenas √†s combina√ß√µes que N√ÉO vamos usar\n",
    "for var_name in data_vars:\n",
    "    print(f\"Processando {var_name}...\")\n",
    "    ds_filtered[var_name] = ds[var_name].where(keep_mask)\n",
    "\n",
    "ds_filtered = ds_filtered.drop_vars('spatial_ref')\n",
    "\n",
    "# ============================================================\n",
    "# VERIFICAR RESULTADO\n",
    "# ============================================================\n",
    "\n",
    "print(f\"\\n‚úÖ PROCESSO CONCLU√çDO!\")\n",
    "print(f\"Dataset original: {ds.nbytes / 1024 / 1024:.1f} MB\")\n",
    "print(f\"Dataset filtrado: {ds_filtered.nbytes / 1024 / 1024:.1f} MB\")\n",
    "\n",
    "# Verificar quantos valores n√£o-NaN restaram\n",
    "for var_name in data_vars[:3]:  # Mostrar apenas as primeiras 3 vari√°veis\n",
    "    non_nan_count = (~np.isnan(ds_filtered[var_name].values)).sum()\n",
    "    total_count = ds_filtered[var_name].size\n",
    "    print(f\"{var_name}: {non_nan_count}/{total_count} valores n√£o-NaN ({non_nan_count/total_count*100:.2f}%)\")\n",
    "\n",
    "# Mostrar o dataset resultante\n",
    "print(f\"\\nüìä DATASET FILTRADO:\")\n",
    "print(ds_filtered)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "43b38889",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üíæ Dataset salvo em: ../../Data/Interim/Meteorological_data/ERA5_NetCDF/ERA5_meteo_SL_c_short.nc\n",
      "\n",
      "üéØ DATASET FINAL (DIMENS√ïES INTACTAS):\n",
      "<xarray.Dataset> Size: 497MB\n",
      "Dimensions:     (valid_time: 2486, latitude: 61, longitude: 41)\n",
      "Coordinates:\n",
      "  * valid_time  (valid_time) datetime64[ns] 20kB 2015-08-03T14:00:00 ... 2025...\n",
      "  * latitude    (latitude) float64 488B 43.0 42.9 42.8 42.7 ... 37.2 37.1 37.0\n",
      "  * longitude   (longitude) float64 328B -10.0 -9.9 -9.8 -9.7 ... -6.2 -6.1 -6.0\n",
      "Data variables: (12/20)\n",
      "    u100        (valid_time, latitude, longitude) float32 25MB nan nan ... nan\n",
      "    v100        (valid_time, latitude, longitude) float32 25MB nan nan ... nan\n",
      "    cbh         (valid_time, latitude, longitude) float32 25MB nan nan ... nan\n",
      "    hcc         (valid_time, latitude, longitude) float32 25MB nan nan ... nan\n",
      "    lcc         (valid_time, latitude, longitude) float32 25MB nan nan ... nan\n",
      "    mcc         (valid_time, latitude, longitude) float32 25MB nan nan ... nan\n",
      "    ...          ...\n",
      "    d2m         (valid_time, latitude, longitude) float32 25MB nan nan ... nan\n",
      "    t2m         (valid_time, latitude, longitude) float32 25MB nan nan ... nan\n",
      "    u10         (valid_time, latitude, longitude) float32 25MB nan nan ... nan\n",
      "    v10         (valid_time, latitude, longitude) float32 25MB nan nan ... nan\n",
      "    sp          (valid_time, latitude, longitude) float32 25MB nan nan ... nan\n",
      "    z           (valid_time, latitude, longitude) float32 25MB nan nan ... nan\n",
      "Attributes:\n",
      "    GRIB_centre:             ecmf\n",
      "    GRIB_centreDescription:  European Centre for Medium-Range Weather Forecasts\n",
      "    GRIB_subCentre:          0\n",
      "    Conventions:             CF-1.7\n",
      "    institution:             European Centre for Medium-Range Weather Forecasts\n",
      "    history:                 2025-11-03T17:39 GRIB to CDM+CF via cfgrib-0.9.1...\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# SALVAR DATASET SEM REMOVER DIMENS√ïES VAZIAS\n",
    "# ============================================================\n",
    "\n",
    "output_path = \"../../Data/Interim/Meteorological_data/ERA5_NetCDF/ERA5_meteo_SL_c_short.nc\"\n",
    "\n",
    "# Salvar diretamente sem otimizar/remover dimens√µes\n",
    "ds_filtered.to_netcdf(output_path, engine=\"netcdf4\")\n",
    "\n",
    "print(f\"\\nüíæ Dataset salvo em: {output_path}\")\n",
    "print(f\"\\nüéØ DATASET FINAL (DIMENS√ïES INTACTAS):\")\n",
    "print(ds_filtered)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "328dc993",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç VERIFICANDO DIMENS√ïES DO ds_PL:\n",
      "Dimens√µes: FrozenMappingWarningOnValuesAccess({'valid_time': 2486, 'pressure_level': 5, 'latitude': 61, 'longitude': 41})\n",
      "Tamanho valid_time: 2486\n",
      "Tamanho pressure_level: 5\n",
      "Tamanho latitude: 61\n",
      "Tamanho longitude: 41\n",
      "Valores de pressure_level: [950. 850. 700. 500. 300.]\n",
      "\n",
      "üîÑ Processando 1715 pol√≠gonos para ds_PL...\n",
      "‚úÖ Combina√ß√µes v√°lidas no ds_PL: 79450\n",
      "üìç C√©lulas marcadas na m√°scara: 55455\n",
      "\n",
      "‚úÖ PROCESSO CONCLU√çDO PARA ds_PL!\n",
      "Dataset PL original: 711.6 MB\n",
      "Dataset PL filtrado: 711.6 MB\n",
      "\n",
      "üìä DATASET PL FILTRADO:\n",
      "<xarray.Dataset> Size: 746MB\n",
      "Dimensions:         (valid_time: 2486, pressure_level: 5, latitude: 61,\n",
      "                     longitude: 41)\n",
      "Coordinates:\n",
      "  * valid_time      (valid_time) datetime64[ns] 20kB 2015-08-03T14:00:00 ... ...\n",
      "  * pressure_level  (pressure_level) float64 40B 950.0 850.0 700.0 500.0 300.0\n",
      "  * latitude        (latitude) float64 488B 43.0 42.9 42.8 ... 37.2 37.1 37.0\n",
      "  * longitude       (longitude) float64 328B -10.0 -9.9 -9.8 ... -6.2 -6.1 -6.0\n",
      "Data variables:\n",
      "    z               (valid_time, pressure_level, latitude, longitude) float32 124MB ...\n",
      "    r               (valid_time, pressure_level, latitude, longitude) float32 124MB ...\n",
      "    t               (valid_time, pressure_level, latitude, longitude) float32 124MB ...\n",
      "    u               (valid_time, pressure_level, latitude, longitude) float32 124MB ...\n",
      "    v               (valid_time, pressure_level, latitude, longitude) float32 124MB ...\n",
      "    w               (valid_time, pressure_level, latitude, longitude) float32 124MB ...\n",
      "Attributes:\n",
      "    GRIB_centre:             ecmf\n",
      "    GRIB_centreDescription:  European Centre for Medium-Range Weather Forecasts\n",
      "    GRIB_subCentre:          0\n",
      "    Conventions:             CF-1.7\n",
      "    institution:             European Centre for Medium-Range Weather Forecasts\n",
      "    history:                 2025-10-14T11:20 GRIB to CDM+CF via cfgrib-0.9.1...\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ============================================================\n",
    "# 1Ô∏è‚É£ Criar m√°scara para ds_PL\n",
    "# ============================================================\n",
    "\n",
    "print(\"üîç VERIFICANDO DIMENS√ïES DO ds_PL:\")\n",
    "print(f\"Dimens√µes: {ds_PL.dims}\")\n",
    "print(f\"Tamanho valid_time: {len(ds_PL.valid_time)}\")\n",
    "print(f\"Tamanho pressure_level: {len(ds_PL.pressure_level)}\")\n",
    "print(f\"Tamanho latitude: {len(ds_PL.latitude)}\")\n",
    "print(f\"Tamanho longitude: {len(ds_PL.longitude)}\")\n",
    "print(f\"Valores de pressure_level: {ds_PL.pressure_level.values}\")\n",
    "\n",
    "# Criar m√°scara com as 4 dimens√µes\n",
    "keep_mask_PL = xr.full_like(ds_PL.u, False, dtype=bool)\n",
    "\n",
    "# Converter tempos para pandas Timestamp\n",
    "ds_PL_times = pd.to_datetime(ds_PL.valid_time.values)\n",
    "\n",
    "print(f\"\\nüîÑ Processando {len(shp_4326)} pol√≠gonos para ds_PL...\")\n",
    "\n",
    "valid_combinations_PL = 0\n",
    "\n",
    "# Para cada pol√≠gono\n",
    "for polygon_id, polygon_row in shp_4326.iterrows():\n",
    "    sdate = polygon_row[\"sdate\"]\n",
    "    edate = polygon_row[\"edate\"]\n",
    "    \n",
    "    # Filtrar apenas tempos dentro do intervalo do pol√≠gono\n",
    "    polygon_times = [time for time in ds_PL_times if sdate <= time <= edate and time.minute == 0]\n",
    "\n",
    "    # Encontrar c√©lulas que intersectam o pol√≠gono\n",
    "    intersecting_cells = cells_gdf[cells_gdf.intersects(polygon_row.geometry)]\n",
    "    \n",
    "    # Se n√£o houver interse√ß√£o direta, usar buffer opcional\n",
    "    if len(intersecting_cells) == 0:\n",
    "        buffered_poly = polygon_row.geometry.buffer(0.05)\n",
    "        intersecting_cells = cells_gdf[cells_gdf.intersects(buffered_poly)]\n",
    "    \n",
    "    # Para cada c√©lula intersectante\n",
    "    for _, cell in intersecting_cells.iterrows():\n",
    "        lat_idx = np.where(ds_PL.latitude.values == cell['latitude'])[0][0]\n",
    "        lon_idx = np.where(ds_PL.longitude.values == cell['longitude'])[0][0]\n",
    "\n",
    "        for time in polygon_times:\n",
    "            time_idx = np.where(ds_PL_times == time)[0]\n",
    "            if len(time_idx) == 0:\n",
    "                # Usar tempo mais pr√≥ximo se n√£o existir exato\n",
    "                time_diff = np.abs(ds_PL_times - time)\n",
    "                time_idx = [time_diff.argmin()]\n",
    "            time_idx = time_idx[0]\n",
    "\n",
    "            # Marcar todos os n√≠veis de press√£o\n",
    "            for pressure_idx in range(len(ds_PL.pressure_level)):\n",
    "                keep_mask_PL[time_idx, pressure_idx, lat_idx, lon_idx] = True\n",
    "                valid_combinations_PL += 1\n",
    "\n",
    "print(f\"‚úÖ Combina√ß√µes v√°lidas no ds_PL: {valid_combinations_PL}\")\n",
    "print(f\"üìç C√©lulas marcadas na m√°scara: {keep_mask_PL.sum().values}\")\n",
    "\n",
    "# ============================================================\n",
    "# 2Ô∏è‚É£ Aplicar NaN √†s combina√ß√µes fora do pol√≠gono\n",
    "# ============================================================\n",
    "\n",
    "ds_PL_filtered = ds_PL.copy()\n",
    "data_vars_PL = [var for var in ds_PL.data_vars if var not in ['spatial_ref']]\n",
    "\n",
    "for var_name in data_vars_PL:\n",
    "    ds_PL_filtered[var_name] = ds_PL[var_name].where(keep_mask_PL)\n",
    "\n",
    "ds_PL_filtered = ds_PL_filtered.drop_vars('spatial_ref')\n",
    "\n",
    "# ============================================================\n",
    "# 3Ô∏è‚É£ Verificar resultado\n",
    "# ============================================================\n",
    "\n",
    "print(f\"\\n‚úÖ PROCESSO CONCLU√çDO PARA ds_PL!\")\n",
    "print(f\"Dataset PL original: {ds_PL.nbytes / 1024 / 1024:.1f} MB\")\n",
    "print(f\"Dataset PL filtrado: {ds_PL_filtered.nbytes / 1024 / 1024:.1f} MB\")\n",
    "\n",
    "'''for var_name in data_vars_PL[:4]:\n",
    "    non_nan_count = (~np.isnan(ds_PL_filtered[var_name].values)).sum()\n",
    "    total_count = ds_PL_filtered[var_name].size\n",
    "    percentage = (non_nan_count / total_count) * 100\n",
    "    print(f\"   {var_name}: {non_nan_count:,}/{total_count:,} valores n√£o-NaN ({percentage:.4f}%)\")'''\n",
    "\n",
    "print(f\"\\nüìä DATASET PL FILTRADO:\")\n",
    "print(ds_PL_filtered)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bcf791ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üíæ Dataset PL salvo em: ../../Data/Interim/Meteorological_data/ERA5_NetCDF/ERA5_meteo_PL_c_short.nc\n",
      "\n",
      "üéØ DATASET PL FINAL (DIMENS√ïES INTACTAS):\n",
      "<xarray.Dataset> Size: 746MB\n",
      "Dimensions:         (valid_time: 2486, pressure_level: 5, latitude: 61,\n",
      "                     longitude: 41)\n",
      "Coordinates:\n",
      "  * valid_time      (valid_time) datetime64[ns] 20kB 2015-08-03T14:00:00 ... ...\n",
      "  * pressure_level  (pressure_level) float64 40B 950.0 850.0 700.0 500.0 300.0\n",
      "  * latitude        (latitude) float64 488B 43.0 42.9 42.8 ... 37.2 37.1 37.0\n",
      "  * longitude       (longitude) float64 328B -10.0 -9.9 -9.8 ... -6.2 -6.1 -6.0\n",
      "Data variables:\n",
      "    z               (valid_time, pressure_level, latitude, longitude) float32 124MB ...\n",
      "    r               (valid_time, pressure_level, latitude, longitude) float32 124MB ...\n",
      "    t               (valid_time, pressure_level, latitude, longitude) float32 124MB ...\n",
      "    u               (valid_time, pressure_level, latitude, longitude) float32 124MB ...\n",
      "    v               (valid_time, pressure_level, latitude, longitude) float32 124MB ...\n",
      "    w               (valid_time, pressure_level, latitude, longitude) float32 124MB ...\n",
      "Attributes:\n",
      "    GRIB_centre:             ecmf\n",
      "    GRIB_centreDescription:  European Centre for Medium-Range Weather Forecasts\n",
      "    GRIB_subCentre:          0\n",
      "    Conventions:             CF-1.7\n",
      "    institution:             European Centre for Medium-Range Weather Forecasts\n",
      "    history:                 2025-10-14T11:20 GRIB to CDM+CF via cfgrib-0.9.1...\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# SALVAR ds_PL SEM REMOVER DIMENS√ïES VAZIAS\n",
    "# ============================================================\n",
    "\n",
    "output_path_PL = \"../../Data/Interim/Meteorological_data/ERA5_NetCDF/ERA5_meteo_PL_c_short.nc\"\n",
    "\n",
    "# Salvar diretamente sem otimizar/remover dimens√µes\n",
    "ds_PL_filtered.to_netcdf(output_path_PL, engine=\"netcdf4\")\n",
    "\n",
    "print(f\"\\nüíæ Dataset PL salvo em: {output_path_PL}\")\n",
    "print(f\"\\nüéØ DATASET PL FINAL (DIMENS√ïES INTACTAS):\")\n",
    "print(ds_PL_filtered)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geoenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
