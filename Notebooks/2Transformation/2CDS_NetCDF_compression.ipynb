{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05b51045",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from shapely.geometry import box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39a93e71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset> Size: 1GB\n",
      "Dimensions:      (valid_time: 2486, latitude: 61, longitude: 41)\n",
      "Coordinates:\n",
      "  * valid_time   (valid_time) datetime64[ns] 20kB 2015-08-03T14:00:00 ... 202...\n",
      "  * latitude     (latitude) float32 244B 43.0 42.9 42.8 42.7 ... 37.2 37.1 37.0\n",
      "  * longitude    (longitude) float32 164B -10.0 -9.9 -9.8 ... -6.2 -6.1 -6.0\n",
      "Data variables: (12/29)\n",
      "    d2m          (valid_time, latitude, longitude) float64 50MB ...\n",
      "    t2m          (valid_time, latitude, longitude) float64 50MB ...\n",
      "    u10          (valid_time, latitude, longitude) float64 50MB ...\n",
      "    v10          (valid_time, latitude, longitude) float64 50MB ...\n",
      "    sp           (valid_time, latitude, longitude) float64 50MB ...\n",
      "    z            (valid_time, latitude, longitude) float32 25MB ...\n",
      "    ...           ...\n",
      "    v10_Fb       (valid_time, latitude, longitude) float64 50MB ...\n",
      "    sp_Fb        (valid_time, latitude, longitude) float64 50MB ...\n",
      "    drtcode      (valid_time, latitude, longitude) float64 50MB ...\n",
      "    ffmcode      (valid_time, latitude, longitude) float64 50MB ...\n",
      "    fwinx        (valid_time, latitude, longitude) float64 50MB ...\n",
      "    spatial_ref  int64 8B ...\n",
      "Attributes:\n",
      "    GRIB_centre:             ecmf\n",
      "    GRIB_centreDescription:  European Centre for Medium-Range Weather Forecasts\n",
      "    GRIB_subCentre:          0\n",
      "    Conventions:             CF-1.7\n",
      "    institution:             European Centre for Medium-Range Weather Forecasts\n",
      "    history:                 2025-10-14T17:07 GRIB to CDM+CF via cfgrib-0.9.1...\n"
     ]
    }
   ],
   "source": [
    "ds = xr.open_dataset(\"..\\..\\Data\\Interim\\Meteorological_data\\ERA5_NetCDF\\ERA5_meteo_SL_c.nc\")\n",
    "print(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abe89ee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset> Size: 1GB\n",
      "Dimensions:         (valid_time: 2486, pressure_level: 5, latitude: 61,\n",
      "                     longitude: 41)\n",
      "Coordinates:\n",
      "  * valid_time      (valid_time) datetime64[ns] 20kB 2015-08-03T14:00:00 ... ...\n",
      "  * pressure_level  (pressure_level) float64 40B 950.0 850.0 700.0 500.0 300.0\n",
      "  * latitude        (latitude) float64 488B 43.0 42.9 42.8 ... 37.2 37.1 37.0\n",
      "  * longitude       (longitude) float64 328B -10.0 -9.9 -9.8 ... -6.2 -6.1 -6.0\n",
      "Data variables:\n",
      "    z               (valid_time, pressure_level, latitude, longitude) float64 249MB ...\n",
      "    r               (valid_time, pressure_level, latitude, longitude) float64 249MB ...\n",
      "    t               (valid_time, pressure_level, latitude, longitude) float64 249MB ...\n",
      "    u               (valid_time, pressure_level, latitude, longitude) float64 249MB ...\n",
      "    v               (valid_time, pressure_level, latitude, longitude) float64 249MB ...\n",
      "    w               (valid_time, pressure_level, latitude, longitude) float64 249MB ...\n",
      "    spatial_ref     int64 8B ...\n",
      "Attributes:\n",
      "    GRIB_centre:             ecmf\n",
      "    GRIB_centreDescription:  European Centre for Medium-Range Weather Forecasts\n",
      "    GRIB_subCentre:          0\n",
      "    Conventions:             CF-1.7\n",
      "    institution:             European Centre for Medium-Range Weather Forecasts\n",
      "    history:                 2025-10-14T11:20 GRIB to CDM+CF via cfgrib-0.9.1...\n"
     ]
    }
   ],
   "source": [
    "ds_PL = xr.open_dataset(r\"../../Data/Interim/Meteorological_data/ERA5_NetCDF/ERA5_meteo_PL_c.nc\", engine=\"netcdf4\")\n",
    "print(ds_PL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84b33021",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Convertendo ds_PL para os mesmos data types do ds...\n",
      "üìä TIPOS ATUAIS:\n",
      "ds:\n",
      "  latitude: float32\n",
      "  longitude: float32\n",
      "  valid_time: datetime64[ns]\n",
      "  Vari√°veis de dados:\n",
      "    d2m: float64\n",
      "    t2m: float64\n",
      "    u10: float64\n",
      "\n",
      "ds_PL (antes da convers√£o):\n",
      "  latitude: float64\n",
      "  longitude: float64\n",
      "  valid_time: datetime64[ns]\n",
      "  pressure_level: float64\n",
      "  Vari√°veis de dados:\n",
      "    z: float64\n",
      "    r: float64\n",
      "    t: float64\n",
      "  pressure_level mantido como: float64\n",
      "\n",
      "üîÑ Convertendo vari√°veis de dados...\n",
      "  Convertendo z: float64 -> float32\n",
      "  Convertendo r: float64 -> <class 'numpy.float32'>\n",
      "  Convertendo t: float64 -> <class 'numpy.float32'>\n",
      "  Convertendo u: float64 -> <class 'numpy.float32'>\n",
      "  Convertendo v: float64 -> <class 'numpy.float32'>\n",
      "  Convertendo w: float64 -> <class 'numpy.float32'>\n",
      "\n",
      "‚úÖ CONVERS√ÉO CONCLU√çDA!\n",
      "üìä TIPOS AP√ìS CONVERS√ÉO:\n",
      "ds_PL (ap√≥s convers√£o):\n",
      "  latitude: float32\n",
      "  longitude: float32\n",
      "  valid_time: datetime64[ns]\n",
      "  Vari√°veis de dados:\n",
      "    z: float32\n",
      "    r: float32\n",
      "    t: float32\n",
      "\n",
      "üîç VERIFICA√á√ÉO DE COORDENADAS:\n",
      "ds latitude == ds_PL latitude: True\n",
      "ds longitude == ds_PL longitude: True\n",
      "\n",
      "üìê COMPARA√á√ÉO DE VALORES:\n",
      "ds latitude[:3]: [43.  42.9 42.8]\n",
      "ds_PL latitude[:3]: [43.  42.9 42.8]\n",
      "Diferen√ßa m√°xima: 0.0\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# CONVERTER ds_PL PARA OS MESMOS DATA TYPES DO ds\n",
    "# ============================================================\n",
    "\n",
    "print(\"üîÑ Convertendo ds_PL para os mesmos data types do ds...\")\n",
    "\n",
    "# Verificar os tipos atuais de ambos os datasets\n",
    "print(\"üìä TIPOS ATUAIS:\")\n",
    "print(\"ds:\")\n",
    "print(f\"  latitude: {ds.latitude.dtype}\")\n",
    "print(f\"  longitude: {ds.longitude.dtype}\") \n",
    "print(f\"  valid_time: {ds.valid_time.dtype}\")\n",
    "print(\"  Vari√°veis de dados:\")\n",
    "for var in list(ds.data_vars)[:3]:  # Primeiras 3 vari√°veis\n",
    "    print(f\"    {var}: {ds[var].dtype}\")\n",
    "\n",
    "print(\"\\nds_PL (antes da convers√£o):\")\n",
    "print(f\"  latitude: {ds_PL.latitude.dtype}\")\n",
    "print(f\"  longitude: {ds_PL.longitude.dtype}\")\n",
    "print(f\"  valid_time: {ds_PL.valid_time.dtype}\")\n",
    "print(f\"  pressure_level: {ds_PL.pressure_level.dtype}\")\n",
    "print(\"  Vari√°veis de dados:\")\n",
    "for var in list(ds_PL.data_vars)[:3]:\n",
    "    print(f\"    {var}: {ds_PL[var].dtype}\")\n",
    "\n",
    "# ============================================================\n",
    "# CONVERS√ÉO DAS COORDENADAS\n",
    "# ============================================================\n",
    "\n",
    "# Converter coordenadas para os mesmos tipos do ds\n",
    "ds_PL = ds_PL.assign_coords({\n",
    "    'latitude': ds_PL.latitude.astype(ds.latitude.dtype),\n",
    "    'longitude': ds_PL.longitude.astype(ds.longitude.dtype),\n",
    "    'valid_time': ds_PL.valid_time.astype(ds.valid_time.dtype)\n",
    "})\n",
    "\n",
    "# pressure_level mant√©m o seu tipo pr√≥prio\n",
    "print(f\"  pressure_level mantido como: {ds_PL.pressure_level.dtype}\")\n",
    "\n",
    "# ============================================================\n",
    "# CONVERS√ÉO DAS VARI√ÅVEIS DE DADOS\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\nüîÑ Convertendo vari√°veis de dados...\")\n",
    "\n",
    "# Criar um mapping dos tipos de dados do ds para refer√™ncia\n",
    "ds_dtypes = {var: ds[var].dtype for var in ds.data_vars}\n",
    "\n",
    "# Para cada vari√°vel no ds_PL, tentar usar o tipo correspondente do ds\n",
    "# Se n√£o existir no ds, usar float32 como fallback\n",
    "for var in ds_PL.data_vars:\n",
    "    if var in ds_dtypes:\n",
    "        # Se a vari√°vel existe no ds, usar o mesmo tipo\n",
    "        target_dtype = ds_dtypes[var]\n",
    "    else:\n",
    "        # Se n√£o existe no ds, usar float32 (tipo comum no ds)\n",
    "        target_dtype = np.float32\n",
    "    \n",
    "    # Apenas converter se necess√°rio\n",
    "    if ds_PL[var].dtype != target_dtype:\n",
    "        print(f\"  Convertendo {var}: {ds_PL[var].dtype} -> {target_dtype}\")\n",
    "        ds_PL[var] = ds_PL[var].astype(target_dtype)\n",
    "\n",
    "# ============================================================\n",
    "# VERIFICA√á√ÉO FINAL\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n‚úÖ CONVERS√ÉO CONCLU√çDA!\")\n",
    "print(\"üìä TIPOS AP√ìS CONVERS√ÉO:\")\n",
    "print(\"ds_PL (ap√≥s convers√£o):\")\n",
    "print(f\"  latitude: {ds_PL.latitude.dtype}\")\n",
    "print(f\"  longitude: {ds_PL.longitude.dtype}\")\n",
    "print(f\"  valid_time: {ds_PL.valid_time.dtype}\")\n",
    "print(\"  Vari√°veis de dados:\")\n",
    "for var in list(ds_PL.data_vars)[:3]:\n",
    "    print(f\"    {var}: {ds_PL[var].dtype}\")\n",
    "\n",
    "# Verificar se as coordenadas agora s√£o iguais\n",
    "print(f\"\\nüîç VERIFICA√á√ÉO DE COORDENADAS:\")\n",
    "print(f\"ds latitude == ds_PL latitude: {np.array_equal(ds.latitude.values, ds_PL.latitude.values)}\")\n",
    "print(f\"ds longitude == ds_PL longitude: {np.array_equal(ds.longitude.values, ds_PL.longitude.values)}\")\n",
    "\n",
    "# Verificar valores espec√≠ficos\n",
    "print(f\"\\nüìê COMPARA√á√ÉO DE VALORES:\")\n",
    "print(f\"ds latitude[:3]: {ds.latitude.values[:3]}\")\n",
    "print(f\"ds_PL latitude[:3]: {ds_PL.latitude.values[:3]}\")\n",
    "print(f\"Diferen√ßa m√°xima: {np.max(np.abs(ds.latitude.values - ds_PL.latitude.values))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f559875",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rafael Oliveira\\AppData\\Local\\Temp\\1\\ipykernel_21256\\1951211481.py:8: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  shp[\"edate\"] = pd.to_datetime(shp[\"edate\"], errors=\"coerce\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de combina√ß√µes geradas: 15890\n",
      "N√∫mero de pol√≠gonos processados: 1715\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'# Salvar em CSV\\ndf_combinations = pd.DataFrame(all_combinations)\\ndf_combinations.to_csv(r\"PT-FireSprd_v2.1_L2_combinations_with_extent.csv\", index=False)'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 1. Ler shapefile e NetCDF\n",
    "# ============================================================\n",
    "shp = gpd.read_file(r\"../../Data/Interim/PT-FireSprd_v2.1/L2_FireBehavior/PT-FireSprd_v2.1_L2_valid.shp\")\n",
    "# shp = gpd.read_file(r\"..\\..\\PT-FireSprd_v2.1_L2_p_meteo_short.shp\")\n",
    "\n",
    "shp[\"sdate\"] = pd.to_datetime(shp[\"sdate\"], errors=\"coerce\")\n",
    "shp[\"edate\"] = pd.to_datetime(shp[\"edate\"], errors=\"coerce\")\n",
    "shp = shp.dropna(subset=[\"sdate\", \"edate\"])\n",
    "\n",
    "# ============================================================\n",
    "# 2. PREPARAR C√âLULAS DA GRADE\n",
    "# ============================================================\n",
    "shp_4326 = shp.to_crs(\"EPSG:4326\")\n",
    "lats = ds.latitude.values\n",
    "lons = ds.longitude.values\n",
    "lat_res = 0.1\n",
    "lon_res = 0.1\n",
    "\n",
    "cell_polys = []\n",
    "for lat in lats:\n",
    "    for lon in lons:\n",
    "        cell_poly = box(lon - lon_res/2, lat - lat_res/2, \n",
    "                        lon + lon_res/2, lat + lat_res/2)\n",
    "        cell_polys.append(cell_poly)\n",
    "\n",
    "cells_gdf = gpd.GeoDataFrame({\n",
    "    \"latitude\": np.repeat(lats, len(lons)),\n",
    "    \"longitude\": np.tile(lons, len(lats)),\n",
    "    \"geometry\": cell_polys\n",
    "}, crs=\"EPSG:4326\")\n",
    "\n",
    "# ============================================================\n",
    "# 3. GERAR COMBINA√á√ïES PARA TODOS OS POL√çGONOS + EXTENT\n",
    "# ============================================================\n",
    "all_times = pd.to_datetime(ds.valid_time.values)\n",
    "all_combinations = []\n",
    "\n",
    "for polygon_id, polygon_row in shp_4326.iterrows():\n",
    "    \n",
    "    # >>> calcular extent do pol√≠gono\n",
    "    minx, miny, maxx, maxy = polygon_row.geometry.bounds\n",
    "    \n",
    "    # Encontrar c√©lulas que intersectam\n",
    "    intersecting_cells = cells_gdf[cells_gdf.intersects(polygon_row.geometry)]\n",
    "    \n",
    "    # Se n√£o houver interse√ß√£o direta, usar buffer\n",
    "    if len(intersecting_cells) == 0:\n",
    "        buffered_poly = polygon_row.geometry.buffer(0.05)\n",
    "        intersecting_cells = cells_gdf[cells_gdf.intersects(buffered_poly)]\n",
    "    \n",
    "    # Extrair intervalo de tempo\n",
    "    sdate = polygon_row[\"sdate\"]\n",
    "    edate = polygon_row[\"edate\"]\n",
    "    \n",
    "    # Filtrar tempos dentro do intervalo com minutos = 0\n",
    "    polygon_times = [\n",
    "        time for time in all_times\n",
    "        if sdate <= time <= edate and time.minute == 0\n",
    "    ]\n",
    "    \n",
    "    # Gerar combina√ß√µes\n",
    "    for _, cell in intersecting_cells.iterrows():\n",
    "        lat = cell.latitude\n",
    "        lon = cell.longitude\n",
    "        \n",
    "        for time in polygon_times:\n",
    "            all_combinations.append({\n",
    "                'latitude': lat,\n",
    "                'longitude': lon,\n",
    "                'time': time,\n",
    "                'polygon_id': polygon_id,\n",
    "                'minx': minx,\n",
    "                'miny': miny,\n",
    "                'maxx': maxx,\n",
    "                'maxy': maxy\n",
    "            })\n",
    "\n",
    "# ============================================================\n",
    "# 4. OUTPUT FINAL\n",
    "# ============================================================\n",
    "print(f\"Total de combina√ß√µes geradas: {len(all_combinations)}\")\n",
    "print(f\"N√∫mero de pol√≠gonos processados: {len(shp_4326)}\")\n",
    "\n",
    "'''print(\"\\nPrimeiras 5 combina√ß√µes:\")\n",
    "for i, combo in enumerate(all_combinations):\n",
    "    print(\n",
    "        f\"{i+1}: Polygon {combo['polygon_id']} - \"\n",
    "        f\"lat={combo['latitude']:.3f}, lon={combo['longitude']:.3f}, \"\n",
    "        f\"time={combo['time'].strftime('%Y-%m-%d %H:%M')}, \"\n",
    "        f\"extent=({combo['minx']:.3f}, {combo['miny']:.3f}, {combo['maxx']:.3f}, {combo['maxy']:.3f})\"\n",
    "    )'''\n",
    "\n",
    "'''# Salvar em CSV\n",
    "df_combinations = pd.DataFrame(all_combinations)\n",
    "df_combinations.to_csv(r\"PT-FireSprd_v2.1_L2_combinations_with_extent.csv\", index=False)'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0387ac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processando 1715 pol√≠gonos...\n",
      "Combina√ß√µes a manter: 11091\n",
      "Combina√ß√µes a descartar: 6206395\n",
      "Aplicando NaN a 28 vari√°veis...\n",
      "Processando d2m...\n",
      "Processando t2m...\n",
      "Processando u10...\n",
      "Processando v10...\n",
      "Processando sp...\n",
      "Processando z...\n",
      "Processando u100...\n",
      "Processando v100...\n",
      "Processando cbh...\n",
      "Processando hcc...\n",
      "Processando lcc...\n",
      "Processando mcc...\n",
      "Processando tcc...\n",
      "Processando blh...\n",
      "Processando cape...\n",
      "Processando cin...\n",
      "Processando swvl1...\n",
      "Processando swvl2...\n",
      "Processando swvl3...\n",
      "Processando swvl4...\n",
      "Processando d2m_Fb...\n",
      "Processando t2m_Fb...\n",
      "Processando u10_Fb...\n",
      "Processando v10_Fb...\n",
      "Processando sp_Fb...\n",
      "Processando drtcode...\n",
      "Processando ffmcode...\n",
      "Processando fwinx...\n",
      "\n",
      "‚úÖ PROCESSO CONCLU√çDO!\n",
      "Dataset original: 1304.5 MB\n",
      "Dataset filtrado: 1304.5 MB\n",
      "d2m: 11091/6217486 valores n√£o-NaN (0.18%)\n",
      "t2m: 11091/6217486 valores n√£o-NaN (0.18%)\n",
      "u10: 11091/6217486 valores n√£o-NaN (0.18%)\n",
      "\n",
      "üìä DATASET FILTRADO:\n",
      "<xarray.Dataset> Size: 1GB\n",
      "Dimensions:     (valid_time: 2486, latitude: 61, longitude: 41)\n",
      "Coordinates:\n",
      "  * valid_time  (valid_time) datetime64[ns] 20kB 2015-08-03T14:00:00 ... 2025...\n",
      "  * latitude    (latitude) float32 244B 43.0 42.9 42.8 42.7 ... 37.2 37.1 37.0\n",
      "  * longitude   (longitude) float32 164B -10.0 -9.9 -9.8 -9.7 ... -6.2 -6.1 -6.0\n",
      "Data variables: (12/28)\n",
      "    d2m         (valid_time, latitude, longitude) float64 50MB nan nan ... nan\n",
      "    t2m         (valid_time, latitude, longitude) float64 50MB nan nan ... nan\n",
      "    u10         (valid_time, latitude, longitude) float64 50MB nan nan ... nan\n",
      "    v10         (valid_time, latitude, longitude) float64 50MB nan nan ... nan\n",
      "    sp          (valid_time, latitude, longitude) float64 50MB nan nan ... nan\n",
      "    z           (valid_time, latitude, longitude) float32 25MB nan nan ... nan\n",
      "    ...          ...\n",
      "    u10_Fb      (valid_time, latitude, longitude) float64 50MB nan nan ... nan\n",
      "    v10_Fb      (valid_time, latitude, longitude) float64 50MB nan nan ... nan\n",
      "    sp_Fb       (valid_time, latitude, longitude) float64 50MB nan nan ... nan\n",
      "    drtcode     (valid_time, latitude, longitude) float64 50MB nan nan ... nan\n",
      "    ffmcode     (valid_time, latitude, longitude) float64 50MB nan nan ... nan\n",
      "    fwinx       (valid_time, latitude, longitude) float64 50MB nan nan ... nan\n",
      "Attributes:\n",
      "    GRIB_centre:             ecmf\n",
      "    GRIB_centreDescription:  European Centre for Medium-Range Weather Forecasts\n",
      "    GRIB_subCentre:          0\n",
      "    Conventions:             CF-1.7\n",
      "    institution:             European Centre for Medium-Range Weather Forecasts\n",
      "    history:                 2025-10-14T17:07 GRIB to CDM+CF via cfgrib-0.9.1...\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# ============================================================\n",
    "# CRIAR M√ÅSCARA PARA AS COMBINA√á√ïES QUE VAMOS MANTER\n",
    "# ============================================================\n",
    "\n",
    "# Criar um array booleano inicializado com False\n",
    "keep_mask = xr.full_like(ds.u100, False, dtype=bool)  # usa u100 como template\n",
    "\n",
    "# Converter os tempos do dataset para pandas Timestamp\n",
    "ds_times = pd.to_datetime(ds.valid_time.values)\n",
    "\n",
    "print(f\"Processando {len(shp_4326)} pol√≠gonos...\")\n",
    "\n",
    "# Para cada pol√≠gono no shapefile\n",
    "for polygon_id, polygon_row in shp_4326.iterrows():\n",
    "    # Intervalo de tempo do pol√≠gono\n",
    "    sdate = polygon_row[\"sdate\"]\n",
    "    edate = polygon_row[\"edate\"]\n",
    "    \n",
    "    # Filtrar apenas os tempos que est√£o dentro do intervalo do pol√≠gono e minutos=0\n",
    "    polygon_times = [time for time in ds_times if sdate <= time <= edate and time.minute == 0]\n",
    "\n",
    "    # Encontrar c√©lulas da grade NetCDF que intersectam o pol√≠gono\n",
    "    intersecting_cells = cells_gdf[cells_gdf.intersects(polygon_row.geometry)]\n",
    "    \n",
    "    # Se n√£o houver interse√ß√£o direta, usar buffer opcional\n",
    "    if len(intersecting_cells) == 0:\n",
    "        buffered_poly = polygon_row.geometry.buffer(0.05)\n",
    "        intersecting_cells = cells_gdf[cells_gdf.intersects(buffered_poly)]\n",
    "    \n",
    "    # Marcar as c√©lulas intersectantes na m√°scara\n",
    "    for _, cell in intersecting_cells.iterrows():\n",
    "        # Encontrar √≠ndices exatos da c√©lula no NetCDF\n",
    "        lat_idx = np.where(ds.latitude.values == cell['latitude'])[0][0]\n",
    "        lon_idx = np.where(ds.longitude.values == cell['longitude'])[0][0]\n",
    "\n",
    "        for time in polygon_times:\n",
    "            time_idx = np.where(ds_times == time)[0]\n",
    "            if len(time_idx) > 0:\n",
    "                keep_mask[time_idx[0], lat_idx, lon_idx] = True\n",
    "            else:\n",
    "                # Se n√£o encontrar o tempo exato, usar o mais pr√≥ximo\n",
    "                time_diff = np.abs(ds_times - time)\n",
    "                closest_time_idx = time_diff.argmin()\n",
    "                keep_mask[closest_time_idx, lat_idx, lon_idx] = True\n",
    "                print(f\"‚ö†Ô∏è Tempo n√£o encontrado exatamente: {time}. Usando mais pr√≥ximo: {ds_times[closest_time_idx]}\")\n",
    "\n",
    "print(f\"Combina√ß√µes a manter: {keep_mask.sum().values}\")\n",
    "print(f\"Combina√ß√µes a descartar: {(~keep_mask).sum().values}\")\n",
    "\n",
    "# ============================================================\n",
    "# APLICAR NAN √ÄS COMBINA√á√ïES QUE N√ÉO VAMOS USAR\n",
    "# ============================================================\n",
    "\n",
    "# Criar uma c√≥pia do dataset original\n",
    "ds_filtered = ds.copy()\n",
    "\n",
    "# Lista de vari√°veis meteorol√≥gicas (excluindo coordenadas e spatial_ref)\n",
    "data_vars = [var for var in ds.data_vars if var not in ['spatial_ref']]\n",
    "\n",
    "print(f\"Aplicando NaN a {len(data_vars)} vari√°veis...\")\n",
    "\n",
    "# Aplicar NaN apenas √†s combina√ß√µes que N√ÉO vamos usar\n",
    "for var_name in data_vars:\n",
    "    print(f\"Processando {var_name}...\")\n",
    "    ds_filtered[var_name] = ds[var_name].where(keep_mask)\n",
    "\n",
    "ds_filtered = ds_filtered.drop_vars('spatial_ref')\n",
    "\n",
    "# ============================================================\n",
    "# VERIFICAR RESULTADO\n",
    "# ============================================================\n",
    "\n",
    "print(f\"\\n‚úÖ PROCESSO CONCLU√çDO!\")\n",
    "print(f\"Dataset original: {ds.nbytes / 1024 / 1024:.1f} MB\")\n",
    "print(f\"Dataset filtrado: {ds_filtered.nbytes / 1024 / 1024:.1f} MB\")\n",
    "\n",
    "# Verificar quantos valores n√£o-NaN restaram\n",
    "for var_name in data_vars[:3]:  # Mostrar apenas as primeiras 3 vari√°veis\n",
    "    non_nan_count = (~np.isnan(ds_filtered[var_name].values)).sum()\n",
    "    total_count = ds_filtered[var_name].size\n",
    "    print(f\"{var_name}: {non_nan_count}/{total_count} valores n√£o-NaN ({non_nan_count/total_count*100:.2f}%)\")\n",
    "\n",
    "# Mostrar o dataset resultante\n",
    "print(f\"\\nüìä DATASET FILTRADO:\")\n",
    "print(ds_filtered)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "43b38889",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üíæ Dataset salvo em: ../../Data/Interim/Meteorological_data/ERA5_NetCDF/ERA5_meteo_SL_c_short.nc\n",
      "\n",
      "üéØ DATASET FINAL (DIMENS√ïES INTACTAS):\n",
      "<xarray.Dataset> Size: 1GB\n",
      "Dimensions:     (valid_time: 2486, latitude: 61, longitude: 41)\n",
      "Coordinates:\n",
      "  * valid_time  (valid_time) datetime64[ns] 20kB 2015-08-03T14:00:00 ... 2025...\n",
      "  * latitude    (latitude) float32 244B 43.0 42.9 42.8 42.7 ... 37.2 37.1 37.0\n",
      "  * longitude   (longitude) float32 164B -10.0 -9.9 -9.8 -9.7 ... -6.2 -6.1 -6.0\n",
      "Data variables: (12/28)\n",
      "    d2m         (valid_time, latitude, longitude) float64 50MB nan nan ... nan\n",
      "    t2m         (valid_time, latitude, longitude) float64 50MB nan nan ... nan\n",
      "    u10         (valid_time, latitude, longitude) float64 50MB nan nan ... nan\n",
      "    v10         (valid_time, latitude, longitude) float64 50MB nan nan ... nan\n",
      "    sp          (valid_time, latitude, longitude) float64 50MB nan nan ... nan\n",
      "    z           (valid_time, latitude, longitude) float32 25MB nan nan ... nan\n",
      "    ...          ...\n",
      "    u10_Fb      (valid_time, latitude, longitude) float64 50MB nan nan ... nan\n",
      "    v10_Fb      (valid_time, latitude, longitude) float64 50MB nan nan ... nan\n",
      "    sp_Fb       (valid_time, latitude, longitude) float64 50MB nan nan ... nan\n",
      "    drtcode     (valid_time, latitude, longitude) float64 50MB nan nan ... nan\n",
      "    ffmcode     (valid_time, latitude, longitude) float64 50MB nan nan ... nan\n",
      "    fwinx       (valid_time, latitude, longitude) float64 50MB nan nan ... nan\n",
      "Attributes:\n",
      "    GRIB_centre:             ecmf\n",
      "    GRIB_centreDescription:  European Centre for Medium-Range Weather Forecasts\n",
      "    GRIB_subCentre:          0\n",
      "    Conventions:             CF-1.7\n",
      "    institution:             European Centre for Medium-Range Weather Forecasts\n",
      "    history:                 2025-10-14T17:07 GRIB to CDM+CF via cfgrib-0.9.1...\n",
      "Pontos com todas as vari√°veis com valor: 88399\n",
      "Pontos com todas as vari√°veis NaN: 6206395\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# SALVAR DATASET SEM REMOVER DIMENS√ïES VAZIAS\n",
    "# ============================================================\n",
    "\n",
    "output_path = \"../../Data/Interim/Meteorological_data/ERA5_NetCDF/ERA5_meteo_SL_c_short.nc\"\n",
    "\n",
    "# Salvar diretamente sem otimizar/remover dimens√µes\n",
    "ds_filtered.to_netcdf(output_path, engine=\"netcdf4\")\n",
    "\n",
    "print(f\"\\nüíæ Dataset salvo em: {output_path}\")\n",
    "print(f\"\\nüéØ DATASET FINAL (DIMENS√ïES INTACTAS):\")\n",
    "print(ds_filtered)\n",
    "\n",
    "# Cria um booleano True se TODAS as vari√°veis forem NaN naquele ponto\n",
    "all_nan = xr.ufuncs.isnan(ds_filtered.to_array()).all(dim=\"variable\")\n",
    "all_value = (~xr.ufuncs.isnan(ds.to_array())).all(dim=\"variable\")\n",
    "\n",
    "num_all_value = all_value.sum().item()\n",
    "print(\"Pontos com todas as vari√°veis com valor:\", num_all_value)\n",
    "\n",
    "# Conta\n",
    "num_all_nan = all_nan.sum().item()\n",
    "\n",
    "print(\"Pontos com todas as vari√°veis NaN:\", num_all_nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "328dc993",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç VERIFICANDO DIMENS√ïES DO ds_PL:\n",
      "Dimens√µes: FrozenMappingWarningOnValuesAccess({'valid_time': 2486, 'pressure_level': 5, 'latitude': 61, 'longitude': 41})\n",
      "Tamanho valid_time: 2486\n",
      "Tamanho pressure_level: 5\n",
      "Tamanho latitude: 61\n",
      "Tamanho longitude: 41\n",
      "üîÑ Processando 1715 pol√≠gonos...\n",
      "‚úÖ Combina√ß√µes a manter: 55455\n",
      "üìç Combina√ß√µes a descartar: 31031975\n",
      "üéØ Aplicando NaN a 6 vari√°veis...\n",
      "   Processando z...\n",
      "   Processando r...\n",
      "   Processando t...\n",
      "   Processando u...\n",
      "   Processando v...\n",
      "   Processando w...\n",
      "\n",
      "‚úÖ PROCESSO CONCLU√çDO!\n",
      "Dataset PL original: 711.6 MB\n",
      "Dataset PL filtrado: 711.6 MB\n",
      "   z: 55455/31087430 valores n√£o-NaN (0.18%)\n",
      "   r: 55455/31087430 valores n√£o-NaN (0.18%)\n",
      "   t: 55455/31087430 valores n√£o-NaN (0.18%)\n",
      "\n",
      "üìä DATASET PL FILTRADO:\n",
      "<xarray.Dataset> Size: 746MB\n",
      "Dimensions:         (valid_time: 2486, pressure_level: 5, latitude: 61,\n",
      "                     longitude: 41)\n",
      "Coordinates:\n",
      "  * valid_time      (valid_time) datetime64[ns] 20kB 2015-08-03T14:00:00 ... ...\n",
      "  * pressure_level  (pressure_level) float64 40B 950.0 850.0 700.0 500.0 300.0\n",
      "  * latitude        (latitude) float32 244B 43.0 42.9 42.8 ... 37.2 37.1 37.0\n",
      "  * longitude       (longitude) float32 164B -10.0 -9.9 -9.8 ... -6.2 -6.1 -6.0\n",
      "Data variables:\n",
      "    z               (valid_time, pressure_level, latitude, longitude) float32 124MB ...\n",
      "    r               (valid_time, pressure_level, latitude, longitude) float32 124MB ...\n",
      "    t               (valid_time, pressure_level, latitude, longitude) float32 124MB ...\n",
      "    u               (valid_time, pressure_level, latitude, longitude) float32 124MB ...\n",
      "    v               (valid_time, pressure_level, latitude, longitude) float32 124MB ...\n",
      "    w               (valid_time, pressure_level, latitude, longitude) float32 124MB ...\n",
      "Attributes:\n",
      "    GRIB_centre:             ecmf\n",
      "    GRIB_centreDescription:  European Centre for Medium-Range Weather Forecasts\n",
      "    GRIB_subCentre:          0\n",
      "    Conventions:             CF-1.7\n",
      "    institution:             European Centre for Medium-Range Weather Forecasts\n",
      "    history:                 2025-10-14T11:20 GRIB to CDM+CF via cfgrib-0.9.1...\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ============================================================\n",
    "# 1Ô∏è‚É£ CRIAR M√ÅSCARA PARA ds_PL USANDO A MESMA METODOLOGIA DO ds\n",
    "# ============================================================\n",
    "\n",
    "print(\"üîç VERIFICANDO DIMENS√ïES DO ds_PL:\")\n",
    "print(f\"Dimens√µes: {ds_PL.dims}\")\n",
    "print(f\"Tamanho valid_time: {len(ds_PL.valid_time)}\")\n",
    "print(f\"Tamanho pressure_level: {len(ds_PL.pressure_level)}\")\n",
    "print(f\"Tamanho latitude: {len(ds_PL.latitude)}\")\n",
    "print(f\"Tamanho longitude: {len(ds_PL.longitude)}\")\n",
    "\n",
    "# Criar um array booleano inicializado com False (MESMO M√âTODO DO ds)\n",
    "keep_mask_PL = xr.full_like(ds_PL.u, False, dtype=bool)\n",
    "\n",
    "# Converter os tempos do dataset para pandas Timestamp (MESMO M√âTODO DO ds)\n",
    "ds_PL_times = pd.to_datetime(ds_PL.valid_time.values)\n",
    "\n",
    "print(f\"üîÑ Processando {len(shp_4326)} pol√≠gonos...\")\n",
    "\n",
    "# Para cada pol√≠gono no shapefile (MESMA L√ìGICA DO ds)\n",
    "for polygon_id, polygon_row in shp_4326.iterrows():\n",
    "    # Intervalo de tempo do pol√≠gono\n",
    "    sdate = polygon_row[\"sdate\"]\n",
    "    edate = polygon_row[\"edate\"]\n",
    "    \n",
    "    # Filtrar apenas os tempos que est√£o dentro do intervalo do pol√≠gono e minutos=0 (MESMO M√âTODO)\n",
    "    polygon_times = [time for time in ds_PL_times if sdate <= time <= edate and time.minute == 0]\n",
    "\n",
    "    # Encontrar c√©lulas da grade NetCDF que intersectam o pol√≠gono (MESMO M√âTODO)\n",
    "    intersecting_cells = cells_gdf[cells_gdf.intersects(polygon_row.geometry)]\n",
    "    \n",
    "    # Se n√£o houver interse√ß√£o direta, usar buffer opcional (MESMO M√âTODO)\n",
    "    if len(intersecting_cells) == 0:\n",
    "        buffered_poly = polygon_row.geometry.buffer(0.05)\n",
    "        intersecting_cells = cells_gdf[cells_gdf.intersects(buffered_poly)]\n",
    "    \n",
    "    # Marcar as c√©lulas intersectantes na m√°scara (MESMA L√ìGICA, ADAPTADA PARA 4 DIMENS√ïES)\n",
    "    for _, cell in intersecting_cells.iterrows():\n",
    "        # Encontrar √≠ndices exatos da c√©lula no NetCDF (MESMO M√âTODO)\n",
    "        lat_idx = np.where(ds_PL.latitude.values == cell['latitude'])[0][0]\n",
    "        lon_idx = np.where(ds_PL.longitude.values == cell['longitude'])[0][0]\n",
    "\n",
    "        for time in polygon_times:\n",
    "            time_idx = np.where(ds_PL_times == time)[0]\n",
    "            if len(time_idx) > 0:\n",
    "                # MARCADOR: Para ds_PL, marcamos TODOS os n√≠veis de press√£o\n",
    "                for pressure_idx in range(len(ds_PL.pressure_level)):\n",
    "                    keep_mask_PL[time_idx[0], pressure_idx, lat_idx, lon_idx] = True\n",
    "            else:\n",
    "                # Se n√£o encontrar o tempo exato, usar o mais pr√≥ximo (MESMO M√âTODO)\n",
    "                time_diff = np.abs(ds_PL_times - time)\n",
    "                closest_time_idx = time_diff.argmin()\n",
    "                # MARCADOR: Para ds_PL, marcamos TODOS os n√≠veis de press√£o\n",
    "                for pressure_idx in range(len(ds_PL.pressure_level)):\n",
    "                    keep_mask_PL[closest_time_idx, pressure_idx, lat_idx, lon_idx] = True\n",
    "                print(f\"‚ö†Ô∏è Tempo n√£o encontrado exatamente: {time}. Usando mais pr√≥ximo: {ds_PL_times[closest_time_idx]}\")\n",
    "\n",
    "print(f\"‚úÖ Combina√ß√µes a manter: {keep_mask_PL.sum().values}\")\n",
    "print(f\"üìç Combina√ß√µes a descartar: {(~keep_mask_PL).sum().values}\")\n",
    "\n",
    "# ============================================================\n",
    "# 2Ô∏è‚É£ APLICAR NAN √ÄS COMBINA√á√ïES QUE N√ÉO VAMOS USAR (MESMO M√âTODO)\n",
    "# ============================================================\n",
    "\n",
    "# Criar uma c√≥pia do dataset original (MESMO M√âTODO)\n",
    "ds_PL_filtered = ds_PL.copy()\n",
    "\n",
    "# Lista de vari√°veis meteorol√≥gicas (excluindo coordenadas e spatial_ref) (MESMO M√âTODO)\n",
    "data_vars_PL = [var for var in ds_PL.data_vars if var not in ['spatial_ref']]\n",
    "\n",
    "print(f\"üéØ Aplicando NaN a {len(data_vars_PL)} vari√°veis...\")\n",
    "\n",
    "# Aplicar NaN apenas √†s combina√ß√µes que N√ÉO vamos usar (MESMO M√âTODO)\n",
    "for var_name in data_vars_PL:\n",
    "    print(f\"   Processando {var_name}...\")\n",
    "    ds_PL_filtered[var_name] = ds_PL[var_name].where(keep_mask_PL)\n",
    "\n",
    "ds_PL_filtered = ds_PL_filtered.drop_vars('spatial_ref')\n",
    "\n",
    "# ============================================================\n",
    "# 3Ô∏è‚É£ VERIFICAR RESULTADO (MESMO M√âTODO)\n",
    "# ============================================================\n",
    "\n",
    "print(f\"\\n‚úÖ PROCESSO CONCLU√çDO!\")\n",
    "print(f\"Dataset PL original: {ds_PL.nbytes / 1024 / 1024:.1f} MB\")\n",
    "print(f\"Dataset PL filtrado: {ds_PL_filtered.nbytes / 1024 / 1024:.1f} MB\")\n",
    "\n",
    "# Verificar quantos valores n√£o-NaN restaram (MESMO M√âTODO)\n",
    "for var_name in data_vars_PL[:3]:  # Mostrar apenas as primeiras 3 vari√°veis\n",
    "    non_nan_count = (~np.isnan(ds_PL_filtered[var_name].values)).sum()\n",
    "    total_count = ds_PL_filtered[var_name].size\n",
    "    print(f\"   {var_name}: {non_nan_count}/{total_count} valores n√£o-NaN ({non_nan_count/total_count*100:.2f}%)\")\n",
    "\n",
    "# Mostrar o dataset resultante (MESMO M√âTODO)\n",
    "print(f\"\\nüìä DATASET PL FILTRADO:\")\n",
    "print(ds_PL_filtered)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bcf791ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üíæ Dataset PL salvo em: ../../Data/Interim/Meteorological_data/ERA5_NetCDF/ERA5_meteo_PL_c_short.nc\n",
      "\n",
      "üéØ DATASET PL FINAL (DIMENS√ïES INTACTAS):\n",
      "<xarray.Dataset> Size: 746MB\n",
      "Dimensions:         (valid_time: 2486, pressure_level: 5, latitude: 61,\n",
      "                     longitude: 41)\n",
      "Coordinates:\n",
      "  * valid_time      (valid_time) datetime64[ns] 20kB 2015-08-03T14:00:00 ... ...\n",
      "  * pressure_level  (pressure_level) float64 40B 950.0 850.0 700.0 500.0 300.0\n",
      "  * latitude        (latitude) float32 244B 43.0 42.9 42.8 ... 37.2 37.1 37.0\n",
      "  * longitude       (longitude) float32 164B -10.0 -9.9 -9.8 ... -6.2 -6.1 -6.0\n",
      "Data variables:\n",
      "    z               (valid_time, pressure_level, latitude, longitude) float32 124MB ...\n",
      "    r               (valid_time, pressure_level, latitude, longitude) float32 124MB ...\n",
      "    t               (valid_time, pressure_level, latitude, longitude) float32 124MB ...\n",
      "    u               (valid_time, pressure_level, latitude, longitude) float32 124MB ...\n",
      "    v               (valid_time, pressure_level, latitude, longitude) float32 124MB ...\n",
      "    w               (valid_time, pressure_level, latitude, longitude) float32 124MB ...\n",
      "Attributes:\n",
      "    GRIB_centre:             ecmf\n",
      "    GRIB_centreDescription:  European Centre for Medium-Range Weather Forecasts\n",
      "    GRIB_subCentre:          0\n",
      "    Conventions:             CF-1.7\n",
      "    institution:             European Centre for Medium-Range Weather Forecasts\n",
      "    history:                 2025-10-14T11:20 GRIB to CDM+CF via cfgrib-0.9.1...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ============================================================\n",
    "# 6Ô∏è‚É£ SALVAR ds_PL FILTRADO\n",
    "# ============================================================\n",
    "\n",
    "output_path_PL = \"../../Data/Interim/Meteorological_data/ERA5_NetCDF/ERA5_meteo_PL_c_short.nc\"\n",
    "\n",
    "ds_PL_filtered.to_netcdf(output_path_PL, engine=\"netcdf4\")\n",
    "\n",
    "print(f\"\\nüíæ Dataset PL salvo em: {output_path_PL}\")\n",
    "print(f\"\\nüéØ DATASET PL FINAL (DIMENS√ïES INTACTAS):\")\n",
    "print(ds_PL_filtered)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "firehack",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
