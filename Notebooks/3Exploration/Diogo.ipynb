{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8488301e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "vars_to_plot = [\n",
    "    \"ros_p_lg1\", \"ros_p_lg2\", \"ros_p_lg3\",\n",
    "    'BLH_m_av', 'BLH_m_mn', 'BLH_m_mx',\n",
    "    'dfmc_av', 'dfmc_mn', 'dfmc_mx',\n",
    "    'wv100_k_av', 'wv100_k_mn', 'wv100_k_mx',\n",
    "    \"wS_v_av_1\", \"wS_v_mn_1\", \"wS_v_mx_1\",\n",
    "    'Recirc', 'CircVar', 'CircStd_dg',\n",
    "    'd_2m_C_av', 'd_2m_C_mn', 'd_2m_C_mx',\n",
    "    \"HDW_av\", 'HDW_mn', 'HDW_mx',\n",
    "    'LCL_hPa_av', 'LCL_hPa_mn', 'LCL_hPa_mx',\n",
    "    \"wv_850_av\", 'wv_850_mn', 'wv_850_mx',\n",
    "    'wv10_kh_av', 'wv10_kh_mn', 'wv10_kh_mx',\n",
    "]\n",
    "\n",
    "# Store results\n",
    "results = []\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"BEST TRANSFORMATION SELECTION (by RÂ²)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Loop through all variables\n",
    "for var in vars_to_plot:\n",
    "    if var not in df.columns or var not in df_transformed.columns:\n",
    "        print(f\"\\n{var}: NOT FOUND in both dataframes, skipping.\")\n",
    "        continue\n",
    "    \n",
    "    if 'ros_p' not in df.columns or 'ros_p' not in df_transformed.columns:\n",
    "        print(f\"\\nros_p column not found in both dataframes, stopping.\")\n",
    "        break\n",
    "    \n",
    "    # Get linear data\n",
    "    x_linear = pd.to_numeric(df[var], errors='coerce')\n",
    "    y_linear = pd.to_numeric(df['ros_p'], errors='coerce')\n",
    "    \n",
    "    # Get log-transformed data\n",
    "    x_log = pd.to_numeric(df_transformed[var], errors='coerce')\n",
    "    y_log = pd.to_numeric(df_transformed['ros_p'], errors='coerce')\n",
    "    \n",
    "    # Define the four combinations\n",
    "    combinations = [\n",
    "        ('Linear-Linear', x_linear, y_linear),\n",
    "        ('Linear-LOG', x_linear, y_log),\n",
    "        ('LOG-Linear', x_log, y_linear),\n",
    "        ('LOG-LOG', x_log, y_log)\n",
    "    ]\n",
    "    \n",
    "    # Calculate RÂ² for each combination\n",
    "    r2_values = {}\n",
    "    r_values = {}\n",
    "    p_values = {}\n",
    "    n_samples = {}\n",
    "    \n",
    "    for name, x, y in combinations:\n",
    "        # Remove NaN values\n",
    "        mask = x.notna() & y.notna()\n",
    "        x_clean = x[mask]\n",
    "        y_clean = y[mask]\n",
    "        \n",
    "        if len(x_clean) < 5:\n",
    "            r2_values[name] = -999  # Sentinel value for insufficient data\n",
    "            r_values[name] = np.nan\n",
    "            p_values[name] = np.nan\n",
    "            n_samples[name] = len(x_clean)\n",
    "            continue\n",
    "        \n",
    "        # Linear fit\n",
    "        coeffs = np.polyfit(x_clean, y_clean, 1)\n",
    "        y_pred = np.polyval(coeffs, x_clean)\n",
    "        r2 = r2_score(y_clean, y_pred)\n",
    "        \n",
    "        # Pearson correlation\n",
    "        r, p_value = stats.pearsonr(x_clean, y_clean)\n",
    "        \n",
    "        r2_values[name] = r2\n",
    "        r_values[name] = r\n",
    "        p_values[name] = p_value\n",
    "        n_samples[name] = len(x_clean)\n",
    "    \n",
    "    # Find the best transformation\n",
    "    valid_r2 = {k: v for k, v in r2_values.items() if v > -999}\n",
    "    \n",
    "    if not valid_r2:\n",
    "        print(f\"\\n{var}: INSUFFICIENT DATA for all transformations\")\n",
    "        continue\n",
    "    \n",
    "    best_transform = max(valid_r2, key=valid_r2.get)\n",
    "    best_r2 = r2_values[best_transform]\n",
    "    best_r = r_values[best_transform]\n",
    "    best_p = p_values[best_transform]\n",
    "    best_n = n_samples[best_transform]\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"\\n{var} vs ros_p:\")\n",
    "    print(f\"  Best transformation: {best_transform}\")\n",
    "    print(f\"  RÂ² = {best_r2:.4f} | r = {best_r:.4f} | p = {best_p:.2e} | n = {best_n}\")\n",
    "    print(f\"  All RÂ² values:\")\n",
    "    for trans_name in ['Linear-Linear', 'Linear-LOG', 'LOG-Linear', 'LOG-LOG']:\n",
    "        r2_val = r2_values[trans_name]\n",
    "        if r2_val > -999:\n",
    "            marker = \" â† BEST\" if trans_name == best_transform else \"\"\n",
    "            print(f\"    {trans_name}: RÂ² = {r2_val:.4f}{marker}\")\n",
    "        else:\n",
    "            print(f\"    {trans_name}: INSUFFICIENT DATA\")\n",
    "    \n",
    "    # Store for summary table\n",
    "    results.append({\n",
    "        'Variable': var,\n",
    "        'Best_Transformation': best_transform,\n",
    "        'RÂ²': best_r2,\n",
    "        'r': best_r,\n",
    "        'p-value': best_p,\n",
    "        'n': best_n\n",
    "    })\n",
    "\n",
    "# Create summary DataFrame\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SUMMARY TABLE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df = results_df.sort_values('RÂ²', ascending=False)\n",
    "\n",
    "print(results_df.to_string(index=False))\n",
    "\n",
    "# Count transformations\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TRANSFORMATION FREQUENCY\")\n",
    "print(\"=\"*80)\n",
    "transform_counts = results_df['Best_Transformation'].value_counts()\n",
    "for trans, count in transform_counts.items():\n",
    "    print(f\"{trans}: {count} variables ({count/len(results_df)*100:.1f}%)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4651012a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Normality tests - Q-Q Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471ff5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assess_normality_visual(df, columns, n_cols=3):\n",
    "    n_features = len(columns)\n",
    "    if n_features == 0:\n",
    "        print(\"No columns to assess.\")\n",
    "        return\n",
    "    \n",
    "    n_rows = (n_features + n_cols - 1) // n_cols\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(5*n_cols, 4*n_rows))\n",
    "    \n",
    "    # Flatten axes for easy iteration\n",
    "    axes = axes.flatten() if n_features > 1 else [axes]\n",
    "    \n",
    "    for idx, col in enumerate(columns):\n",
    "        data = df[col].dropna()\n",
    "        if len(data) < 5:\n",
    "            axes[idx].axis('off')\n",
    "            continue\n",
    "\n",
    "        # Q-Q plot\n",
    "        stats.probplot(data, dist=\"norm\", plot=axes[idx])\n",
    "        axes[idx].set_title(f'{col}\\n(skew: {data.skew():.2f}, kurt: {data.kurtosis():.2f})')\n",
    "        axes[idx].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Turn off unused subplots\n",
    "    for idx in range(len(columns), len(axes)):\n",
    "        axes[idx].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# --- Apply to all transformed DataFrames ---\n",
    "for name, df_transformed in transformed_dataframes.items():\n",
    "    print(f\"\\nAssessing normality for transformed columns in {name}...\")\n",
    "\n",
    "    if name not in transformation_logs:\n",
    "        print(f\"No transformation log for {name}, skipping.\")\n",
    "        continue\n",
    "\n",
    "    # Select columns that were transformed using Yeo-Johnson\n",
    "    transformed_cols = [col for col, status in transformation_logs[name].items()\n",
    "                        if 'Yeo-Johnson' in status]\n",
    "\n",
    "    if not transformed_cols:\n",
    "        print(f\"No Yeo-Johnson transformed columns found in {name}.\")\n",
    "        continue\n",
    "\n",
    "    assess_normality_visual(df_transformed, transformed_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44733002",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Normality - hypothesis testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629db577",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_normality_pipeline(df, df_transformed, dataset_name=\"Dataset\", alpha=0.05):\n",
    "    print(\"=\"*80)\n",
    "    print(f\"NORMALITY TESTING FOR {dataset_name.upper()}\")\n",
    "    print(f\"Original shape: {df.shape}, Transformed shape: {df_transformed.shape}\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    # --- 1. Run normality tests on transformed data ---\n",
    "    results = []\n",
    "    numeric_cols = df_transformed.select_dtypes(include=[np.number]).columns\n",
    "\n",
    "    for col in tqdm(numeric_cols, desc=\"Normality testing\"):\n",
    "        data = df_transformed[col].dropna()\n",
    "        if len(data) < 3:\n",
    "            continue\n",
    "        \n",
    "        shapiro_stat, shapiro_p = stats.shapiro(data)\n",
    "        jb_stat, jb_p = stats.jarque_bera(data)\n",
    "        skewness = stats.skew(data)\n",
    "        kurtosis = stats.kurtosis(data)\n",
    "        dagostino_stat, dagostino_p = stats.normaltest(data)\n",
    "\n",
    "        results.append({\n",
    "            'Column': col,\n",
    "            'N': len(data),\n",
    "            'Mean': data.mean(),\n",
    "            'Std': data.std(),\n",
    "            'Skewness': skewness,\n",
    "            'Kurtosis': kurtosis,\n",
    "            'Shapiro_W': shapiro_stat,\n",
    "            'Shapiro_p': shapiro_p,\n",
    "            'JB_p': jb_p,\n",
    "            'DAgostino_p': dagostino_p,\n",
    "            'Normal_Shapiro': 'Yes' if shapiro_p > alpha else 'No',\n",
    "            'Normal_JB': 'Yes' if jb_p > alpha else 'No',\n",
    "            'Normal_DAgostino': 'Yes' if dagostino_p > alpha else 'No'\n",
    "        })\n",
    "    \n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df.to_csv(f'normality_results_{dataset_name}.csv', index=False)\n",
    "    print(f\"\\nâœ“ Detailed normality results saved: normality_results_{dataset_name}.csv\")\n",
    "\n",
    "    # --- 2. Summary ---\n",
    "    total_cols = len(results_df)\n",
    "    shapiro_normal = (results_df['Shapiro_p'] > alpha).sum()\n",
    "    jb_normal = (results_df['JB_p'] > alpha).sum()\n",
    "    dagostino_normal = (results_df['DAgostino_p'] > alpha).sum()\n",
    "    all_normal = ((results_df['Shapiro_p'] > alpha) & \n",
    "                  (results_df['JB_p'] > alpha) & \n",
    "                  (results_df['DAgostino_p'] > alpha)).sum()\n",
    "    all_non_normal = ((results_df['Shapiro_p'] <= alpha) & \n",
    "                      (results_df['JB_p'] <= alpha) & \n",
    "                      (results_df['DAgostino_p'] <= alpha)).sum()\n",
    "\n",
    "    print(f\"\\nTotal numeric features tested: {total_cols}\")\n",
    "    print(f\"Shapiro-Wilk normal: {shapiro_normal} ({shapiro_normal/total_cols*100:.1f}%)\")\n",
    "    print(f\"Jarque-Bera normal: {jb_normal} ({jb_normal/total_cols*100:.1f}%)\")\n",
    "    print(f\"D'Agostino-Pearson normal: {dagostino_normal} ({dagostino_normal/total_cols*100:.1f}%)\")\n",
    "    print(f\"All tests agree NORMAL: {all_normal} ({all_normal/total_cols*100:.1f}%)\")\n",
    "    print(f\"All tests agree NON-NORMAL: {all_non_normal} ({all_non_normal/total_cols*100:.1f}%)\")\n",
    "    print(f\"Tests disagree: {total_cols - all_normal - all_non_normal}\")\n",
    "\n",
    "    # --- 3. Overview plots ---\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "    axes = axes.flatten()\n",
    "    axes[0].hist(results_df['Shapiro_p'], bins=50, edgecolor='black', alpha=0.7)\n",
    "    axes[0].axvline(alpha, color='red', linestyle='--', label=f'Î±={alpha}')\n",
    "    axes[0].set_title('Shapiro-Wilk P-value Distribution'); axes[0].legend()\n",
    "\n",
    "    axes[1].hist(results_df['JB_p'], bins=50, edgecolor='black', alpha=0.7)\n",
    "    axes[1].axvline(alpha, color='red', linestyle='--', label=f'Î±={alpha}')\n",
    "    axes[1].set_title('Jarque-Bera P-value Distribution'); axes[1].legend()\n",
    "\n",
    "    axes[2].hist(results_df['DAgostino_p'], bins=50, edgecolor='black', alpha=0.7)\n",
    "    axes[2].axvline(alpha, color='red', linestyle='--', label=f'Î±={alpha}')\n",
    "    axes[2].set_title(\"D'Agostino-Pearson P-value Distribution\"); axes[2].legend()\n",
    "\n",
    "    axes[3].hist(results_df['Skewness'], bins=50, edgecolor='black', alpha=0.7)\n",
    "    axes[3].axvline(0, color='red', linestyle='--'); axes[3].set_title('Skewness Distribution')\n",
    "\n",
    "    axes[4].hist(results_df['Kurtosis'], bins=50, edgecolor='black', alpha=0.7)\n",
    "    axes[4].axvline(0, color='red', linestyle='--'); axes[4].set_title('Kurtosis Distribution')\n",
    "\n",
    "    colors = ['green' if p > alpha else 'red' for p in results_df['Shapiro_p']]\n",
    "    axes[5].scatter(results_df['Skewness'], results_df['Kurtosis'], c=colors, alpha=0.5, s=20)\n",
    "    axes[5].axhline(0, color='gray', linestyle='--'); axes[5].axvline(0, color='gray', linestyle='--')\n",
    "    axes[5].set_title('Skewness vs Kurtosis (Green=Normal, Red=Non-normal)')\n",
    "\n",
    "    plt.suptitle(f'Normality Overview - {dataset_name}', fontsize=16)\n",
    "    plt.tight_layout(rect=[0,0,1,0.95])\n",
    "    plt.show()\n",
    "\n",
    "    return results_df\n",
    "\n",
    "# Loop through all transformed datasets\n",
    "for name, df_transformed in transformed_dataframes.items():\n",
    "    run_normality_pipeline(df, df_transformed, dataset_name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5739646",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through all transformed DataFrames\n",
    "for name, df_trans in transformed_dataframes.items():\n",
    "    if 'ros_p' not in df_trans.columns:\n",
    "        print(f\"Skipping {name} â€” 'ros_p' not found.\")\n",
    "        continue\n",
    "\n",
    "    ros_data = pd.to_numeric(df_trans['ros_p'], errors='coerce').dropna()\n",
    "\n",
    "    if len(ros_data) < 3:\n",
    "        print(f\"Skipping {name} â€” not enough valid ros_p data.\")\n",
    "        continue\n",
    "\n",
    "    # Compute mean and std\n",
    "    mu, sigma = ros_data.mean(), ros_data.std()\n",
    "\n",
    "    # Plot histogram with normal overlay\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(ros_data, bins=100, density=True, alpha=0.6, color='steelblue', edgecolor='black')\n",
    "\n",
    "    # Normal PDF\n",
    "    x = np.linspace(ros_data.min(), ros_data.max(), 1000)\n",
    "    pdf = stats.norm.pdf(x, mu, sigma)\n",
    "    plt.plot(x, pdf, 'r', linewidth=2, label=f'N({mu:.2f}, {sigma:.2f}Â²)')\n",
    "\n",
    "    # Labels and title\n",
    "    plt.title(f\"Distribution of ROS (ros_p) â€” {name}\")\n",
    "    plt.xlabel(\"ROS (ros_p)\")\n",
    "    plt.ylabel(\"Density\")\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()\n",
    "\n",
    "    # Dâ€™Agostinoâ€“Pearson test\n",
    "    stat, p_value = stats.normaltest(ros_data)\n",
    "    print(f\"{'-'*60}\\nDataset: {name}\")\n",
    "    print(\"Dâ€™Agostinoâ€“Pearson Normality Test for ros_p\")\n",
    "    print(f\"Statistic: {stat:.4f}\")\n",
    "    print(f\"p-value: {p_value:.4e}\")\n",
    "    if p_value > 0.05:\n",
    "        print(\"Fail to reject Hâ‚€ â€” data appears approximately normal.\")\n",
    "    else:\n",
    "        print(\"Reject Hâ‚€ â€” data likely not normal.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d6eb54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SCATTER PLOT das correlaÃ§Ãµes com ros_p (top 10 legendadas, invertido)\n",
    "\n",
    "# Columns to exclude from correlation\n",
    "exclude_cols = [\n",
    "    'fid', 'fname', 'year', 'id', 'type', 'sdate', 'edate',\n",
    "    'inidoy', 'enddoy', 'source', 'zp_link', 'burn_perio', 'area',\n",
    "    'growth_rat', 'ros_i', 'ros_p', 'spdir_i', 'spdir_p',\n",
    "    'int_i', 'int_p', 'duration_i', 'duration_p', 'qc',\n",
    "    '1_3y_fir_p', '3_8y_fir_p', '8_ny_fir_p', \"ros_p_lag1\", \"ros_p_lag2\"\n",
    "]\n",
    "\n",
    "# Select numeric columns except the excluded ones\n",
    "numeric_subset = df_transformed.select_dtypes(include=[np.number])\n",
    "numeric_subset = numeric_subset.drop(columns=[c for c in exclude_cols if c in numeric_subset.columns], errors='ignore')\n",
    "\n",
    "# Make sure ros_p is included for correlation\n",
    "numeric_subset = pd.concat([numeric_subset, df_transformed[['ros_p']]], axis=1)\n",
    "\n",
    "# 1ï¸Compute correlation of all allowed variables with 'ros_p'\n",
    "corr_with_ros = numeric_subset.corr()['ros_p'].drop('ros_p')\n",
    "\n",
    "# 2ï¸Sort by absolute value of correlation\n",
    "corr_sorted = corr_with_ros.reindex(corr_with_ros.abs().sort_values(ascending=False).index)\n",
    "\n",
    "# 3ï¸Take top 20 for labeling\n",
    "top20_vars = corr_sorted.head(10).index\n",
    "\n",
    "# 4ï¸Scatter plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "for i, var in enumerate(corr_sorted.index):\n",
    "    alpha = 1.0 if var in top20_vars else 0.1\n",
    "    color = 'royalblue' if corr_sorted[var] >= 0 else 'tomato'\n",
    "    plt.scatter(i, corr_sorted[var], color=color, alpha=alpha, s=60)\n",
    "\n",
    "# 5ï¸Label only top 20\n",
    "for i, var in enumerate(corr_sorted.index):\n",
    "    if var in top20_vars:\n",
    "        plt.text(i, corr_sorted[var], var, fontsize=9, ha='right', va='bottom', rotation=45)\n",
    "\n",
    "plt.axhline(0, color='gray', linestyle='--', linewidth=1)\n",
    "plt.gca().invert_xaxis()\n",
    "plt.title(\"Correlation with ros_p\", fontsize=14)\n",
    "plt.ylabel(\"Pearson Correlation Coefficient\")\n",
    "plt.xticks([])\n",
    "plt.grid(True, linestyle='--', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Mostrar top 20 correlaÃ§Ãµes com ros_p em DataFrame\n",
    "\n",
    "top_corr_df = corr_sorted.head(10).reset_index()\n",
    "top_corr_df.columns = ['Variable', 'correlation_with_ros_p']\n",
    "\n",
    "# Ordenar: positivos (desc) primeiro, depois negativos (asc)\n",
    "top_corr_df = pd.concat([\n",
    "    top_corr_df[top_corr_df['correlation_with_ros_p'] > 0].sort_values(by='correlation_with_ros_p', ascending=False),\n",
    "    top_corr_df[top_corr_df['correlation_with_ros_p'] < 0].sort_values(by='correlation_with_ros_p', ascending=True)\n",
    "]).reset_index(drop=True)\n",
    "\n",
    "display(top_corr_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a8a979",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Test correlation with ros_p before and after transformation and lists variables that have less cor after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59322192",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import normaltest # New import for D'Agostino-Pearson\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "import warnings\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "\n",
    "# --- Assumes your DataFrame 'df' is loaded here ---\n",
    "\n",
    "## Data Preparation and Column Identification\n",
    "# Identify columns that are purely numeric for testing and transformation\n",
    "numeric_cols = df.select_dtypes(include=np.number).columns.tolist()\n",
    "cols_to_test_and_transform = [col for col in numeric_cols if col != 'ros_p']\n",
    "cols_to_exclude = [col for col in df.columns if col not in numeric_cols] + ['ros_p']\n",
    "\n",
    "print(f\"Total columns found: {len(df.columns)}\")\n",
    "print(f\"Numeric columns to process: {cols_to_test_and_transform}\")\n",
    "print(f\"Columns excluded: {cols_to_exclude}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "\n",
    "## 1. Initial Normality Tests (Dâ€™Agostinoâ€“Pearson)\n",
    "\n",
    "print(\"--- 1. Normality Tests Before Transformation (D'Agostino-Pearson) ---\")\n",
    "results_before = []\n",
    "for col in cols_to_test_and_transform:\n",
    "    data = df[col].dropna()\n",
    "    # D'Agostino-Pearson test requires at least 8 non-null samples (N>=20 is recommended)\n",
    "    if len(data) >= 8:\n",
    "        stat, p = normaltest(data)\n",
    "        results_before.append({'Variable': col, 'DAP_Stat_Before': stat, 'P_Value_Before': p})\n",
    "    else:\n",
    "        results_before.append({'Variable': col, 'DAP_Stat_Before': np.nan, 'P_Value_Before': np.nan})\n",
    "\n",
    "results_before_df = pd.DataFrame(results_before)\n",
    "print(results_before_df)\n",
    "print(\"-\" * 50)\n",
    "\n",
    "\n",
    "## 2. Yeo-Johnson Transformation\n",
    "\n",
    "df_transformed = df.copy()\n",
    "\n",
    "if cols_to_test_and_transform:\n",
    "    print(f\"Transforming variables: {', '.join(cols_to_test_and_transform)}\")\n",
    "\n",
    "    warnings.filterwarnings(action='ignore', category=DataConversionWarning)\n",
    "    # Initialize PowerTransformer for Yeo-Johnson\n",
    "    pt = PowerTransformer(method='yeo-johnson', standardize=False)\n",
    "\n",
    "    try:\n",
    "        # Fit and transform the specified columns\n",
    "        df_transformed[cols_to_test_and_transform] = pt.fit_transform(df[cols_to_test_and_transform])\n",
    "\n",
    "        print(\"--- Transformed DataFrame Head (subset) ---\")\n",
    "        print(df_transformed[cols_to_test_and_transform[:3] + ['ros_p']].head()) # Show a subset + ros_p\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "    except ValueError as e:\n",
    "        print(f\"Error during transformation: {e}\")\n",
    "        # Continue with post-test on original data if transform fails\n",
    "        df_transformed = df.copy()\n",
    "\n",
    "\n",
    "## 3. Post-Transformation Normality Tests (Dâ€™Agostinoâ€“Pearson)\n",
    "\n",
    "print(\"--- 3. Normality Tests After Transformation (D'Agostino-Pearson) ---\")\n",
    "results_after = []\n",
    "for col in cols_to_test_and_transform:\n",
    "    data = df_transformed[col].dropna()\n",
    "    if len(data) >= 8:\n",
    "        stat, p = normaltest(data)\n",
    "        results_after.append({'Variable': col, 'DAP_Stat_After': stat, 'P_Value_After': p})\n",
    "    else:\n",
    "        results_after.append({'Variable': col, 'DAP_Stat_After': np.nan, 'P_Value_After': np.nan})\n",
    "\n",
    "results_after_df = pd.DataFrame(results_after)\n",
    "print(results_after_df)\n",
    "print(\"-\" * 50)\n",
    "\n",
    "\n",
    "## 4. Compare Results and List Variables\n",
    "\n",
    "print(\"--- 4. Comparison of Normality (Before vs. After) ---\")\n",
    "\n",
    "# Merge the results\n",
    "all_results = pd.merge(results_before_df, results_after_df, on='Variable')\n",
    "\n",
    "# Calculate the change in p-value\n",
    "all_results['P_Value_Change'] = all_results['P_Value_After'] - all_results['P_Value_Before']\n",
    "\n",
    "print(\"Full comparison of transformed variables:\")\n",
    "print(all_results[['Variable', 'P_Value_Before', 'P_Value_After', 'P_Value_Change']].to_string())\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Find variables where normality DECREASED\n",
    "# This means the p-value became smaller (moving *away* from normality)\n",
    "decreased_normality_vars = all_results[\n",
    "    all_results['P_Value_After'] < all_results['P_Value_Before']\n",
    "]\n",
    "\n",
    "print(\"================================================================\")\n",
    "print(\"ðŸ”´ VARIABLES THAT DECREASED IN NORMALITY (P-Value went DOWN)\")\n",
    "print(\"================================================================\")\n",
    "if decreased_normality_vars.empty:\n",
    "    print(\"None of the transformed variables showed a decrease in normality.\")\n",
    "else:\n",
    "    print(decreased_normality_vars[['Variable', 'P_Value_Before', 'P_Value_After']])\n",
    "\n",
    "print(\"================================================================\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
