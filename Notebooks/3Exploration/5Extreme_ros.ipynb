{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5099ef35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primeiras linhas do dataset:\n",
      "       inidoy      enddoy        ros_p  duration_p     elev_av   aspect_av  \\\n",
      "0  221.750000  221.958333  1199.641053         5.0  222.993924  184.797777   \n",
      "1  221.958333  222.125000   397.497644         4.0  167.295794  164.945149   \n",
      "2  222.500000  222.604167  1092.753836         2.5  211.103842  248.382782   \n",
      "3  222.604167  222.916667   584.937417         7.5  184.752690  152.575136   \n",
      "4  241.722222  241.784722   708.321556         1.5  170.930441  276.002661   \n",
      "\n",
      "   landform  land_use  1_3y_fir_p  3_8y_fir_p  ...  LCL_m_av  LFC_hPa_av  \\\n",
      "0      21.0       4.0         0.0         0.0  ...  2.187129         NaN   \n",
      "1      22.0       4.0         0.0         0.0  ...  1.955263         NaN   \n",
      "2      21.0       4.0         0.0         0.0  ...  3.322814         NaN   \n",
      "3      21.0       4.0         0.0         0.0  ...  2.860403         NaN   \n",
      "4      21.0       4.0         0.0         0.0  ...  1.686957         NaN   \n",
      "\n",
      "   CCL_hPa_av  EL_m_av  LiftIdx_av    VentIdx_av   CMLG_av    ros_p_lg1  \\\n",
      "0  603.126054      NaN   23.052628  21987.987686  1.521746          NaN   \n",
      "1  580.925947      NaN   25.889089  23552.555084  1.600810  1199.641053   \n",
      "2  518.699850      NaN   17.904506   7464.756538  1.769979          NaN   \n",
      "3  531.037893      NaN   19.628183   9233.734741  1.936235  1092.753836   \n",
      "4  722.966350      NaN   18.231640  24199.052811  0.896715          NaN   \n",
      "\n",
      "   f_start                                           geometry  \n",
      "0      0.0  POLYGON ((567070.391 4377440.37, 567146.283 43...  \n",
      "1    300.0  POLYGON ((568191.985 4374565.347, 568271.318 4...  \n",
      "2   1080.0  POLYGON ((563396.27 4376587.137, 563396.139 43...  \n",
      "3   1230.0  MULTIPOLYGON (((562148.15 4377681.616, 562134....  \n",
      "4      0.0  POLYGON ((564016.048 4350265.124, 564010.871 4...  \n",
      "\n",
      "[5 rows x 100 columns]\n",
      "\n",
      "Informações do dataset:\n",
      "<class 'geopandas.geodataframe.GeoDataFrame'>\n",
      "RangeIndex: 1173 entries, 0 to 1172\n",
      "Data columns (total 100 columns):\n",
      " #   Column      Non-Null Count  Dtype   \n",
      "---  ------      --------------  -----   \n",
      " 0   inidoy      1173 non-null   float64 \n",
      " 1   enddoy      1173 non-null   float64 \n",
      " 2   ros_p       1173 non-null   float64 \n",
      " 3   duration_p  1173 non-null   float64 \n",
      " 4   elev_av     1173 non-null   float64 \n",
      " 5   aspect_av   1173 non-null   float64 \n",
      " 6   landform    1172 non-null   float64 \n",
      " 7   land_use    1063 non-null   float64 \n",
      " 8   1_3y_fir_p  1173 non-null   float64 \n",
      " 9   3_8y_fir_p  1173 non-null   float64 \n",
      " 10  8_ny_fir_p  1173 non-null   float64 \n",
      " 11  fuel_model  1173 non-null   float64 \n",
      " 12  f_load_av   1173 non-null   float64 \n",
      " 13  sW_1m_av    1173 non-null   float64 \n",
      " 14  sW_3m_av    1173 non-null   float64 \n",
      " 15  sW_7_av     1173 non-null   float64 \n",
      " 16  sW_28_av    1173 non-null   float64 \n",
      " 17  sW_100_av   1173 non-null   float64 \n",
      " 18  sW_289_av   1173 non-null   float64 \n",
      " 19  t_2m_C_av   1173 non-null   float64 \n",
      " 20  d_2m_C_av   1173 non-null   float64 \n",
      " 21  rh_2m_av    1173 non-null   float64 \n",
      " 22  VPD_Pa_av   1173 non-null   float64 \n",
      " 23  sP_hPa_av   1173 non-null   float64 \n",
      " 24  gp_m2s2_av  1173 non-null   float64 \n",
      " 25  dfmc_av     1173 non-null   float64 \n",
      " 26  HDW_av      1173 non-null   float64 \n",
      " 27  Haines_av   1173 non-null   float64 \n",
      " 28  FWI_12h_av  1173 non-null   float64 \n",
      " 29  DC_12h_av   1173 non-null   float64 \n",
      " 30  FFMC_12h_a  1173 non-null   float64 \n",
      " 31  wv10_kh_av  1173 non-null   float64 \n",
      " 32  wdir10_av   1173 non-null   float64 \n",
      " 33  wv100_k_av  1173 non-null   float64 \n",
      " 34  wdir100_av  1173 non-null   float64 \n",
      " 35  Recirc      1061 non-null   float64 \n",
      " 36  CircVar     1061 non-null   float64 \n",
      " 37  t_950_av    1173 non-null   float64 \n",
      " 38  t_850_av    1173 non-null   float64 \n",
      " 39  t_700_av    1173 non-null   float64 \n",
      " 40  t_500_av    1173 non-null   float64 \n",
      " 41  t_300_av    1173 non-null   float64 \n",
      " 42  rh_950_av   1173 non-null   float64 \n",
      " 43  rh_850_av   1173 non-null   float64 \n",
      " 44  rh_700_av   1173 non-null   float64 \n",
      " 45  rh_500_av   1173 non-null   float64 \n",
      " 46  rh_300_av   1173 non-null   float64 \n",
      " 47  wv_950_av   1173 non-null   float64 \n",
      " 48  wv_850_av   1173 non-null   float64 \n",
      " 49  wv_700_av   1173 non-null   float64 \n",
      " 50  wv_500_av   1173 non-null   float64 \n",
      " 51  wv_300_av   1173 non-null   float64 \n",
      " 52  wdi_950_av  1173 non-null   float64 \n",
      " 53  wdi_850_av  1173 non-null   float64 \n",
      " 54  wdi_700_av  1173 non-null   float64 \n",
      " 55  wdi_500_av  1173 non-null   float64 \n",
      " 56  wdi_300_av  1173 non-null   float64 \n",
      " 57  vwv_950_av  1173 non-null   float64 \n",
      " 58  vwv_850_av  1173 non-null   float64 \n",
      " 59  vwv_700_av  1173 non-null   float64 \n",
      " 60  vwv_500_av  1173 non-null   float64 \n",
      " 61  vwv_300_av  1173 non-null   float64 \n",
      " 62  gp_950_av   1173 non-null   float64 \n",
      " 63  gp_850_av   1173 non-null   float64 \n",
      " 64  gp_700_av   1173 non-null   float64 \n",
      " 65  gp_500_av   1173 non-null   float64 \n",
      " 66  gp_300_av   1173 non-null   float64 \n",
      " 67  gT_s_9_av   493 non-null    float64 \n",
      " 68  gT_9_8_av   1173 non-null   float64 \n",
      " 69  gT_8_7_av   1173 non-null   float64 \n",
      " 70  gT_7_5_av   1173 non-null   float64 \n",
      " 71  gT_5_3_av   1173 non-null   float64 \n",
      " 72  wSv_9_av    1173 non-null   float64 \n",
      " 73  wSdir_9_av  1173 non-null   float64 \n",
      " 74  wSv_7_av    1173 non-null   float64 \n",
      " 75  wSdir_7_av  1173 non-null   float64 \n",
      " 76  wSv_5_av    1173 non-null   float64 \n",
      " 77  wSdir_5_av  1173 non-null   float64 \n",
      " 78  wSv_1_av    1173 non-null   float64 \n",
      " 79  wSdir_1_av  1173 non-null   float64 \n",
      " 80  CBH_m_av    607 non-null    float64 \n",
      " 81  HigCC_p_av  1173 non-null   float64 \n",
      " 82  LowCC_p_av  1173 non-null   float64 \n",
      " 83  MidCC_p_av  1173 non-null   float64 \n",
      " 84  TotCC_p_av  1173 non-null   float64 \n",
      " 85  Cape_av     1173 non-null   float64 \n",
      " 86  Cin_av      44 non-null     float64 \n",
      " 87  BLH_m_av    1173 non-null   float64 \n",
      " 88  BLH_m_rt    1061 non-null   float64 \n",
      " 89  LCL_hPa_av  1173 non-null   float64 \n",
      " 90  LCL_m_av    1173 non-null   float64 \n",
      " 91  LFC_hPa_av  687 non-null    float64 \n",
      " 92  CCL_hPa_av  1173 non-null   float64 \n",
      " 93  EL_m_av     134 non-null    float64 \n",
      " 94  LiftIdx_av  1173 non-null   float64 \n",
      " 95  VentIdx_av  1173 non-null   float64 \n",
      " 96  CMLG_av     1173 non-null   float64 \n",
      " 97  ros_p_lg1   820 non-null    float64 \n",
      " 98  f_start     1173 non-null   float64 \n",
      " 99  geometry    1173 non-null   geometry\n",
      "dtypes: float64(99), geometry(1)\n",
      "memory usage: 916.5 KB\n",
      "None\n",
      "\n",
      "Colunas disponíveis:\n",
      "['inidoy', 'enddoy', 'ros_p', 'duration_p', 'elev_av', 'aspect_av', 'landform', 'land_use', '1_3y_fir_p', '3_8y_fir_p', '8_ny_fir_p', 'fuel_model', 'f_load_av', 'sW_1m_av', 'sW_3m_av', 'sW_7_av', 'sW_28_av', 'sW_100_av', 'sW_289_av', 't_2m_C_av', 'd_2m_C_av', 'rh_2m_av', 'VPD_Pa_av', 'sP_hPa_av', 'gp_m2s2_av', 'dfmc_av', 'HDW_av', 'Haines_av', 'FWI_12h_av', 'DC_12h_av', 'FFMC_12h_a', 'wv10_kh_av', 'wdir10_av', 'wv100_k_av', 'wdir100_av', 'Recirc', 'CircVar', 't_950_av', 't_850_av', 't_700_av', 't_500_av', 't_300_av', 'rh_950_av', 'rh_850_av', 'rh_700_av', 'rh_500_av', 'rh_300_av', 'wv_950_av', 'wv_850_av', 'wv_700_av', 'wv_500_av', 'wv_300_av', 'wdi_950_av', 'wdi_850_av', 'wdi_700_av', 'wdi_500_av', 'wdi_300_av', 'vwv_950_av', 'vwv_850_av', 'vwv_700_av', 'vwv_500_av', 'vwv_300_av', 'gp_950_av', 'gp_850_av', 'gp_700_av', 'gp_500_av', 'gp_300_av', 'gT_s_9_av', 'gT_9_8_av', 'gT_8_7_av', 'gT_7_5_av', 'gT_5_3_av', 'wSv_9_av', 'wSdir_9_av', 'wSv_7_av', 'wSdir_7_av', 'wSv_5_av', 'wSdir_5_av', 'wSv_1_av', 'wSdir_1_av', 'CBH_m_av', 'HigCC_p_av', 'LowCC_p_av', 'MidCC_p_av', 'TotCC_p_av', 'Cape_av', 'Cin_av', 'BLH_m_av', 'BLH_m_rt', 'LCL_hPa_av', 'LCL_m_av', 'LFC_hPa_av', 'CCL_hPa_av', 'EL_m_av', 'LiftIdx_av', 'VentIdx_av', 'CMLG_av', 'ros_p_lg1', 'f_start', 'geometry']\n"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Carregar os dados\n",
    "gdf = gpd.read_file(\"..\\..\\Data\\Processed\\PT-FireSprd_v2.1\\L2_FireBehavior\\PT-FireProg_v2.1_L2_model.shp\")\n",
    "\n",
    "print(\"Primeiras linhas do dataset:\")\n",
    "print(gdf.head())\n",
    "print(\"\\nInformações do dataset:\")\n",
    "print(gdf.info())\n",
    "print(\"\\nColunas disponíveis:\")\n",
    "print(gdf.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45127f62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Grupo com ros_p > 2000: 132 registros\n",
      "Grupo com 1000 < ros_p <= 2000: 196 registros\n",
      "Grupo com ros_p <= 1000: 845 registros\n",
      "\n",
      "Colunas para análise: ['inidoy', 'enddoy', 'duration_p', 'elev_av', 'aspect_av', 'landform', 'land_use', '1_3y_fir_p', '3_8y_fir_p', '8_ny_fir_p', 'fuel_model', 'f_load_av', 'sW_1m_av', 'sW_3m_av', 'sW_7_av', 'sW_28_av', 'sW_100_av', 'sW_289_av', 't_2m_C_av', 'd_2m_C_av', 'rh_2m_av', 'VPD_Pa_av', 'sP_hPa_av', 'gp_m2s2_av', 'dfmc_av', 'HDW_av', 'Haines_av', 'FWI_12h_av', 'DC_12h_av', 'FFMC_12h_a', 'wv10_kh_av', 'wdir10_av', 'wv100_k_av', 'wdir100_av', 'Recirc', 'CircVar', 't_950_av', 't_850_av', 't_700_av', 't_500_av', 't_300_av', 'rh_950_av', 'rh_850_av', 'rh_700_av', 'rh_500_av', 'rh_300_av', 'wv_950_av', 'wv_850_av', 'wv_700_av', 'wv_500_av', 'wv_300_av', 'wdi_950_av', 'wdi_850_av', 'wdi_700_av', 'wdi_500_av', 'wdi_300_av', 'vwv_950_av', 'vwv_850_av', 'vwv_700_av', 'vwv_500_av', 'vwv_300_av', 'gp_950_av', 'gp_850_av', 'gp_700_av', 'gp_500_av', 'gp_300_av', 'gT_s_9_av', 'gT_9_8_av', 'gT_8_7_av', 'gT_7_5_av', 'gT_5_3_av', 'wSv_9_av', 'wSdir_9_av', 'wSv_7_av', 'wSdir_7_av', 'wSv_5_av', 'wSdir_5_av', 'wSv_1_av', 'wSdir_1_av', 'CBH_m_av', 'HigCC_p_av', 'LowCC_p_av', 'MidCC_p_av', 'TotCC_p_av', 'Cape_av', 'Cin_av', 'BLH_m_av', 'BLH_m_rt', 'LCL_hPa_av', 'LCL_m_av', 'LFC_hPa_av', 'CCL_hPa_av', 'EL_m_av', 'LiftIdx_av', 'VentIdx_av', 'CMLG_av', 'ros_p_lg1', 'f_start']\n"
     ]
    }
   ],
   "source": [
    "# Separar os dados\n",
    "grupo_alto = gdf[gdf['ros_p'] > 2000]\n",
    "grupo_medio = gdf[(gdf['ros_p'] > 1000) & (gdf['ros_p'] <= 2000)]\n",
    "grupo_baixo = gdf[gdf['ros_p'] <= 1000]\n",
    "\n",
    "print(f\"\\nGrupo com ros_p > 2000: {len(grupo_alto)} registros\")\n",
    "print(f\"Grupo com 1000 < ros_p <= 2000: {len(grupo_medio)} registros\")\n",
    "print(f\"Grupo com ros_p <= 1000: {len(grupo_baixo)} registros\")\n",
    "\n",
    "# Identificar colunas numéricas para análise\n",
    "colunas_numericas = gdf.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "# Remover colunas que não são relevantes para análise (como coordenadas, IDs, etc)\n",
    "colunas_nao_relevantes = ['geometry', 'FID', 'OBJECTID', 'ID', 'id']\n",
    "colunas_analise = [col for col in colunas_numericas if col not in colunas_nao_relevantes and col != 'ros_p']\n",
    "\n",
    "print(f\"\\nColunas para análise: {colunas_analise}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e63940b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparando dados para análise...\n",
      "\n",
      "Grupo com ros_p > 2000: 132 registros\n",
      "Grupo com ros_p <= 2000: 1041 registros\n",
      "\n",
      "Colunas para análise: 98\n",
      "\n",
      "==================================================\n",
      "REALIZANDO TESTES ESTATÍSTICOS\n",
      "==================================================\n",
      "Testes estatísticos concluídos!\n",
      "\n",
      "================================================================================\n",
      "CRIANDO RESUMO E VISUALIZAÇÕES\n",
      "================================================================================\n",
      "RESUMO DAS VARIÁVEIS MAIS IMPORTANTES (SIGNIFICATIVAS)\n",
      "================================================================================\n",
      "\n",
      "Variáveis com diferenças estatisticamente significativas (p < 0.05): 30\n",
      "\n",
      "Top 20 variáveis mais importantes:\n",
      "  Variável  Grupo Alto (média)  Grupo Baixo (média)  Diferença  p-valor\n",
      "    HDW_av          39235.2030           25762.3231 13472.8799   0.0000\n",
      "VentIdx_av          14851.7973           11410.7828  3441.0145   0.0000\n",
      " ros_p_lg1           2861.4344             755.5641  2105.8703   0.0000\n",
      "gp_m2s2_av           3971.5785            4725.7786  -754.2001   0.0007\n",
      "   f_start            962.1970            1670.5524  -708.3554   0.0000\n",
      "  CBH_m_av           5136.8512            4532.2086   604.6426   0.0301\n",
      " VPD_Pa_av           2716.7144            2295.6867   421.0277   0.0007\n",
      " gp_300_av          93839.8598           94206.9161  -367.0564   0.0000\n",
      "  BLH_m_av           1032.3806             791.3701   241.0105   0.0077\n",
      "  wSv_9_av            125.7547             -74.6358   200.3905   0.0000\n",
      " DC_12h_av            876.2330             677.3898   198.8431   0.0000\n",
      " gp_500_av          57367.7167           57564.8029  -197.0863   0.0000\n",
      "   elev_av            412.7915             502.6048   -89.8133   0.0003\n",
      "   Cape_av             26.3546             100.7202   -74.3657   0.0000\n",
      " aspect_av            231.5059             190.9787    40.5272   0.0000\n",
      "LCL_hPa_av            731.3293             767.8460   -36.5167   0.0000\n",
      "  wSv_1_av            102.8548              66.4501    36.4047   0.0000\n",
      " gp_950_av           5717.5950            5683.8675    33.7275   0.0428\n",
      " gp_850_av          15205.4736           15173.2943    32.1794   0.0039\n",
      "    inidoy            255.0175             223.8096    31.2079   0.0000\n",
      "\n",
      "================================================================================\n",
      "CRIANDO VISUALIZAÇÕES\n",
      "================================================================================\n",
      "\n",
      "1. Gráfico de TODAS as variáveis — primeiro significativas, depois não significativas\n",
      "\n",
      "PDF guardado como: ..\\..\\Data\\Data_Exploration\\variaveis_diferentes_2000_ros.pdf\n",
      "\n",
      "================================================================================\n",
      "RESUMO FINAL DA ANÁLISE\n",
      "================================================================================\n",
      "\n",
      "1. AMOSTRAS:\n",
      "   • Grupo Alto (ros_p > 2000): 132 registros\n",
      "   • Grupo Baixo (ros_p ≤ 2000): 1041 registros\n",
      "\n",
      "2. SIGNIFICÂNCIA ESTATÍSTICA:\n",
      "   • Variáveis analisadas: 98\n",
      "   • Variáveis significativas (p < 0.05): 30\n",
      "   • Taxa de significância: 30.6%\n",
      "\n",
      "3. TOP 10 VARIÁVEIS COM MAIOR IMPACTO:\n",
      "    1. HDW_av               → MAIOR no grupo alto (Δ = 13472.88, p = 0.0000)\n",
      "    2. VentIdx_av           → MAIOR no grupo alto (Δ = 3441.01, p = 0.0000)\n",
      "    3. ros_p_lg1            → MAIOR no grupo alto (Δ = 2105.87, p = 0.0000)\n",
      "    4. gp_m2s2_av           → MENOR no grupo alto (Δ = -754.20, p = 0.0007)\n",
      "    5. f_start              → MENOR no grupo alto (Δ = -708.36, p = 0.0000)\n",
      "    6. CBH_m_av             → MAIOR no grupo alto (Δ =  604.64, p = 0.0301)\n",
      "    7. VPD_Pa_av            → MAIOR no grupo alto (Δ =  421.03, p = 0.0007)\n",
      "    8. gp_300_av            → MENOR no grupo alto (Δ = -367.06, p = 0.0000)\n",
      "    9. BLH_m_av             → MAIOR no grupo alto (Δ =  241.01, p = 0.0077)\n",
      "   10. wSv_9_av             → MAIOR no grupo alto (Δ =  200.39, p = 0.0000)\n",
      "\n",
      "4. PADRÕES PRINCIPAIS IDENTIFICADOS:\n",
      "   • VENTOS FORTES: wv_950_av, wv_850_av, wv_700_av\n",
      "   • ÍNDICES FOGO ALTOS: FWI_12h_av, DC_12h_av, VentIdx_av\n",
      "   • ÉPOCA TARDIA: inidoy, enddoy\n",
      "   • MENOR ELEVAÇÃO: elev_av\n",
      "\n",
      "================================================================================\n",
      "ANÁLISE CONCLUÍDA!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "# Primeiro, vamos garantir que temos os dados carregados corretamente\n",
    "print(\"Preparando dados para análise...\")\n",
    "\n",
    "# Separar os dados\n",
    "grupo_alto = gdf[gdf['ros_p'] > 2000]\n",
    "grupo_baixo = gdf[gdf['ros_p'] <= 2000]\n",
    "\n",
    "print(f\"\\nGrupo com ros_p > 2000: {len(grupo_alto)} registros\")\n",
    "print(f\"Grupo com ros_p <= 2000: {len(grupo_baixo)} registros\")\n",
    "\n",
    "# Identificar colunas numéricas para análise\n",
    "colunas_numericas = gdf.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "# Remover colunas que não são relevantes para análise (como coordenadas, IDs, etc)\n",
    "colunas_nao_relevantes = ['geometry', 'FID', 'OBJECTID', 'ID', 'id']\n",
    "colunas_analise = [col for col in colunas_numericas if col not in colunas_nao_relevantes and col != 'ros_p']\n",
    "\n",
    "print(f\"\\nColunas para análise: {len(colunas_analise)}\")\n",
    "\n",
    "# REALIZAR OS TESTES ESTATÍSTICOS PRIMEIRO\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"REALIZANDO TESTES ESTATÍSTICOS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "resultados_teste = []\n",
    "\n",
    "for coluna in colunas_analise:\n",
    "    try:\n",
    "        # Remover valores NaN\n",
    "        dados_alto = grupo_alto[coluna].dropna()\n",
    "        dados_baixo = grupo_baixo[coluna].dropna()\n",
    "        \n",
    "        if len(dados_alto) < 3 or len(dados_baixo) < 3:\n",
    "            resultados_teste.append({\n",
    "                'Variável': coluna,\n",
    "                'Teste': 'Não aplicável',\n",
    "                'Estatística': np.nan,\n",
    "                'p-valor': np.nan,\n",
    "                'Significativo': False\n",
    "            })\n",
    "            continue\n",
    "            \n",
    "        # Teste de normalidade (Shapiro-Wilk)\n",
    "        try:\n",
    "            _, p_alto = stats.shapiro(dados_alto)\n",
    "            _, p_baixo = stats.shapiro(dados_baixo)\n",
    "            \n",
    "            normal_alto = p_alto > 0.05\n",
    "            normal_baixo = p_baixo > 0.05\n",
    "            \n",
    "            # Escolher teste baseado na normalidade\n",
    "            if normal_alto and normal_baixo:\n",
    "                # Teste t para amostras independentes\n",
    "                estatistica, p_valor = stats.ttest_ind(dados_alto, dados_baixo, equal_var=False)\n",
    "                teste_usado = \"Teste t (Welch)\"\n",
    "            else:\n",
    "                # Teste de Mann-Whitney U (não paramétrico)\n",
    "                estatistica, p_valor = stats.mannwhitneyu(dados_alto, dados_baixo)\n",
    "                teste_usado = \"Mann-Whitney U\"\n",
    "                \n",
    "        except:\n",
    "            # Se houver erro no teste paramétrico, usar não paramétrico\n",
    "            estatistica, p_valor = stats.mannwhitneyu(dados_alto, dados_baixo)\n",
    "            teste_usado = \"Mann-Whitney U\"\n",
    "        \n",
    "        resultados_teste.append({\n",
    "            'Variável': coluna,\n",
    "            'Teste': teste_usado,\n",
    "            'Estatística': estatistica,\n",
    "            'p-valor': p_valor,\n",
    "            'Significativo': p_valor < 0.05\n",
    "        })\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Erro na variável {coluna}: {e}\")\n",
    "        resultados_teste.append({\n",
    "            'Variável': coluna,\n",
    "            'Teste': 'Erro',\n",
    "            'Estatística': np.nan,\n",
    "            'p-valor': np.nan,\n",
    "            'Significativo': False\n",
    "        })\n",
    "\n",
    "print(\"Testes estatísticos concluídos!\")\n",
    "\n",
    "# AGORA CRIAR O RESUMO E OS GRÁFICOS\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CRIANDO RESUMO E VISUALIZAÇÕES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Criar DataFrame com resultados\n",
    "resultados = []\n",
    "for coluna in colunas_analise:\n",
    "    # Encontrar os resultados correspondentes\n",
    "    for resultado in resultados_teste:\n",
    "        if resultado['Variável'] == coluna:\n",
    "            try:\n",
    "                resultados.append({\n",
    "                    'Variável': coluna,\n",
    "                    'Grupo Alto (média)': grupo_alto[coluna].mean(),\n",
    "                    'Grupo Baixo (média)': grupo_baixo[coluna].mean(),\n",
    "                    'Diferença': grupo_alto[coluna].mean() - grupo_baixo[coluna].mean(),\n",
    "                    'p-valor': resultado['p-valor'],\n",
    "                    'Significativo': resultado['Significativo'],\n",
    "                    'Teste': resultado['Teste']\n",
    "                })\n",
    "            except:\n",
    "                continue\n",
    "            break\n",
    "\n",
    "df_resumo = pd.DataFrame(resultados)\n",
    "\n",
    "# Ordenar por significância e magnitude da diferença\n",
    "df_resumo['abs_diferenca'] = abs(df_resumo['Diferença'])\n",
    "df_resumo = df_resumo.sort_values(['Significativo', 'abs_diferenca'], ascending=[False, False])\n",
    "\n",
    "print(\"RESUMO DAS VARIÁVEIS MAIS IMPORTANTES (SIGNIFICATIVAS)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Filtrar apenas variáveis significativas\n",
    "df_significativas = df_resumo[df_resumo['Significativo'] == True].head(30)\n",
    "\n",
    "print(f\"\\nVariáveis com diferenças estatisticamente significativas (p < 0.05): {len(df_significativas)}\")\n",
    "print(\"\\nTop 20 variáveis mais importantes:\")\n",
    "print(df_significativas[['Variável', 'Grupo Alto (média)', 'Grupo Baixo (média)', 'Diferença', 'p-valor']].head(20).round(4).to_string(index=False))\n",
    "\n",
    "# VISUALIZAÇÕES PRINCIPAIS\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CRIANDO VISUALIZAÇÕES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"\\n1. Gráfico de TODAS as variáveis — primeiro significativas, depois não significativas\")\n",
    "\n",
    "# Criar PDF para guardar os gráficos\n",
    "pdf_path = r'..\\..\\Data\\Data_Exploration\\variaveis_diferentes_2000_ros.pdf'\n",
    "pdf = PdfPages(pdf_path)\n",
    "\n",
    "# Separar variáveis significativas e não significativas\n",
    "df_signif = df_resumo[df_resumo['Significativo'] == True].sort_values('abs_diferenca', ascending=False)\n",
    "df_nsignif = df_resumo[df_resumo['Significativo'] == False].sort_values('abs_diferenca', ascending=False)\n",
    "\n",
    "# SIGNIFICATIVAS primeiro, mas dentro do grupo em ordem alfabética\n",
    "df_signif_plot = df_signif.sort_values(\"Variável\")\n",
    "\n",
    "# NÃO significativas depois, também em ordem alfabética\n",
    "df_nsignif_plot = df_nsignif.sort_values(\"Variável\")\n",
    "\n",
    "# Agora concatena mantendo a ordem desejada\n",
    "df_plot = pd.concat([df_signif_plot, df_nsignif_plot], axis=0)\n",
    "\n",
    "\n",
    "n = len(df_plot)\n",
    "cols = 4\n",
    "rows = (n // cols) + (1 if n % cols != 0 else 0)\n",
    "\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(20, 5*rows))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i, (idx, row) in enumerate(df_plot.iterrows()):\n",
    "    var = row['Variável']\n",
    "\n",
    "    try:\n",
    "        dados_alto_clean = grupo_alto[var].dropna()\n",
    "        dados_baixo_clean = grupo_baixo[var].dropna()\n",
    "\n",
    "        dados = pd.DataFrame({\n",
    "            'Valor': pd.concat([dados_alto_clean, dados_baixo_clean]),\n",
    "            'Grupo': ['ros_p > 2000'] * len(dados_alto_clean) + ['ros_p ≤ 2000'] * len(dados_baixo_clean)\n",
    "        })\n",
    "\n",
    "        sns.boxplot(\n",
    "            x='Grupo',\n",
    "            y='Valor',\n",
    "            data=dados,\n",
    "            ax=axes[i],\n",
    "            palette={'ros_p > 2000': 'red', 'ros_p ≤ 2000': 'blue'}\n",
    "        )\n",
    "\n",
    "        titulo = (\n",
    "            f\"{var}\\n(p = {row['p-valor']:.4f}) ★\"\n",
    "            if row['Significativo'] else\n",
    "            f\"{var}\\n(p = {row['p-valor']:.4f})\"\n",
    "        )\n",
    "\n",
    "        axes[i].set_title(titulo, fontsize=10)\n",
    "        axes[i].tick_params(axis='x', rotation=45)\n",
    "        axes[i].grid(True, linestyle='--', alpha=0.5)\n",
    "\n",
    "        diff = row['Diferença']\n",
    "        axes[i].text(\n",
    "            0.5, 0.95, f'Δ = {diff:.2f}',\n",
    "            transform=axes[i].transAxes, ha='center',\n",
    "            bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"yellow\", alpha=0.7),\n",
    "            fontsize=8\n",
    "        )\n",
    "\n",
    "    except Exception as e:\n",
    "        axes[i].set_title(f'Erro: {var}')\n",
    "        print(f\"Erro no plot de {var}: {e}\")\n",
    "\n",
    "# Remover eixos vazios\n",
    "for j in range(i+1, len(axes)):\n",
    "    fig.delaxes(axes[j])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle(\n",
    "    'TODAS AS VARIÁVEIS — Significativas (★) primeiro, depois não significativas',\n",
    "    fontsize=18, y=1.02\n",
    ")\n",
    "\n",
    "# Salvar esta figura no PDF\n",
    "pdf.savefig(fig)\n",
    "plt.close(fig)\n",
    "\n",
    "# Fechar PDF\n",
    "pdf.close()\n",
    "print(f\"\\nPDF guardado como: {pdf_path}\")\n",
    "\n",
    "\n",
    "\n",
    "# 4. RESUMO FINAL\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RESUMO FINAL DA ANÁLISE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\n1. AMOSTRAS:\")\n",
    "print(f\"   • Grupo Alto (ros_p > 2000): {len(grupo_alto)} registros\")\n",
    "print(f\"   • Grupo Baixo (ros_p ≤ 2000): {len(grupo_baixo)} registros\")\n",
    "\n",
    "print(f\"\\n2. SIGNIFICÂNCIA ESTATÍSTICA:\")\n",
    "print(f\"   • Variáveis analisadas: {len(colunas_analise)}\")\n",
    "print(f\"   • Variáveis significativas (p < 0.05): {len(df_significativas)}\")\n",
    "print(f\"   • Taxa de significância: {len(df_significativas)/len(colunas_analise)*100:.1f}%\")\n",
    "\n",
    "# Top 10 variáveis por magnitude do efeito\n",
    "print(f\"\\n3. TOP 10 VARIÁVEIS COM MAIOR IMPACTO:\")\n",
    "top_10_efeito = df_significativas.nlargest(10, 'abs_diferenca')\n",
    "for i, (idx, row) in enumerate(top_10_efeito.iterrows(), 1):\n",
    "    direcao = \"MAIOR\" if row['Diferença'] > 0 else \"MENOR\"\n",
    "    print(f\"   {i:2d}. {row['Variável']:20s} → {direcao} no grupo alto (Δ = {row['Diferença']:7.2f}, p = {row['p-valor']:.4f})\")\n",
    "\n",
    "# Padrões principais\n",
    "print(f\"\\n4. PADRÕES PRINCIPAIS IDENTIFICADOS:\")\n",
    "\n",
    "padroes = {\n",
    "    'VENTOS FORTES': ['wv100_k_av', 'wv10_kh_av', 'wv_950_av', 'wv_850_av', 'wv_700_av'],\n",
    "    'CONDIÇÕES SECAS': ['sW_1m_av', 'sW_3m_av', 'sW_7_av', 'rh_2m_av', 'rh_700_av'],\n",
    "    'ÍNDICES FOGO ALTOS': ['FWI_12h_av', 'DC_12h_av', 'VentIdx_av'],\n",
    "    'ÉPOCA TARDIA': ['inidoy', 'enddoy'],\n",
    "    'DURAÇÃO CURTA': ['duration_p'],\n",
    "    'MENOR ELEVAÇÃO': ['elev_av']\n",
    "}\n",
    "\n",
    "for padrao, variaveis in padroes.items():\n",
    "    vars_encontradas = [v for v in variaveis if v in df_significativas['Variável'].values]\n",
    "    if vars_encontradas:\n",
    "        print(f\"   • {padrao}: {', '.join(vars_encontradas)}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ANÁLISE CONCLUÍDA!\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8409a35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================================================\n",
      "TABELA RESUMO - VARIÁVEIS SIGNIFICATIVAS (p < 0.05)\n",
      "====================================================================================================\n",
      "\n",
      "Total de variáveis significativas: 30\n",
      "\n",
      "Tabela ordenada por magnitude da diferença:\n",
      "  Variável  Grupo Alto (média)  Grupo Baixo (média)  Diferença  Diferença Relativa (%)  Efeito  p-valor\n",
      "    HDW_av           39235.203            25762.323  13472.880                   52.30 ↑ MAIOR   0.0000\n",
      "VentIdx_av           14851.797            11410.783   3441.014                   30.16 ↑ MAIOR   0.0000\n",
      " ros_p_lg1            2861.434              755.564   2105.870                  278.71 ↑ MAIOR   0.0000\n",
      "gp_m2s2_av            3971.578             4725.779   -754.200                  -15.96 ↓ MENOR   0.0007\n",
      "   f_start             962.197             1670.552   -708.355                  -42.40 ↓ MENOR   0.0000\n",
      "  CBH_m_av            5136.851             4532.209    604.643                   13.34 ↑ MAIOR   0.0301\n",
      " VPD_Pa_av            2716.714             2295.687    421.028                   18.34 ↑ MAIOR   0.0007\n",
      " gp_300_av           93839.860            94206.916   -367.056                   -0.39 ↓ MENOR   0.0000\n",
      "  BLH_m_av            1032.381              791.370    241.011                   30.45 ↑ MAIOR   0.0077\n",
      "  wSv_9_av             125.755              -74.636    200.390                 -268.49 ↑ MAIOR   0.0000\n",
      " DC_12h_av             876.233              677.390    198.843                   29.35 ↑ MAIOR   0.0000\n",
      " gp_500_av           57367.717            57564.803   -197.086                   -0.34 ↓ MENOR   0.0000\n",
      "   elev_av             412.792              502.605    -89.813                  -17.87 ↓ MENOR   0.0003\n",
      "   Cape_av              26.355              100.720    -74.366                  -73.83 ↓ MENOR   0.0000\n",
      " aspect_av             231.506              190.979     40.527                   21.22 ↑ MAIOR   0.0000\n",
      "LCL_hPa_av             731.329              767.846    -36.517                   -4.76 ↓ MENOR   0.0000\n",
      "  wSv_1_av             102.855               66.450     36.405                   54.79 ↑ MAIOR   0.0000\n",
      " gp_950_av            5717.595             5683.868     33.727                    0.59 ↑ MAIOR   0.0428\n",
      " gp_850_av           15205.474            15173.294     32.179                    0.21 ↑ MAIOR   0.0039\n",
      "    inidoy             255.017              223.810     31.208                   13.94 ↑ MAIOR   0.0000\n",
      "    enddoy             255.071              223.976     31.095                   13.88 ↑ MAIOR   0.0000\n",
      "CCL_hPa_av             710.237              734.663    -24.426                   -3.32 ↓ MENOR   0.0128\n",
      "wdi_500_av             191.340              207.152    -15.811                   -7.63 ↓ MENOR   0.0000\n",
      " wv_850_av              36.460               21.775     14.685                   67.44 ↑ MAIOR   0.0000\n",
      "wdi_850_av             196.508              183.075     13.433                    7.34 ↑ MAIOR   0.0454\n",
      " wv_700_av              43.021               29.994     13.026                   43.43 ↑ MAIOR   0.0000\n",
      "wSdir_9_av               1.640              -10.351     11.990                 -115.84 ↑ MAIOR   0.0016\n",
      " wv_500_av              47.418               37.350     10.068                   26.96 ↑ MAIOR   0.0000\n",
      "FWI_12h_av              56.564               46.543     10.021                   21.53 ↑ MAIOR   0.0000\n",
      " wv_950_av              27.473               17.659      9.813                   55.57 ↑ MAIOR   0.0000\n",
      "\n",
      "Tabela salva como 'variaveis_significativas_ros_p.csv'\n"
     ]
    }
   ],
   "source": [
    "# TABELA RESUMO COMPACTA\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"TABELA RESUMO - VARIÁVEIS SIGNIFICATIVAS (p < 0.05)\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "# Criar tabela compacta\n",
    "tabela_compacta = df_significativas[['Variável', 'Grupo Alto (média)', 'Grupo Baixo (média)', \n",
    "                                     'Diferença', 'p-valor']].copy()\n",
    "\n",
    "# Direção do efeito\n",
    "tabela_compacta['Efeito'] = tabela_compacta['Diferença'].apply(\n",
    "    lambda x: '↑ MAIOR' if x > 0 else '↓ MENOR'\n",
    ")\n",
    "\n",
    "# Diferença relativa (%)\n",
    "tabela_compacta['Diferença Relativa (%)'] = (\n",
    "    (tabela_compacta['Grupo Alto (média)'] - tabela_compacta['Grupo Baixo (média)']) /\n",
    "     tabela_compacta['Grupo Baixo (média)']\n",
    ") * 100\n",
    "\n",
    "# Formatar números\n",
    "for col in ['Grupo Alto (média)', 'Grupo Baixo (média)', 'Diferença']:\n",
    "    tabela_compacta[col] = tabela_compacta[col].round(3)\n",
    "\n",
    "tabela_compacta['Diferença Relativa (%)'] = tabela_compacta['Diferença Relativa (%)'].round(2)\n",
    "tabela_compacta['p-valor'] = tabela_compacta['p-valor'].round(4)\n",
    "\n",
    "# ✔ Reordenar colunas: Diferença e Diferença Relativa lado a lado\n",
    "tabela_compacta = tabela_compacta[\n",
    "    ['Variável',\n",
    "     'Grupo Alto (média)', \n",
    "     'Grupo Baixo (média)',\n",
    "     'Diferença',\n",
    "     'Diferença Relativa (%)',\n",
    "     'Efeito',\n",
    "     'p-valor']\n",
    "]\n",
    "\n",
    "print(f\"\\nTotal de variáveis significativas: {len(tabela_compacta)}\")\n",
    "\n",
    "print(\"\\nTabela ordenada por magnitude da diferença:\")\n",
    "print(\n",
    "    tabela_compacta.to_string(index=False, max_colwidth=30)\n",
    ")\n",
    "\n",
    "# Salvar CSV\n",
    "tabela_compacta.to_csv(r'..\\..\\Data\\Data_Exploration\\variaveis_significativas_ros_p_2000.csv', index=False, encoding='utf-8-sig')\n",
    "print(f\"\\nTabela salva como 'variaveis_significativas_ros_p.csv'\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
