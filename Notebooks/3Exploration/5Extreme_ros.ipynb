{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5099ef35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primeiras linhas do dataset:\n",
      "       inidoy      enddoy        ros_p  duration_p     elev_av   aspect_av  \\\n",
      "0  221.750000  221.958333  1199.641053         5.0  222.993924  184.797777   \n",
      "1  221.958333  222.125000   397.497644         4.0  167.295794  164.945149   \n",
      "2  222.500000  222.604167  1092.753836         2.5  211.103842  248.382782   \n",
      "3  222.604167  222.916667   584.937417         7.5  184.752690  152.575136   \n",
      "4  241.722222  241.784722   708.321556         1.5  170.930441  276.002661   \n",
      "\n",
      "   landform  land_use  1_3y_fir_p  3_8y_fir_p  ...  LCL_m_av  LFC_hPa_av  \\\n",
      "0      21.0       4.0         0.0         0.0  ...  2.187129         NaN   \n",
      "1      22.0       4.0         0.0         0.0  ...  1.955263         NaN   \n",
      "2      21.0       4.0         0.0         0.0  ...  3.322814         NaN   \n",
      "3      21.0       4.0         0.0         0.0  ...  2.860403         NaN   \n",
      "4      21.0       4.0         0.0         0.0  ...  1.686957         NaN   \n",
      "\n",
      "   CCL_hPa_av  EL_m_av  LiftIdx_av    VentIdx_av   CMLG_av    ros_p_lg1  \\\n",
      "0  603.126054      NaN   23.052628  21987.987686  1.521746          NaN   \n",
      "1  580.925947      NaN   25.889089  23552.555084  1.600810  1199.641053   \n",
      "2  518.699850      NaN   17.904506   7464.756538  1.769979          NaN   \n",
      "3  531.037893      NaN   19.628183   9233.734741  1.936235  1092.753836   \n",
      "4  722.966350      NaN   18.231640  24199.052811  0.896715          NaN   \n",
      "\n",
      "   f_start                                           geometry  \n",
      "0      0.0  POLYGON ((567070.391 4377440.37, 567146.283 43...  \n",
      "1    300.0  POLYGON ((568191.985 4374565.347, 568271.318 4...  \n",
      "2   1080.0  POLYGON ((563396.27 4376587.137, 563396.139 43...  \n",
      "3   1230.0  MULTIPOLYGON (((562148.15 4377681.616, 562134....  \n",
      "4      0.0  POLYGON ((564016.048 4350265.124, 564010.871 4...  \n",
      "\n",
      "[5 rows x 100 columns]\n",
      "\n",
      "Informações do dataset:\n",
      "<class 'geopandas.geodataframe.GeoDataFrame'>\n",
      "RangeIndex: 1177 entries, 0 to 1176\n",
      "Data columns (total 100 columns):\n",
      " #   Column      Non-Null Count  Dtype   \n",
      "---  ------      --------------  -----   \n",
      " 0   inidoy      1177 non-null   float64 \n",
      " 1   enddoy      1177 non-null   float64 \n",
      " 2   ros_p       1173 non-null   float64 \n",
      " 3   duration_p  1177 non-null   float64 \n",
      " 4   elev_av     1177 non-null   float64 \n",
      " 5   aspect_av   1177 non-null   float64 \n",
      " 6   landform    1176 non-null   float64 \n",
      " 7   land_use    1066 non-null   float64 \n",
      " 8   1_3y_fir_p  1177 non-null   float64 \n",
      " 9   3_8y_fir_p  1177 non-null   float64 \n",
      " 10  8_ny_fir_p  1177 non-null   float64 \n",
      " 11  fuel_model  1177 non-null   float64 \n",
      " 12  f_load_av   1177 non-null   float64 \n",
      " 13  sW_1m_av    1177 non-null   float64 \n",
      " 14  sW_3m_av    1177 non-null   float64 \n",
      " 15  sW_7_av     1177 non-null   float64 \n",
      " 16  sW_28_av    1177 non-null   float64 \n",
      " 17  sW_100_av   1177 non-null   float64 \n",
      " 18  sW_289_av   1177 non-null   float64 \n",
      " 19  t_2m_C_av   1177 non-null   float64 \n",
      " 20  d_2m_C_av   1177 non-null   float64 \n",
      " 21  rh_2m_av    1177 non-null   float64 \n",
      " 22  VPD_Pa_av   1177 non-null   float64 \n",
      " 23  sP_hPa_av   1177 non-null   float64 \n",
      " 24  gp_m2s2_av  1177 non-null   float64 \n",
      " 25  dfmc_av     1177 non-null   float64 \n",
      " 26  HDW_av      1177 non-null   float64 \n",
      " 27  Haines_av   1177 non-null   float64 \n",
      " 28  FWI_12h_av  1177 non-null   float64 \n",
      " 29  DC_12h_av   1177 non-null   float64 \n",
      " 30  FFMC_12h_a  1177 non-null   float64 \n",
      " 31  wv10_kh_av  1177 non-null   float64 \n",
      " 32  wdir10_av   1177 non-null   float64 \n",
      " 33  wv100_k_av  1177 non-null   float64 \n",
      " 34  wdir100_av  1177 non-null   float64 \n",
      " 35  Recirc      1065 non-null   float64 \n",
      " 36  CircVar     1065 non-null   float64 \n",
      " 37  t_950_av    1177 non-null   float64 \n",
      " 38  t_850_av    1177 non-null   float64 \n",
      " 39  t_700_av    1177 non-null   float64 \n",
      " 40  t_500_av    1177 non-null   float64 \n",
      " 41  t_300_av    1177 non-null   float64 \n",
      " 42  rh_950_av   1177 non-null   float64 \n",
      " 43  rh_850_av   1177 non-null   float64 \n",
      " 44  rh_700_av   1177 non-null   float64 \n",
      " 45  rh_500_av   1177 non-null   float64 \n",
      " 46  rh_300_av   1177 non-null   float64 \n",
      " 47  wv_950_av   1177 non-null   float64 \n",
      " 48  wv_850_av   1177 non-null   float64 \n",
      " 49  wv_700_av   1177 non-null   float64 \n",
      " 50  wv_500_av   1177 non-null   float64 \n",
      " 51  wv_300_av   1177 non-null   float64 \n",
      " 52  wdi_950_av  1177 non-null   float64 \n",
      " 53  wdi_850_av  1177 non-null   float64 \n",
      " 54  wdi_700_av  1177 non-null   float64 \n",
      " 55  wdi_500_av  1177 non-null   float64 \n",
      " 56  wdi_300_av  1177 non-null   float64 \n",
      " 57  vwv_950_av  1177 non-null   float64 \n",
      " 58  vwv_850_av  1177 non-null   float64 \n",
      " 59  vwv_700_av  1177 non-null   float64 \n",
      " 60  vwv_500_av  1177 non-null   float64 \n",
      " 61  vwv_300_av  1177 non-null   float64 \n",
      " 62  gp_950_av   1177 non-null   float64 \n",
      " 63  gp_850_av   1177 non-null   float64 \n",
      " 64  gp_700_av   1177 non-null   float64 \n",
      " 65  gp_500_av   1177 non-null   float64 \n",
      " 66  gp_300_av   1177 non-null   float64 \n",
      " 67  gT_s_9_av   495 non-null    float64 \n",
      " 68  gT_9_8_av   1177 non-null   float64 \n",
      " 69  gT_8_7_av   1177 non-null   float64 \n",
      " 70  gT_7_5_av   1177 non-null   float64 \n",
      " 71  gT_5_3_av   1177 non-null   float64 \n",
      " 72  wSv_9_av    1177 non-null   float64 \n",
      " 73  wSdir_9_av  1177 non-null   float64 \n",
      " 74  wSv_7_av    1177 non-null   float64 \n",
      " 75  wSdir_7_av  1177 non-null   float64 \n",
      " 76  wSv_5_av    1177 non-null   float64 \n",
      " 77  wSdir_5_av  1177 non-null   float64 \n",
      " 78  wSv_1_av    1177 non-null   float64 \n",
      " 79  wSdir_1_av  1177 non-null   float64 \n",
      " 80  CBH_m_av    611 non-null    float64 \n",
      " 81  HigCC_p_av  1177 non-null   float64 \n",
      " 82  LowCC_p_av  1177 non-null   float64 \n",
      " 83  MidCC_p_av  1177 non-null   float64 \n",
      " 84  TotCC_p_av  1177 non-null   float64 \n",
      " 85  Cape_av     1177 non-null   float64 \n",
      " 86  Cin_av      44 non-null     float64 \n",
      " 87  BLH_m_av    1177 non-null   float64 \n",
      " 88  BLH_m_rt    1065 non-null   float64 \n",
      " 89  LCL_hPa_av  1177 non-null   float64 \n",
      " 90  LCL_m_av    1177 non-null   float64 \n",
      " 91  LFC_hPa_av  689 non-null    float64 \n",
      " 92  CCL_hPa_av  1177 non-null   float64 \n",
      " 93  EL_m_av     134 non-null    float64 \n",
      " 94  LiftIdx_av  1177 non-null   float64 \n",
      " 95  VentIdx_av  1177 non-null   float64 \n",
      " 96  CMLG_av     1177 non-null   float64 \n",
      " 97  ros_p_lg1   823 non-null    float64 \n",
      " 98  f_start     1177 non-null   float64 \n",
      " 99  geometry    1177 non-null   geometry\n",
      "dtypes: float64(99), geometry(1)\n",
      "memory usage: 919.7 KB\n",
      "None\n",
      "\n",
      "Colunas disponíveis:\n",
      "['inidoy', 'enddoy', 'ros_p', 'duration_p', 'elev_av', 'aspect_av', 'landform', 'land_use', '1_3y_fir_p', '3_8y_fir_p', '8_ny_fir_p', 'fuel_model', 'f_load_av', 'sW_1m_av', 'sW_3m_av', 'sW_7_av', 'sW_28_av', 'sW_100_av', 'sW_289_av', 't_2m_C_av', 'd_2m_C_av', 'rh_2m_av', 'VPD_Pa_av', 'sP_hPa_av', 'gp_m2s2_av', 'dfmc_av', 'HDW_av', 'Haines_av', 'FWI_12h_av', 'DC_12h_av', 'FFMC_12h_a', 'wv10_kh_av', 'wdir10_av', 'wv100_k_av', 'wdir100_av', 'Recirc', 'CircVar', 't_950_av', 't_850_av', 't_700_av', 't_500_av', 't_300_av', 'rh_950_av', 'rh_850_av', 'rh_700_av', 'rh_500_av', 'rh_300_av', 'wv_950_av', 'wv_850_av', 'wv_700_av', 'wv_500_av', 'wv_300_av', 'wdi_950_av', 'wdi_850_av', 'wdi_700_av', 'wdi_500_av', 'wdi_300_av', 'vwv_950_av', 'vwv_850_av', 'vwv_700_av', 'vwv_500_av', 'vwv_300_av', 'gp_950_av', 'gp_850_av', 'gp_700_av', 'gp_500_av', 'gp_300_av', 'gT_s_9_av', 'gT_9_8_av', 'gT_8_7_av', 'gT_7_5_av', 'gT_5_3_av', 'wSv_9_av', 'wSdir_9_av', 'wSv_7_av', 'wSdir_7_av', 'wSv_5_av', 'wSdir_5_av', 'wSv_1_av', 'wSdir_1_av', 'CBH_m_av', 'HigCC_p_av', 'LowCC_p_av', 'MidCC_p_av', 'TotCC_p_av', 'Cape_av', 'Cin_av', 'BLH_m_av', 'BLH_m_rt', 'LCL_hPa_av', 'LCL_m_av', 'LFC_hPa_av', 'CCL_hPa_av', 'EL_m_av', 'LiftIdx_av', 'VentIdx_av', 'CMLG_av', 'ros_p_lg1', 'f_start', 'geometry']\n"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Carregar os dados\n",
    "gdf = gpd.read_file(\"..\\..\\Data\\Processed\\PT-FireSprd_v2.1\\L2_FireBehavior\\PT-FireProg_v2.1_L2_model.shp\")\n",
    "\n",
    "print(\"Primeiras linhas do dataset:\")\n",
    "print(gdf.head())\n",
    "print(\"\\nInformações do dataset:\")\n",
    "print(gdf.info())\n",
    "print(\"\\nColunas disponíveis:\")\n",
    "print(gdf.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "45127f62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Grupo com ros_p > 4000: 31 registros\n",
      "Grupo com ros_p <= 4000: 1142 registros\n",
      "\n",
      "Colunas para análise: ['inidoy', 'enddoy', 'duration_p', 'elev_av', 'aspect_av', 'landform', 'land_use', '1_3y_fir_p', '3_8y_fir_p', '8_ny_fir_p', 'fuel_model', 'f_load_av', 'sW_1m_av', 'sW_3m_av', 'sW_7_av', 'sW_28_av', 'sW_100_av', 'sW_289_av', 't_2m_C_av', 'd_2m_C_av', 'rh_2m_av', 'VPD_Pa_av', 'sP_hPa_av', 'gp_m2s2_av', 'dfmc_av', 'HDW_av', 'Haines_av', 'FWI_12h_av', 'DC_12h_av', 'FFMC_12h_a', 'wv10_kh_av', 'wdir10_av', 'wv100_k_av', 'wdir100_av', 'Recirc', 'CircVar', 't_950_av', 't_850_av', 't_700_av', 't_500_av', 't_300_av', 'rh_950_av', 'rh_850_av', 'rh_700_av', 'rh_500_av', 'rh_300_av', 'wv_950_av', 'wv_850_av', 'wv_700_av', 'wv_500_av', 'wv_300_av', 'wdi_950_av', 'wdi_850_av', 'wdi_700_av', 'wdi_500_av', 'wdi_300_av', 'vwv_950_av', 'vwv_850_av', 'vwv_700_av', 'vwv_500_av', 'vwv_300_av', 'gp_950_av', 'gp_850_av', 'gp_700_av', 'gp_500_av', 'gp_300_av', 'gT_s_9_av', 'gT_9_8_av', 'gT_8_7_av', 'gT_7_5_av', 'gT_5_3_av', 'wSv_9_av', 'wSdir_9_av', 'wSv_7_av', 'wSdir_7_av', 'wSv_5_av', 'wSdir_5_av', 'wSv_1_av', 'wSdir_1_av', 'CBH_m_av', 'HigCC_p_av', 'LowCC_p_av', 'MidCC_p_av', 'TotCC_p_av', 'Cape_av', 'Cin_av', 'BLH_m_av', 'BLH_m_rt', 'LCL_hPa_av', 'LCL_m_av', 'LFC_hPa_av', 'CCL_hPa_av', 'EL_m_av', 'LiftIdx_av', 'VentIdx_av', 'CMLG_av', 'ros_p_lg1', 'f_start']\n"
     ]
    }
   ],
   "source": [
    "# Separar os dados\n",
    "grupo_alto = gdf[gdf['ros_p'] > 4000]\n",
    "grupo_baixo = gdf[gdf['ros_p'] <= 4000]\n",
    "\n",
    "print(f\"\\nGrupo com ros_p > 4000: {len(grupo_alto)} registros\")\n",
    "print(f\"Grupo com ros_p <= 4000: {len(grupo_baixo)} registros\")\n",
    "\n",
    "# Identificar colunas numéricas para análise\n",
    "colunas_numericas = gdf.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "# Remover colunas que não são relevantes para análise (como coordenadas, IDs, etc)\n",
    "colunas_nao_relevantes = ['geometry', 'FID', 'OBJECTID', 'ID', 'id']\n",
    "colunas_analise = [col for col in colunas_numericas if col not in colunas_nao_relevantes and col != 'ros_p']\n",
    "\n",
    "print(f\"\\nColunas para análise: {colunas_analise}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3e63940b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparando dados para análise...\n",
      "\n",
      "Grupo com ros_p > 4000: 31 registros\n",
      "Grupo com ros_p <= 4000: 1142 registros\n",
      "\n",
      "Colunas para análise: 98\n",
      "\n",
      "==================================================\n",
      "REALIZANDO TESTES ESTATÍSTICOS\n",
      "==================================================\n",
      "Testes estatísticos concluídos!\n",
      "\n",
      "================================================================================\n",
      "CRIANDO RESUMO E VISUALIZAÇÕES\n",
      "================================================================================\n",
      "RESUMO DAS VARIÁVEIS MAIS IMPORTANTES (SIGNIFICATIVAS)\n",
      "================================================================================\n",
      "\n",
      "Variáveis com diferenças estatisticamente significativas (p < 0.05): 30\n",
      "\n",
      "Top 20 variáveis mais importantes:\n",
      "  Variável  Grupo Alto (média)  Grupo Baixo (média)  Diferença  p-valor\n",
      "VentIdx_av          17869.7895           11633.1862  6236.6033   0.0001\n",
      " ros_p_lg1           3798.2709             908.8775  2889.3934   0.0000\n",
      "gp_m2s2_av           2896.0432            4688.2720 -1792.2287   0.0000\n",
      "  CBH_m_av           5943.6446            4559.6106  1384.0341   0.0079\n",
      "   f_start            498.3871            1620.4947 -1122.1076   0.0123\n",
      " gp_300_av          93416.5934           94185.9429  -769.3495   0.0000\n",
      " gp_500_av          57167.4253           57552.8093  -385.3841   0.0000\n",
      "  wSv_9_av            280.0339             -61.1009   341.1349   0.0000\n",
      " DC_12h_av            937.9920             693.2993   244.6926   0.0000\n",
      "   elev_av            267.6329             498.6020  -230.9691   0.0000\n",
      " gp_950_av           5789.0796            5684.9099   104.1697   0.0087\n",
      " aspect_av            271.5563             193.4758    78.0806   0.0000\n",
      "CCL_hPa_av            659.6433             733.8761   -74.2328   0.0036\n",
      "   Cape_av             22.8568              94.2382   -71.3814   0.0007\n",
      " gp_850_av          15246.3131           15175.0316    71.2815   0.0132\n",
      "  wSv_1_av            132.0021              68.8785    63.1236   0.0000\n",
      " gp_700_av          31173.9055           31232.4651   -58.5596   0.0348\n",
      "    inidoy            275.5457             226.0124    49.5333   0.0000\n",
      "    enddoy            275.5905             226.1692    49.4213   0.0000\n",
      "wdi_500_av            175.4975             206.1833   -30.6859   0.0001\n",
      "\n",
      "================================================================================\n",
      "CRIANDO VISUALIZAÇÕES\n",
      "================================================================================\n",
      "\n",
      "1. Gráfico de TODAS as variáveis — primeiro significativas, depois não significativas\n",
      "\n",
      "PDF guardado como: ..\\..\\Data\\Data_Exploration\\variaveis_diferentes_4000_ros.pdf\n",
      "\n",
      "================================================================================\n",
      "RESUMO FINAL DA ANÁLISE\n",
      "================================================================================\n",
      "\n",
      "1. AMOSTRAS:\n",
      "   • Grupo Alto (ros_p > 4000): 31 registros\n",
      "   • Grupo Baixo (ros_p ≤ 4000): 1142 registros\n",
      "\n",
      "2. SIGNIFICÂNCIA ESTATÍSTICA:\n",
      "   • Variáveis analisadas: 98\n",
      "   • Variáveis significativas (p < 0.05): 30\n",
      "   • Taxa de significância: 30.6%\n",
      "\n",
      "3. TOP 10 VARIÁVEIS COM MAIOR IMPACTO:\n",
      "    1. VentIdx_av           → MAIOR no grupo alto (Δ = 6236.60, p = 0.0001)\n",
      "    2. ros_p_lg1            → MAIOR no grupo alto (Δ = 2889.39, p = 0.0000)\n",
      "    3. gp_m2s2_av           → MENOR no grupo alto (Δ = -1792.23, p = 0.0000)\n",
      "    4. CBH_m_av             → MAIOR no grupo alto (Δ = 1384.03, p = 0.0079)\n",
      "    5. f_start              → MENOR no grupo alto (Δ = -1122.11, p = 0.0123)\n",
      "    6. gp_300_av            → MENOR no grupo alto (Δ = -769.35, p = 0.0000)\n",
      "    7. gp_500_av            → MENOR no grupo alto (Δ = -385.38, p = 0.0000)\n",
      "    8. wSv_9_av             → MAIOR no grupo alto (Δ =  341.13, p = 0.0000)\n",
      "    9. DC_12h_av            → MAIOR no grupo alto (Δ =  244.69, p = 0.0000)\n",
      "   10. elev_av              → MENOR no grupo alto (Δ = -230.97, p = 0.0000)\n",
      "\n",
      "4. PADRÕES PRINCIPAIS IDENTIFICADOS:\n",
      "   • VENTOS FORTES: wv_950_av, wv_850_av, wv_700_av\n",
      "   • CONDIÇÕES SECAS: rh_700_av\n",
      "   • ÍNDICES FOGO ALTOS: FWI_12h_av, DC_12h_av, VentIdx_av\n",
      "   • ÉPOCA TARDIA: inidoy, enddoy\n",
      "   • MENOR ELEVAÇÃO: elev_av\n",
      "\n",
      "================================================================================\n",
      "ANÁLISE CONCLUÍDA!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "# Primeiro, vamos garantir que temos os dados carregados corretamente\n",
    "print(\"Preparando dados para análise...\")\n",
    "\n",
    "# Separar os dados\n",
    "grupo_alto = gdf[gdf['ros_p'] > 4000]\n",
    "grupo_baixo = gdf[gdf['ros_p'] <= 4000]\n",
    "\n",
    "print(f\"\\nGrupo com ros_p > 4000: {len(grupo_alto)} registros\")\n",
    "print(f\"Grupo com ros_p <= 4000: {len(grupo_baixo)} registros\")\n",
    "\n",
    "# Identificar colunas numéricas para análise\n",
    "colunas_numericas = gdf.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "# Remover colunas que não são relevantes para análise (como coordenadas, IDs, etc)\n",
    "colunas_nao_relevantes = ['geometry', 'FID', 'OBJECTID', 'ID', 'id']\n",
    "colunas_analise = [col for col in colunas_numericas if col not in colunas_nao_relevantes and col != 'ros_p']\n",
    "\n",
    "print(f\"\\nColunas para análise: {len(colunas_analise)}\")\n",
    "\n",
    "# REALIZAR OS TESTES ESTATÍSTICOS PRIMEIRO\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"REALIZANDO TESTES ESTATÍSTICOS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "resultados_teste = []\n",
    "\n",
    "for coluna in colunas_analise:\n",
    "    try:\n",
    "        # Remover valores NaN\n",
    "        dados_alto = grupo_alto[coluna].dropna()\n",
    "        dados_baixo = grupo_baixo[coluna].dropna()\n",
    "        \n",
    "        if len(dados_alto) < 3 or len(dados_baixo) < 3:\n",
    "            resultados_teste.append({\n",
    "                'Variável': coluna,\n",
    "                'Teste': 'Não aplicável',\n",
    "                'Estatística': np.nan,\n",
    "                'p-valor': np.nan,\n",
    "                'Significativo': False\n",
    "            })\n",
    "            continue\n",
    "            \n",
    "        # Teste de normalidade (Shapiro-Wilk)\n",
    "        try:\n",
    "            _, p_alto = stats.shapiro(dados_alto)\n",
    "            _, p_baixo = stats.shapiro(dados_baixo)\n",
    "            \n",
    "            normal_alto = p_alto > 0.05\n",
    "            normal_baixo = p_baixo > 0.05\n",
    "            \n",
    "            # Escolher teste baseado na normalidade\n",
    "            if normal_alto and normal_baixo:\n",
    "                # Teste t para amostras independentes\n",
    "                estatistica, p_valor = stats.ttest_ind(dados_alto, dados_baixo, equal_var=False)\n",
    "                teste_usado = \"Teste t (Welch)\"\n",
    "            else:\n",
    "                # Teste de Mann-Whitney U (não paramétrico)\n",
    "                estatistica, p_valor = stats.mannwhitneyu(dados_alto, dados_baixo)\n",
    "                teste_usado = \"Mann-Whitney U\"\n",
    "                \n",
    "        except:\n",
    "            # Se houver erro no teste paramétrico, usar não paramétrico\n",
    "            estatistica, p_valor = stats.mannwhitneyu(dados_alto, dados_baixo)\n",
    "            teste_usado = \"Mann-Whitney U\"\n",
    "        \n",
    "        resultados_teste.append({\n",
    "            'Variável': coluna,\n",
    "            'Teste': teste_usado,\n",
    "            'Estatística': estatistica,\n",
    "            'p-valor': p_valor,\n",
    "            'Significativo': p_valor < 0.05\n",
    "        })\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Erro na variável {coluna}: {e}\")\n",
    "        resultados_teste.append({\n",
    "            'Variável': coluna,\n",
    "            'Teste': 'Erro',\n",
    "            'Estatística': np.nan,\n",
    "            'p-valor': np.nan,\n",
    "            'Significativo': False\n",
    "        })\n",
    "\n",
    "print(\"Testes estatísticos concluídos!\")\n",
    "\n",
    "# AGORA CRIAR O RESUMO E OS GRÁFICOS\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CRIANDO RESUMO E VISUALIZAÇÕES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Criar DataFrame com resultados\n",
    "resultados = []\n",
    "for coluna in colunas_analise:\n",
    "    # Encontrar os resultados correspondentes\n",
    "    for resultado in resultados_teste:\n",
    "        if resultado['Variável'] == coluna:\n",
    "            try:\n",
    "                resultados.append({\n",
    "                    'Variável': coluna,\n",
    "                    'Grupo Alto (média)': grupo_alto[coluna].mean(),\n",
    "                    'Grupo Baixo (média)': grupo_baixo[coluna].mean(),\n",
    "                    'Diferença': grupo_alto[coluna].mean() - grupo_baixo[coluna].mean(),\n",
    "                    'p-valor': resultado['p-valor'],\n",
    "                    'Significativo': resultado['Significativo'],\n",
    "                    'Teste': resultado['Teste']\n",
    "                })\n",
    "            except:\n",
    "                continue\n",
    "            break\n",
    "\n",
    "df_resumo = pd.DataFrame(resultados)\n",
    "\n",
    "# Ordenar por significância e magnitude da diferença\n",
    "df_resumo['abs_diferenca'] = abs(df_resumo['Diferença'])\n",
    "df_resumo = df_resumo.sort_values(['Significativo', 'abs_diferenca'], ascending=[False, False])\n",
    "\n",
    "print(\"RESUMO DAS VARIÁVEIS MAIS IMPORTANTES (SIGNIFICATIVAS)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Filtrar apenas variáveis significativas\n",
    "df_significativas = df_resumo[df_resumo['Significativo'] == True].head(30)\n",
    "\n",
    "print(f\"\\nVariáveis com diferenças estatisticamente significativas (p < 0.05): {len(df_significativas)}\")\n",
    "print(\"\\nTop 20 variáveis mais importantes:\")\n",
    "print(df_significativas[['Variável', 'Grupo Alto (média)', 'Grupo Baixo (média)', 'Diferença', 'p-valor']].head(20).round(4).to_string(index=False))\n",
    "\n",
    "# VISUALIZAÇÕES PRINCIPAIS\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CRIANDO VISUALIZAÇÕES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"\\n1. Gráfico de TODAS as variáveis — primeiro significativas, depois não significativas\")\n",
    "\n",
    "# Criar PDF para guardar os gráficos\n",
    "pdf_path = r'..\\..\\Data\\Data_Exploration\\variaveis_diferentes_4000_ros.pdf'\n",
    "pdf = PdfPages(pdf_path)\n",
    "\n",
    "# Separar variáveis significativas e não significativas\n",
    "df_signif = df_resumo[df_resumo['Significativo'] == True].sort_values('abs_diferenca', ascending=False)\n",
    "df_nsignif = df_resumo[df_resumo['Significativo'] == False].sort_values('abs_diferenca', ascending=False)\n",
    "\n",
    "df_plot = pd.concat([df_signif, df_nsignif], axis=0)\n",
    "\n",
    "n = len(df_plot)\n",
    "cols = 4\n",
    "rows = (n // cols) + (1 if n % cols != 0 else 0)\n",
    "\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(20, 5*rows))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i, (idx, row) in enumerate(df_plot.iterrows()):\n",
    "    var = row['Variável']\n",
    "\n",
    "    try:\n",
    "        dados_alto_clean = grupo_alto[var].dropna()\n",
    "        dados_baixo_clean = grupo_baixo[var].dropna()\n",
    "\n",
    "        dados = pd.DataFrame({\n",
    "            'Valor': pd.concat([dados_alto_clean, dados_baixo_clean]),\n",
    "            'Grupo': ['ros_p > 4000'] * len(dados_alto_clean) + ['ros_p ≤ 4000'] * len(dados_baixo_clean)\n",
    "        })\n",
    "\n",
    "        sns.boxplot(\n",
    "            x='Grupo',\n",
    "            y='Valor',\n",
    "            data=dados,\n",
    "            ax=axes[i],\n",
    "            palette={'ros_p > 4000': 'red', 'ros_p ≤ 4000': 'blue'}\n",
    "        )\n",
    "\n",
    "        titulo = (\n",
    "            f\"{var}\\n(p = {row['p-valor']:.4f}) ★\"\n",
    "            if row['Significativo'] else\n",
    "            f\"{var}\\n(p = {row['p-valor']:.4f})\"\n",
    "        )\n",
    "\n",
    "        axes[i].set_title(titulo, fontsize=10)\n",
    "        axes[i].tick_params(axis='x', rotation=45)\n",
    "        axes[i].grid(True, linestyle='--', alpha=0.5)\n",
    "\n",
    "        diff = row['Diferença']\n",
    "        axes[i].text(\n",
    "            0.5, 0.95, f'Δ = {diff:.2f}',\n",
    "            transform=axes[i].transAxes, ha='center',\n",
    "            bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"yellow\", alpha=0.7),\n",
    "            fontsize=8\n",
    "        )\n",
    "\n",
    "    except Exception as e:\n",
    "        axes[i].set_title(f'Erro: {var}')\n",
    "        print(f\"Erro no plot de {var}: {e}\")\n",
    "\n",
    "# Remover eixos vazios\n",
    "for j in range(i+1, len(axes)):\n",
    "    fig.delaxes(axes[j])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle(\n",
    "    'TODAS AS VARIÁVEIS — Significativas (★) primeiro, depois não significativas',\n",
    "    fontsize=18, y=1.02\n",
    ")\n",
    "\n",
    "# Salvar esta figura no PDF\n",
    "pdf.savefig(fig)\n",
    "plt.close(fig)\n",
    "\n",
    "# Fechar PDF\n",
    "pdf.close()\n",
    "print(f\"\\nPDF guardado como: {pdf_path}\")\n",
    "\n",
    "\n",
    "\n",
    "# 4. RESUMO FINAL\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RESUMO FINAL DA ANÁLISE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\n1. AMOSTRAS:\")\n",
    "print(f\"   • Grupo Alto (ros_p > 4000): {len(grupo_alto)} registros\")\n",
    "print(f\"   • Grupo Baixo (ros_p ≤ 4000): {len(grupo_baixo)} registros\")\n",
    "\n",
    "print(f\"\\n2. SIGNIFICÂNCIA ESTATÍSTICA:\")\n",
    "print(f\"   • Variáveis analisadas: {len(colunas_analise)}\")\n",
    "print(f\"   • Variáveis significativas (p < 0.05): {len(df_significativas)}\")\n",
    "print(f\"   • Taxa de significância: {len(df_significativas)/len(colunas_analise)*100:.1f}%\")\n",
    "\n",
    "# Top 10 variáveis por magnitude do efeito\n",
    "print(f\"\\n3. TOP 10 VARIÁVEIS COM MAIOR IMPACTO:\")\n",
    "top_10_efeito = df_significativas.nlargest(10, 'abs_diferenca')\n",
    "for i, (idx, row) in enumerate(top_10_efeito.iterrows(), 1):\n",
    "    direcao = \"MAIOR\" if row['Diferença'] > 0 else \"MENOR\"\n",
    "    print(f\"   {i:2d}. {row['Variável']:20s} → {direcao} no grupo alto (Δ = {row['Diferença']:7.2f}, p = {row['p-valor']:.4f})\")\n",
    "\n",
    "# Padrões principais\n",
    "print(f\"\\n4. PADRÕES PRINCIPAIS IDENTIFICADOS:\")\n",
    "\n",
    "padroes = {\n",
    "    'VENTOS FORTES': ['wv100_k_av', 'wv10_kh_av', 'wv_950_av', 'wv_850_av', 'wv_700_av'],\n",
    "    'CONDIÇÕES SECAS': ['sW_1m_av', 'sW_3m_av', 'sW_7_av', 'rh_2m_av', 'rh_700_av'],\n",
    "    'ÍNDICES FOGO ALTOS': ['FWI_12h_av', 'DC_12h_av', 'VentIdx_av'],\n",
    "    'ÉPOCA TARDIA': ['inidoy', 'enddoy'],\n",
    "    'DURAÇÃO CURTA': ['duration_p'],\n",
    "    'MENOR ELEVAÇÃO': ['elev_av']\n",
    "}\n",
    "\n",
    "for padrao, variaveis in padroes.items():\n",
    "    vars_encontradas = [v for v in variaveis if v in df_significativas['Variável'].values]\n",
    "    if vars_encontradas:\n",
    "        print(f\"   • {padrao}: {', '.join(vars_encontradas)}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ANÁLISE CONCLUÍDA!\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e8409a35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================================================\n",
      "TABELA RESUMO - VARIÁVEIS SIGNIFICATIVAS (p < 0.05)\n",
      "====================================================================================================\n",
      "\n",
      "Total de variáveis significativas: 30\n",
      "\n",
      "Tabela ordenada por magnitude da diferença:\n",
      "  Variável  Grupo Alto (média)  Grupo Baixo (média)  Diferença  Diferença Relativa (%)  Efeito  p-valor\n",
      "VentIdx_av           17869.790            11633.186   6236.603                   53.61 ↑ MAIOR   0.0001\n",
      " ros_p_lg1            3798.271              908.878   2889.393                  317.91 ↑ MAIOR   0.0000\n",
      "gp_m2s2_av            2896.043             4688.272  -1792.229                  -38.23 ↓ MENOR   0.0000\n",
      "  CBH_m_av            5943.645             4559.611   1384.034                   30.35 ↑ MAIOR   0.0079\n",
      "   f_start             498.387             1620.495  -1122.108                  -69.24 ↓ MENOR   0.0123\n",
      " gp_300_av           93416.593            94185.943   -769.350                   -0.82 ↓ MENOR   0.0000\n",
      " gp_500_av           57167.425            57552.809   -385.384                   -0.67 ↓ MENOR   0.0000\n",
      "  wSv_9_av             280.034              -61.101    341.135                 -558.31 ↑ MAIOR   0.0000\n",
      " DC_12h_av             937.992              693.299    244.693                   35.29 ↑ MAIOR   0.0000\n",
      "   elev_av             267.633              498.602   -230.969                  -46.32 ↓ MENOR   0.0000\n",
      " gp_950_av            5789.080             5684.910    104.170                    1.83 ↑ MAIOR   0.0087\n",
      " aspect_av             271.556              193.476     78.081                   40.36 ↑ MAIOR   0.0000\n",
      "CCL_hPa_av             659.643              733.876    -74.233                  -10.12 ↓ MENOR   0.0036\n",
      "   Cape_av              22.857               94.238    -71.381                  -75.75 ↓ MENOR   0.0007\n",
      " gp_850_av           15246.313            15175.032     71.281                    0.47 ↑ MAIOR   0.0132\n",
      "  wSv_1_av             132.002               68.879     63.124                   91.64 ↑ MAIOR   0.0000\n",
      " gp_700_av           31173.906            31232.465    -58.560                   -0.19 ↓ MENOR   0.0348\n",
      "    inidoy             275.546              226.012     49.533                   21.92 ↑ MAIOR   0.0000\n",
      "    enddoy             275.591              226.169     49.421                   21.85 ↑ MAIOR   0.0000\n",
      "wdi_500_av             175.497              206.183    -30.686                  -14.88 ↓ MENOR   0.0001\n",
      " wv_850_av              45.913               22.818     23.096                  101.22 ↑ MAIOR   0.0000\n",
      " sP_hPa_av             981.941              962.815     19.126                    1.99 ↑ MAIOR   0.0000\n",
      " wv_700_av              49.611               30.968     18.644                   60.20 ↑ MAIOR   0.0000\n",
      "HigCC_p_av              45.163               26.873     18.291                   68.06 ↑ MAIOR   0.0014\n",
      " rh_500_av              51.438               33.884     17.554                   51.81 ↑ MAIOR   0.0001\n",
      "TotCC_p_av              46.233               29.818     16.415                   55.05 ↑ MAIOR   0.0123\n",
      " wv_950_av              34.480               18.337     16.143                   88.04 ↑ MAIOR   0.0000\n",
      " rh_700_av              51.382               36.068     15.314                   42.46 ↑ MAIOR   0.0000\n",
      " wv_500_av              51.036               38.142     12.894                   33.80 ↑ MAIOR   0.0000\n",
      "FWI_12h_av              58.874               47.367     11.507                   24.29 ↑ MAIOR   0.0000\n",
      "\n",
      "Tabela salva como 'variaveis_significativas_ros_p.csv'\n"
     ]
    }
   ],
   "source": [
    "# TABELA RESUMO COMPACTA\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"TABELA RESUMO - VARIÁVEIS SIGNIFICATIVAS (p < 0.05)\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "# Criar tabela compacta\n",
    "tabela_compacta = df_significativas[['Variável', 'Grupo Alto (média)', 'Grupo Baixo (média)', \n",
    "                                     'Diferença', 'p-valor']].copy()\n",
    "\n",
    "# Direção do efeito\n",
    "tabela_compacta['Efeito'] = tabela_compacta['Diferença'].apply(\n",
    "    lambda x: '↑ MAIOR' if x > 0 else '↓ MENOR'\n",
    ")\n",
    "\n",
    "# Diferença relativa (%)\n",
    "tabela_compacta['Diferença Relativa (%)'] = (\n",
    "    (tabela_compacta['Grupo Alto (média)'] - tabela_compacta['Grupo Baixo (média)']) /\n",
    "     tabela_compacta['Grupo Baixo (média)']\n",
    ") * 100\n",
    "\n",
    "# Formatar números\n",
    "for col in ['Grupo Alto (média)', 'Grupo Baixo (média)', 'Diferença']:\n",
    "    tabela_compacta[col] = tabela_compacta[col].round(3)\n",
    "\n",
    "tabela_compacta['Diferença Relativa (%)'] = tabela_compacta['Diferença Relativa (%)'].round(2)\n",
    "tabela_compacta['p-valor'] = tabela_compacta['p-valor'].round(4)\n",
    "\n",
    "# ✔ Reordenar colunas: Diferença e Diferença Relativa lado a lado\n",
    "tabela_compacta = tabela_compacta[\n",
    "    ['Variável',\n",
    "     'Grupo Alto (média)', \n",
    "     'Grupo Baixo (média)',\n",
    "     'Diferença',\n",
    "     'Diferença Relativa (%)',\n",
    "     'Efeito',\n",
    "     'p-valor']\n",
    "]\n",
    "\n",
    "print(f\"\\nTotal de variáveis significativas: {len(tabela_compacta)}\")\n",
    "\n",
    "print(\"\\nTabela ordenada por magnitude da diferença:\")\n",
    "print(\n",
    "    tabela_compacta.to_string(index=False, max_colwidth=30)\n",
    ")\n",
    "\n",
    "# Salvar CSV\n",
    "tabela_compacta.to_csv(r'..\\..\\Data\\Data_Exploration\\variaveis_significativas_ros_p_4000.csv', index=False, encoding='utf-8-sig')\n",
    "print(f\"\\nTabela salva como 'variaveis_significativas_ros_p.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c774f66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### AGORA PARA 2000M/H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6915b706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Grupo com ros_p > 2000: 132 registros\n",
      "Grupo com ros_p <= 2000: 1041 registros\n",
      "\n",
      "Colunas para análise: ['inidoy', 'enddoy', 'duration_p', 'elev_av', 'aspect_av', 'landform', 'land_use', '1_3y_fir_p', '3_8y_fir_p', '8_ny_fir_p', 'fuel_model', 'f_load_av', 'sW_1m_av', 'sW_3m_av', 'sW_7_av', 'sW_28_av', 'sW_100_av', 'sW_289_av', 't_2m_C_av', 'd_2m_C_av', 'rh_2m_av', 'VPD_Pa_av', 'sP_hPa_av', 'gp_m2s2_av', 'dfmc_av', 'HDW_av', 'Haines_av', 'FWI_12h_av', 'DC_12h_av', 'FFMC_12h_a', 'wv10_kh_av', 'wdir10_av', 'wv100_k_av', 'wdir100_av', 'Recirc', 'CircVar', 't_950_av', 't_850_av', 't_700_av', 't_500_av', 't_300_av', 'rh_950_av', 'rh_850_av', 'rh_700_av', 'rh_500_av', 'rh_300_av', 'wv_950_av', 'wv_850_av', 'wv_700_av', 'wv_500_av', 'wv_300_av', 'wdi_950_av', 'wdi_850_av', 'wdi_700_av', 'wdi_500_av', 'wdi_300_av', 'vwv_950_av', 'vwv_850_av', 'vwv_700_av', 'vwv_500_av', 'vwv_300_av', 'gp_950_av', 'gp_850_av', 'gp_700_av', 'gp_500_av', 'gp_300_av', 'gT_s_9_av', 'gT_9_8_av', 'gT_8_7_av', 'gT_7_5_av', 'gT_5_3_av', 'wSv_9_av', 'wSdir_9_av', 'wSv_7_av', 'wSdir_7_av', 'wSv_5_av', 'wSdir_5_av', 'wSv_1_av', 'wSdir_1_av', 'CBH_m_av', 'HigCC_p_av', 'LowCC_p_av', 'MidCC_p_av', 'TotCC_p_av', 'Cape_av', 'Cin_av', 'BLH_m_av', 'BLH_m_rt', 'LCL_hPa_av', 'LCL_m_av', 'LFC_hPa_av', 'CCL_hPa_av', 'EL_m_av', 'LiftIdx_av', 'VentIdx_av', 'CMLG_av', 'ros_p_lg1', 'f_start']\n"
     ]
    }
   ],
   "source": [
    "# Separar os dados\n",
    "grupo_alto = gdf[gdf['ros_p'] > 2000]\n",
    "grupo_baixo = gdf[gdf['ros_p'] <= 2000]\n",
    "\n",
    "print(f\"\\nGrupo com ros_p > 2000: {len(grupo_alto)} registros\")\n",
    "print(f\"Grupo com ros_p <= 2000: {len(grupo_baixo)} registros\")\n",
    "\n",
    "# Identificar colunas numéricas para análise\n",
    "colunas_numericas = gdf.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "# Remover colunas que não são relevantes para análise (como coordenadas, IDs, etc)\n",
    "colunas_nao_relevantes = ['geometry', 'FID', 'OBJECTID', 'ID', 'id']\n",
    "colunas_analise = [col for col in colunas_numericas if col not in colunas_nao_relevantes and col != 'ros_p']\n",
    "\n",
    "print(f\"\\nColunas para análise: {colunas_analise}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "944395ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparando dados para análise...\n",
      "\n",
      "Grupo com ros_p > 2000: 132 registros\n",
      "Grupo com ros_p <= 2000: 1041 registros\n",
      "\n",
      "Colunas para análise: 98\n",
      "\n",
      "==================================================\n",
      "REALIZANDO TESTES ESTATÍSTICOS\n",
      "==================================================\n",
      "Testes estatísticos concluídos!\n",
      "\n",
      "================================================================================\n",
      "CRIANDO RESUMO E VISUALIZAÇÕES\n",
      "================================================================================\n",
      "RESUMO DAS VARIÁVEIS MAIS IMPORTANTES (SIGNIFICATIVAS)\n",
      "================================================================================\n",
      "\n",
      "Variáveis com diferenças estatisticamente significativas (p < 0.05): 30\n",
      "\n",
      "Top 20 variáveis mais importantes:\n",
      "  Variável  Grupo Alto (média)  Grupo Baixo (média)  Diferença  p-valor\n",
      "    HDW_av          39235.2030           25762.3231 13472.8799   0.0000\n",
      "VentIdx_av          14851.7973           11410.7828  3441.0145   0.0000\n",
      " ros_p_lg1           2861.4344             755.5641  2105.8703   0.0000\n",
      "gp_m2s2_av           3971.5785            4725.7786  -754.2001   0.0007\n",
      "   f_start            962.1970            1670.5524  -708.3554   0.0000\n",
      "  CBH_m_av           5136.8512            4532.2086   604.6426   0.0301\n",
      " VPD_Pa_av           2716.7144            2295.6867   421.0277   0.0007\n",
      " gp_300_av          93839.8598           94206.9161  -367.0564   0.0000\n",
      "  BLH_m_av           1032.3806             791.3701   241.0105   0.0077\n",
      "  wSv_9_av            125.7547             -74.6358   200.3905   0.0000\n",
      " DC_12h_av            876.2330             677.3898   198.8431   0.0000\n",
      " gp_500_av          57367.7167           57564.8029  -197.0863   0.0000\n",
      "   elev_av            412.7915             502.6048   -89.8133   0.0003\n",
      "   Cape_av             26.3546             100.7202   -74.3657   0.0000\n",
      " aspect_av            231.5059             190.9787    40.5272   0.0000\n",
      "LCL_hPa_av            731.3293             767.8460   -36.5167   0.0000\n",
      "  wSv_1_av            102.8548              66.4501    36.4047   0.0000\n",
      " gp_950_av           5717.5950            5683.8675    33.7275   0.0428\n",
      " gp_850_av          15205.4736           15173.2943    32.1794   0.0039\n",
      "    inidoy            255.0175             223.8096    31.2079   0.0000\n",
      "\n",
      "================================================================================\n",
      "CRIANDO VISUALIZAÇÕES\n",
      "================================================================================\n",
      "\n",
      "1. Gráfico de TODAS as variáveis — primeiro significativas, depois não significativas\n",
      "\n",
      "PDF guardado como: ..\\..\\Data\\Data_Exploration\\variaveis_diferentes_2000_ros.pdf\n",
      "\n",
      "================================================================================\n",
      "RESUMO FINAL DA ANÁLISE\n",
      "================================================================================\n",
      "\n",
      "1. AMOSTRAS:\n",
      "   • Grupo Alto (ros_p > 2000): 132 registros\n",
      "   • Grupo Baixo (ros_p ≤ 2000): 1041 registros\n",
      "\n",
      "2. SIGNIFICÂNCIA ESTATÍSTICA:\n",
      "   • Variáveis analisadas: 98\n",
      "   • Variáveis significativas (p < 0.05): 30\n",
      "   • Taxa de significância: 30.6%\n",
      "\n",
      "3. TOP 10 VARIÁVEIS COM MAIOR IMPACTO:\n",
      "    1. HDW_av               → MAIOR no grupo alto (Δ = 13472.88, p = 0.0000)\n",
      "    2. VentIdx_av           → MAIOR no grupo alto (Δ = 3441.01, p = 0.0000)\n",
      "    3. ros_p_lg1            → MAIOR no grupo alto (Δ = 2105.87, p = 0.0000)\n",
      "    4. gp_m2s2_av           → MENOR no grupo alto (Δ = -754.20, p = 0.0007)\n",
      "    5. f_start              → MENOR no grupo alto (Δ = -708.36, p = 0.0000)\n",
      "    6. CBH_m_av             → MAIOR no grupo alto (Δ =  604.64, p = 0.0301)\n",
      "    7. VPD_Pa_av            → MAIOR no grupo alto (Δ =  421.03, p = 0.0007)\n",
      "    8. gp_300_av            → MENOR no grupo alto (Δ = -367.06, p = 0.0000)\n",
      "    9. BLH_m_av             → MAIOR no grupo alto (Δ =  241.01, p = 0.0077)\n",
      "   10. wSv_9_av             → MAIOR no grupo alto (Δ =  200.39, p = 0.0000)\n",
      "\n",
      "4. PADRÕES PRINCIPAIS IDENTIFICADOS:\n",
      "   • VENTOS FORTES: wv_950_av, wv_850_av, wv_700_av\n",
      "   • ÍNDICES FOGO ALTOS: FWI_12h_av, DC_12h_av, VentIdx_av\n",
      "   • ÉPOCA TARDIA: inidoy, enddoy\n",
      "   • MENOR ELEVAÇÃO: elev_av\n",
      "\n",
      "================================================================================\n",
      "ANÁLISE CONCLUÍDA!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "# Primeiro, vamos garantir que temos os dados carregados corretamente\n",
    "print(\"Preparando dados para análise...\")\n",
    "\n",
    "# Separar os dados\n",
    "grupo_alto = gdf[gdf['ros_p'] > 2000]\n",
    "grupo_baixo = gdf[gdf['ros_p'] <= 2000]\n",
    "\n",
    "print(f\"\\nGrupo com ros_p > 2000: {len(grupo_alto)} registros\")\n",
    "print(f\"Grupo com ros_p <= 2000: {len(grupo_baixo)} registros\")\n",
    "\n",
    "# Identificar colunas numéricas para análise\n",
    "colunas_numericas = gdf.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "# Remover colunas que não são relevantes para análise (como coordenadas, IDs, etc)\n",
    "colunas_nao_relevantes = ['geometry', 'FID', 'OBJECTID', 'ID', 'id']\n",
    "colunas_analise = [col for col in colunas_numericas if col not in colunas_nao_relevantes and col != 'ros_p']\n",
    "\n",
    "print(f\"\\nColunas para análise: {len(colunas_analise)}\")\n",
    "\n",
    "# REALIZAR OS TESTES ESTATÍSTICOS PRIMEIRO\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"REALIZANDO TESTES ESTATÍSTICOS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "resultados_teste = []\n",
    "\n",
    "for coluna in colunas_analise:\n",
    "    try:\n",
    "        # Remover valores NaN\n",
    "        dados_alto = grupo_alto[coluna].dropna()\n",
    "        dados_baixo = grupo_baixo[coluna].dropna()\n",
    "        \n",
    "        if len(dados_alto) < 3 or len(dados_baixo) < 3:\n",
    "            resultados_teste.append({\n",
    "                'Variável': coluna,\n",
    "                'Teste': 'Não aplicável',\n",
    "                'Estatística': np.nan,\n",
    "                'p-valor': np.nan,\n",
    "                'Significativo': False\n",
    "            })\n",
    "            continue\n",
    "            \n",
    "        # Teste de normalidade (Shapiro-Wilk)\n",
    "        try:\n",
    "            _, p_alto = stats.shapiro(dados_alto)\n",
    "            _, p_baixo = stats.shapiro(dados_baixo)\n",
    "            \n",
    "            normal_alto = p_alto > 0.05\n",
    "            normal_baixo = p_baixo > 0.05\n",
    "            \n",
    "            # Escolher teste baseado na normalidade\n",
    "            if normal_alto and normal_baixo:\n",
    "                # Teste t para amostras independentes\n",
    "                estatistica, p_valor = stats.ttest_ind(dados_alto, dados_baixo, equal_var=False)\n",
    "                teste_usado = \"Teste t (Welch)\"\n",
    "            else:\n",
    "                # Teste de Mann-Whitney U (não paramétrico)\n",
    "                estatistica, p_valor = stats.mannwhitneyu(dados_alto, dados_baixo)\n",
    "                teste_usado = \"Mann-Whitney U\"\n",
    "                \n",
    "        except:\n",
    "            # Se houver erro no teste paramétrico, usar não paramétrico\n",
    "            estatistica, p_valor = stats.mannwhitneyu(dados_alto, dados_baixo)\n",
    "            teste_usado = \"Mann-Whitney U\"\n",
    "        \n",
    "        resultados_teste.append({\n",
    "            'Variável': coluna,\n",
    "            'Teste': teste_usado,\n",
    "            'Estatística': estatistica,\n",
    "            'p-valor': p_valor,\n",
    "            'Significativo': p_valor < 0.05\n",
    "        })\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Erro na variável {coluna}: {e}\")\n",
    "        resultados_teste.append({\n",
    "            'Variável': coluna,\n",
    "            'Teste': 'Erro',\n",
    "            'Estatística': np.nan,\n",
    "            'p-valor': np.nan,\n",
    "            'Significativo': False\n",
    "        })\n",
    "\n",
    "print(\"Testes estatísticos concluídos!\")\n",
    "\n",
    "# AGORA CRIAR O RESUMO E OS GRÁFICOS\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CRIANDO RESUMO E VISUALIZAÇÕES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Criar DataFrame com resultados\n",
    "resultados = []\n",
    "for coluna in colunas_analise:\n",
    "    # Encontrar os resultados correspondentes\n",
    "    for resultado in resultados_teste:\n",
    "        if resultado['Variável'] == coluna:\n",
    "            try:\n",
    "                resultados.append({\n",
    "                    'Variável': coluna,\n",
    "                    'Grupo Alto (média)': grupo_alto[coluna].mean(),\n",
    "                    'Grupo Baixo (média)': grupo_baixo[coluna].mean(),\n",
    "                    'Diferença': grupo_alto[coluna].mean() - grupo_baixo[coluna].mean(),\n",
    "                    'p-valor': resultado['p-valor'],\n",
    "                    'Significativo': resultado['Significativo'],\n",
    "                    'Teste': resultado['Teste']\n",
    "                })\n",
    "            except:\n",
    "                continue\n",
    "            break\n",
    "\n",
    "df_resumo = pd.DataFrame(resultados)\n",
    "\n",
    "# Ordenar por significância e magnitude da diferença\n",
    "df_resumo['abs_diferenca'] = abs(df_resumo['Diferença'])\n",
    "df_resumo = df_resumo.sort_values(['Significativo', 'abs_diferenca'], ascending=[False, False])\n",
    "\n",
    "print(\"RESUMO DAS VARIÁVEIS MAIS IMPORTANTES (SIGNIFICATIVAS)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Filtrar apenas variáveis significativas\n",
    "df_significativas = df_resumo[df_resumo['Significativo'] == True].head(30)\n",
    "\n",
    "print(f\"\\nVariáveis com diferenças estatisticamente significativas (p < 0.05): {len(df_significativas)}\")\n",
    "print(\"\\nTop 20 variáveis mais importantes:\")\n",
    "print(df_significativas[['Variável', 'Grupo Alto (média)', 'Grupo Baixo (média)', 'Diferença', 'p-valor']].head(20).round(4).to_string(index=False))\n",
    "\n",
    "# VISUALIZAÇÕES PRINCIPAIS\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CRIANDO VISUALIZAÇÕES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"\\n1. Gráfico de TODAS as variáveis — primeiro significativas, depois não significativas\")\n",
    "\n",
    "# Criar PDF para guardar os gráficos\n",
    "pdf_path = r'..\\..\\Data\\Data_Exploration\\variaveis_diferentes_2000_ros.pdf'\n",
    "pdf = PdfPages(pdf_path)\n",
    "\n",
    "# Separar variáveis significativas e não significativas\n",
    "df_signif = df_resumo[df_resumo['Significativo'] == True].sort_values('abs_diferenca', ascending=False)\n",
    "df_nsignif = df_resumo[df_resumo['Significativo'] == False].sort_values('abs_diferenca', ascending=False)\n",
    "\n",
    "df_plot = pd.concat([df_signif, df_nsignif], axis=0)\n",
    "\n",
    "n = len(df_plot)\n",
    "cols = 4\n",
    "rows = (n // cols) + (1 if n % cols != 0 else 0)\n",
    "\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(20, 5*rows))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i, (idx, row) in enumerate(df_plot.iterrows()):\n",
    "    var = row['Variável']\n",
    "\n",
    "    try:\n",
    "        dados_alto_clean = grupo_alto[var].dropna()\n",
    "        dados_baixo_clean = grupo_baixo[var].dropna()\n",
    "\n",
    "        dados = pd.DataFrame({\n",
    "            'Valor': pd.concat([dados_alto_clean, dados_baixo_clean]),\n",
    "            'Grupo': ['ros_p > 2000'] * len(dados_alto_clean) + ['ros_p ≤ 2000'] * len(dados_baixo_clean)\n",
    "        })\n",
    "\n",
    "        sns.boxplot(\n",
    "            x='Grupo',\n",
    "            y='Valor',\n",
    "            data=dados,\n",
    "            ax=axes[i],\n",
    "            palette={'ros_p > 2000': 'red', 'ros_p ≤ 2000': 'blue'}\n",
    "        )\n",
    "\n",
    "        titulo = (\n",
    "            f\"{var}\\n(p = {row['p-valor']:.4f}) ★\"\n",
    "            if row['Significativo'] else\n",
    "            f\"{var}\\n(p = {row['p-valor']:.4f})\"\n",
    "        )\n",
    "\n",
    "        axes[i].set_title(titulo, fontsize=10)\n",
    "        axes[i].tick_params(axis='x', rotation=45)\n",
    "        axes[i].grid(True, linestyle='--', alpha=0.5)\n",
    "\n",
    "        diff = row['Diferença']\n",
    "        axes[i].text(\n",
    "            0.5, 0.95, f'Δ = {diff:.2f}',\n",
    "            transform=axes[i].transAxes, ha='center',\n",
    "            bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"yellow\", alpha=0.7),\n",
    "            fontsize=8\n",
    "        )\n",
    "\n",
    "    except Exception as e:\n",
    "        axes[i].set_title(f'Erro: {var}')\n",
    "        print(f\"Erro no plot de {var}: {e}\")\n",
    "\n",
    "# Remover eixos vazios\n",
    "for j in range(i+1, len(axes)):\n",
    "    fig.delaxes(axes[j])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle(\n",
    "    'TODAS AS VARIÁVEIS — Significativas (★) primeiro, depois não significativas',\n",
    "    fontsize=18, y=1.02\n",
    ")\n",
    "\n",
    "# Salvar esta figura no PDF\n",
    "pdf.savefig(fig)\n",
    "plt.close(fig)\n",
    "\n",
    "# Fechar PDF\n",
    "pdf.close()\n",
    "print(f\"\\nPDF guardado como: {pdf_path}\")\n",
    "\n",
    "\n",
    "\n",
    "# 4. RESUMO FINAL\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RESUMO FINAL DA ANÁLISE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\n1. AMOSTRAS:\")\n",
    "print(f\"   • Grupo Alto (ros_p > 2000): {len(grupo_alto)} registros\")\n",
    "print(f\"   • Grupo Baixo (ros_p ≤ 2000): {len(grupo_baixo)} registros\")\n",
    "\n",
    "print(f\"\\n2. SIGNIFICÂNCIA ESTATÍSTICA:\")\n",
    "print(f\"   • Variáveis analisadas: {len(colunas_analise)}\")\n",
    "print(f\"   • Variáveis significativas (p < 0.05): {len(df_significativas)}\")\n",
    "print(f\"   • Taxa de significância: {len(df_significativas)/len(colunas_analise)*100:.1f}%\")\n",
    "\n",
    "# Top 10 variáveis por magnitude do efeito\n",
    "print(f\"\\n3. TOP 10 VARIÁVEIS COM MAIOR IMPACTO:\")\n",
    "top_10_efeito = df_significativas.nlargest(10, 'abs_diferenca')\n",
    "for i, (idx, row) in enumerate(top_10_efeito.iterrows(), 1):\n",
    "    direcao = \"MAIOR\" if row['Diferença'] > 0 else \"MENOR\"\n",
    "    print(f\"   {i:2d}. {row['Variável']:20s} → {direcao} no grupo alto (Δ = {row['Diferença']:7.2f}, p = {row['p-valor']:.4f})\")\n",
    "\n",
    "# Padrões principais\n",
    "print(f\"\\n4. PADRÕES PRINCIPAIS IDENTIFICADOS:\")\n",
    "\n",
    "padroes = {\n",
    "    'VENTOS FORTES': ['wv100_k_av', 'wv10_kh_av', 'wv_950_av', 'wv_850_av', 'wv_700_av'],\n",
    "    'CONDIÇÕES SECAS': ['sW_1m_av', 'sW_3m_av', 'sW_7_av', 'rh_2m_av', 'rh_700_av'],\n",
    "    'ÍNDICES FOGO ALTOS': ['FWI_12h_av', 'DC_12h_av', 'VentIdx_av'],\n",
    "    'ÉPOCA TARDIA': ['inidoy', 'enddoy'],\n",
    "    'DURAÇÃO CURTA': ['duration_p'],\n",
    "    'MENOR ELEVAÇÃO': ['elev_av']\n",
    "}\n",
    "\n",
    "for padrao, variaveis in padroes.items():\n",
    "    vars_encontradas = [v for v in variaveis if v in df_significativas['Variável'].values]\n",
    "    if vars_encontradas:\n",
    "        print(f\"   • {padrao}: {', '.join(vars_encontradas)}\")\n",
    "        \n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ANÁLISE CONCLUÍDA!\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "97f483fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================================================\n",
      "TABELA RESUMO - VARIÁVEIS SIGNIFICATIVAS (p < 0.05)\n",
      "====================================================================================================\n",
      "\n",
      "Total de variáveis significativas: 30\n",
      "\n",
      "Tabela ordenada por magnitude da diferença:\n",
      "  Variável  Grupo Alto (média)  Grupo Baixo (média)  Diferença  Diferença Relativa (%)  Efeito  p-valor\n",
      "    HDW_av           39235.203            25762.323  13472.880                   52.30 ↑ MAIOR   0.0000\n",
      "VentIdx_av           14851.797            11410.783   3441.014                   30.16 ↑ MAIOR   0.0000\n",
      " ros_p_lg1            2861.434              755.564   2105.870                  278.71 ↑ MAIOR   0.0000\n",
      "gp_m2s2_av            3971.578             4725.779   -754.200                  -15.96 ↓ MENOR   0.0007\n",
      "   f_start             962.197             1670.552   -708.355                  -42.40 ↓ MENOR   0.0000\n",
      "  CBH_m_av            5136.851             4532.209    604.643                   13.34 ↑ MAIOR   0.0301\n",
      " VPD_Pa_av            2716.714             2295.687    421.028                   18.34 ↑ MAIOR   0.0007\n",
      " gp_300_av           93839.860            94206.916   -367.056                   -0.39 ↓ MENOR   0.0000\n",
      "  BLH_m_av            1032.381              791.370    241.011                   30.45 ↑ MAIOR   0.0077\n",
      "  wSv_9_av             125.755              -74.636    200.390                 -268.49 ↑ MAIOR   0.0000\n",
      " DC_12h_av             876.233              677.390    198.843                   29.35 ↑ MAIOR   0.0000\n",
      " gp_500_av           57367.717            57564.803   -197.086                   -0.34 ↓ MENOR   0.0000\n",
      "   elev_av             412.792              502.605    -89.813                  -17.87 ↓ MENOR   0.0003\n",
      "   Cape_av              26.355              100.720    -74.366                  -73.83 ↓ MENOR   0.0000\n",
      " aspect_av             231.506              190.979     40.527                   21.22 ↑ MAIOR   0.0000\n",
      "LCL_hPa_av             731.329              767.846    -36.517                   -4.76 ↓ MENOR   0.0000\n",
      "  wSv_1_av             102.855               66.450     36.405                   54.79 ↑ MAIOR   0.0000\n",
      " gp_950_av            5717.595             5683.868     33.727                    0.59 ↑ MAIOR   0.0428\n",
      " gp_850_av           15205.474            15173.294     32.179                    0.21 ↑ MAIOR   0.0039\n",
      "    inidoy             255.017              223.810     31.208                   13.94 ↑ MAIOR   0.0000\n",
      "    enddoy             255.071              223.976     31.095                   13.88 ↑ MAIOR   0.0000\n",
      "CCL_hPa_av             710.237              734.663    -24.426                   -3.32 ↓ MENOR   0.0128\n",
      "wdi_500_av             191.340              207.152    -15.811                   -7.63 ↓ MENOR   0.0000\n",
      " wv_850_av              36.460               21.775     14.685                   67.44 ↑ MAIOR   0.0000\n",
      "wdi_850_av             196.508              183.075     13.433                    7.34 ↑ MAIOR   0.0454\n",
      " wv_700_av              43.021               29.994     13.026                   43.43 ↑ MAIOR   0.0000\n",
      "wSdir_9_av               1.640              -10.351     11.990                 -115.84 ↑ MAIOR   0.0016\n",
      " wv_500_av              47.418               37.350     10.068                   26.96 ↑ MAIOR   0.0000\n",
      "FWI_12h_av              56.564               46.543     10.021                   21.53 ↑ MAIOR   0.0000\n",
      " wv_950_av              27.473               17.659      9.813                   55.57 ↑ MAIOR   0.0000\n",
      "\n",
      "Tabela salva como 'variaveis_significativas_ros_p.csv'\n"
     ]
    }
   ],
   "source": [
    "# TABELA RESUMO COMPACTA\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"TABELA RESUMO - VARIÁVEIS SIGNIFICATIVAS (p < 0.05)\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "# Criar tabela compacta\n",
    "tabela_compacta = df_significativas[['Variável', 'Grupo Alto (média)', 'Grupo Baixo (média)', \n",
    "                                     'Diferença', 'p-valor']].copy()\n",
    "\n",
    "# Direção do efeito\n",
    "tabela_compacta['Efeito'] = tabela_compacta['Diferença'].apply(\n",
    "    lambda x: '↑ MAIOR' if x > 0 else '↓ MENOR'\n",
    ")\n",
    "\n",
    "# Diferença relativa (%)\n",
    "tabela_compacta['Diferença Relativa (%)'] = (\n",
    "    (tabela_compacta['Grupo Alto (média)'] - tabela_compacta['Grupo Baixo (média)']) /\n",
    "     tabela_compacta['Grupo Baixo (média)']\n",
    ") * 100\n",
    "\n",
    "# Formatar números\n",
    "for col in ['Grupo Alto (média)', 'Grupo Baixo (média)', 'Diferença']:\n",
    "    tabela_compacta[col] = tabela_compacta[col].round(3)\n",
    "\n",
    "tabela_compacta['Diferença Relativa (%)'] = tabela_compacta['Diferença Relativa (%)'].round(2)\n",
    "tabela_compacta['p-valor'] = tabela_compacta['p-valor'].round(4)\n",
    "\n",
    "# ✔ Reordenar colunas: Diferença e Diferença Relativa lado a lado\n",
    "tabela_compacta = tabela_compacta[\n",
    "    ['Variável',\n",
    "     'Grupo Alto (média)', \n",
    "     'Grupo Baixo (média)',\n",
    "     'Diferença',\n",
    "     'Diferença Relativa (%)',\n",
    "     'Efeito',\n",
    "     'p-valor']\n",
    "]\n",
    "\n",
    "print(f\"\\nTotal de variáveis significativas: {len(tabela_compacta)}\")\n",
    "\n",
    "print(\"\\nTabela ordenada por magnitude da diferença:\")\n",
    "print(\n",
    "    tabela_compacta.to_string(index=False, max_colwidth=30)\n",
    ")\n",
    "\n",
    "# Salvar CSV\n",
    "tabela_compacta.to_csv(r'..\\..\\Data\\Data_Exploration\\variaveis_significativas_ros_p_2000.csv', index=False, encoding='utf-8-sig')\n",
    "print(f\"\\nTabela salva como 'variaveis_significativas_ros_p.csv'\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geoenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
