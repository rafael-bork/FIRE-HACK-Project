{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a37766f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully created ../../Data/Data_Exploration/all_ros_p_correlations.csv\n",
      "Total variables: 106\n",
      "Files processed: 4\n",
      "\n",
      "DataFrame structure:\n",
      "     variable  corr_ros_p_model  corr_ros_p_model_log  corr_ros_p_model_sqrt\n",
      "0  1_3y_fir_p         -0.041748              0.008214              -0.010580\n",
      "1  3_8y_fir_p          0.026505              0.132478               0.094862\n",
      "2  8_ny_fir_p         -0.051356              0.041549              -0.005699\n",
      "3    BLH_m_av          0.169148              0.248752               0.229735\n",
      "4    BLH_m_rt          0.050939              0.051698               0.043778\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# Define o path pattern para todos os CSVs\n",
    "path_pattern = '../../Data/Data_Exploration/descriptive_stats_*.csv'\n",
    "\n",
    "# Encontrar todos os CSVs\n",
    "csv_files = glob.glob(path_pattern)\n",
    "\n",
    "# Garantir que o CSV model_sqrt esteja incluído\n",
    "sqrt_file = '../../Data/Data_Exploration/descriptive_stats_PT-FireProg_v2.1_L2_model_sqrt.csv'\n",
    "if sqrt_file not in csv_files:\n",
    "    csv_files.append(sqrt_file)\n",
    "\n",
    "# Dicionário para armazenar as correlações por variável\n",
    "correlations_data = {}\n",
    "\n",
    "# Processar cada CSV\n",
    "for file_path in csv_files:\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "\n",
    "        if 'corr_ros_p' in df.columns:  # Usar corr_ros_p em vez de R2_ros_p\n",
    "            filename = os.path.basename(file_path).lower()\n",
    "            \n",
    "            # Determinar tipo de transformação\n",
    "            if 'model' in filename and 'log' in filename:\n",
    "                col_suffix = 'model_log'\n",
    "            elif 'model' in filename and 'sqrt' in filename:\n",
    "                col_suffix = 'model_sqrt'\n",
    "            elif 'model' in filename:\n",
    "                col_suffix = 'model'\n",
    "            else:\n",
    "                print(f\"Warning: Could not determine type for {filename}\")\n",
    "                continue\n",
    "\n",
    "            # Extrair nomes das variáveis e valores de corr_ros_p\n",
    "            for idx, row in df.iterrows():\n",
    "                if pd.notna(row['corr_ros_p']):\n",
    "                    variable_name = df.iloc[idx, 0]  # Primeira coluna tem os nomes das variáveis\n",
    "                    \n",
    "                    if variable_name not in correlations_data:\n",
    "                        correlations_data[variable_name] = {'variable': variable_name}\n",
    "                    \n",
    "                    correlations_data[variable_name][f'corr_ros_p_{col_suffix}'] = row['corr_ros_p']\n",
    "\n",
    "        else:\n",
    "            print(f\"Warning: corr_ros_p column not found in {file_path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {str(e)}\")\n",
    "\n",
    "# Criar DataFrame consolidado\n",
    "if correlations_data:\n",
    "    correlations_df = pd.DataFrame(correlations_data.values())\n",
    "\n",
    "    # Colunas desejadas\n",
    "    desired_columns = [\n",
    "        'variable',\n",
    "        'corr_ros_p_model',\n",
    "        'corr_ros_p_model_log',\n",
    "        'corr_ros_p_model_sqrt'\n",
    "    ]\n",
    "\n",
    "    # Adicionar colunas ausentes com NaN\n",
    "    for col in desired_columns:\n",
    "        if col not in correlations_df.columns:\n",
    "            correlations_df[col] = None\n",
    "\n",
    "    correlations_df = correlations_df[desired_columns]\n",
    "\n",
    "    # Salvar CSV final\n",
    "    output_file = '../../Data/Data_Exploration/all_ros_p_correlations.csv'\n",
    "    correlations_df.to_csv(output_file, index=False)\n",
    "\n",
    "    print(f\"Successfully created {output_file}\")\n",
    "    print(f\"Total variables: {len(correlations_df)}\")\n",
    "    print(f\"Files processed: {len(csv_files)}\")\n",
    "    print(f\"\\nDataFrame structure:\")\n",
    "    print(correlations_df.head())\n",
    "\n",
    "else:\n",
    "    print(\"No correlation data found in any of the files\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b002cf54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 15 |correlation| for corr_ros_p_model:\n",
      "       variable  corr_ros_p_model\n",
      "50    ros_p_lg1          0.593037\n",
      "52    ros_p_lg2          0.510589\n",
      "53    ros_p_lg3          0.488578\n",
      "54    ros_p_lg4          0.384327\n",
      "55    ros_p_lg5          0.329380\n",
      "93     wv100_av          0.325578\n",
      "100   wv_850_av          0.320757\n",
      "94   wv100_k_av          0.320109\n",
      "51   ros_p_lg10          0.306571\n",
      "56    ros_p_lg6          0.305461\n",
      "12       HDW_av          0.301808\n",
      "27   duration_p         -0.294387\n",
      "82     wSv_1_av          0.291103\n",
      "101   wv_950_av          0.287039\n",
      "57    ros_p_lg7          0.282740\n",
      "\n",
      "Top 15 |correlation| for corr_ros_p_model_sqrt:\n",
      "       variable  corr_ros_p_model_sqrt\n",
      "50    ros_p_lg1               0.597953\n",
      "52    ros_p_lg2               0.556599\n",
      "53    ros_p_lg3               0.513295\n",
      "54    ros_p_lg4               0.456006\n",
      "55    ros_p_lg5               0.387761\n",
      "56    ros_p_lg6               0.364889\n",
      "27   duration_p              -0.361356\n",
      "12       HDW_av               0.356880\n",
      "93     wv100_av               0.355211\n",
      "94   wv100_k_av               0.354899\n",
      "57    ros_p_lg7               0.339250\n",
      "58    ros_p_lg8               0.326651\n",
      "44     rh_2m_av              -0.320233\n",
      "51   ros_p_lg10               0.314495\n",
      "101   wv_950_av               0.310834\n",
      "\n",
      "Top 15 |correlation| for corr_ros_p_model_log:\n",
      "      variable  corr_ros_p_model_log\n",
      "50   ros_p_lg1              0.559746\n",
      "52   ros_p_lg2              0.529670\n",
      "53   ros_p_lg3              0.487521\n",
      "54   ros_p_lg4              0.425138\n",
      "27  duration_p             -0.406249\n",
      "55   ros_p_lg5              0.359646\n",
      "12      HDW_av              0.357132\n",
      "44    rh_2m_av             -0.344037\n",
      "94  wv100_k_av              0.342666\n",
      "26     dfmc_av             -0.338851\n",
      "93    wv100_av              0.336712\n",
      "56   ros_p_lg6              0.322469\n",
      "95     wv10_av              0.305994\n",
      "96  wv10_kh_av              0.302588\n",
      "8      Cape_av             -0.299278\n"
     ]
    }
   ],
   "source": [
    "# Calcular top 15 |correlation| para cada tipo de transformação\n",
    "top_n = 15\n",
    "\n",
    "for col in ['corr_ros_p_model', 'corr_ros_p_model_sqrt', 'corr_ros_p_model_log']:\n",
    "    if col in correlations_df.columns:\n",
    "        # Ordenar por valor absoluto decrescente\n",
    "        top_vars = correlations_df.reindex(\n",
    "            correlations_df[col].abs().sort_values(ascending=False).index\n",
    "        ).head(top_n)\n",
    "        \n",
    "        print(f\"\\nTop {top_n} |correlation| for {col}:\")\n",
    "        print(top_vars[['variable', col]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef04d0d6",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'R2_ros_p_model'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dias3\\miniconda3\\envs\\geoenv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3811\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7096\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'R2_ros_p_model'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      7\u001b[39m df = pd.read_csv(\u001b[33m'\u001b[39m\u001b[33m..\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[33m..\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[33mData\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[33mData_Exploration\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[33mall_ros_p_correlations.csv\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# Ordenando pelos maiores R² para cada modelo\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m top15_linear = \u001b[43mdf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnlargest\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m15\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mR2_ros_p_model\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m[[\u001b[33m'\u001b[39m\u001b[33mvariable\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mR2_ros_p_model\u001b[39m\u001b[33m'\u001b[39m]]\n\u001b[32m     11\u001b[39m top15_log = df.nlargest(\u001b[32m15\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mR2_ros_p_model_log\u001b[39m\u001b[33m'\u001b[39m)[[\u001b[33m'\u001b[39m\u001b[33mvariable\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mR2_ros_p_model_log\u001b[39m\u001b[33m'\u001b[39m]]\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# Juntando todos os candidatos únicos\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dias3\\miniconda3\\envs\\geoenv\\Lib\\site-packages\\pandas\\core\\frame.py:7666\u001b[39m, in \u001b[36mDataFrame.nlargest\u001b[39m\u001b[34m(self, n, columns, keep)\u001b[39m\n\u001b[32m   7547\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mnlargest\u001b[39m(\n\u001b[32m   7548\u001b[39m     \u001b[38;5;28mself\u001b[39m, n: \u001b[38;5;28mint\u001b[39m, columns: IndexLabel, keep: NsmallestNlargestKeep = \u001b[33m\"\u001b[39m\u001b[33mfirst\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   7549\u001b[39m ) -> DataFrame:\n\u001b[32m   7550\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   7551\u001b[39m \u001b[33;03m    Return the first `n` rows ordered by `columns` in descending order.\u001b[39;00m\n\u001b[32m   7552\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   7664\u001b[39m \u001b[33;03m    Brunei      434000    12128      BN\u001b[39;00m\n\u001b[32m   7665\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m7666\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mselectn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mSelectNFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeep\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkeep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnlargest\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dias3\\miniconda3\\envs\\geoenv\\Lib\\site-packages\\pandas\\core\\methods\\selectn.py:57\u001b[39m, in \u001b[36mSelectN.nlargest\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;129m@final\u001b[39m\n\u001b[32m     56\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mnlargest\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m57\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mnlargest\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dias3\\miniconda3\\envs\\geoenv\\Lib\\site-packages\\pandas\\core\\methods\\selectn.py:199\u001b[39m, in \u001b[36mSelectNFrame.compute\u001b[39m\u001b[34m(self, method)\u001b[39m\n\u001b[32m    196\u001b[39m columns = \u001b[38;5;28mself\u001b[39m.columns\n\u001b[32m    198\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m column \u001b[38;5;129;01min\u001b[39;00m columns:\n\u001b[32m--> \u001b[39m\u001b[32m199\u001b[39m     dtype = \u001b[43mframe\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcolumn\u001b[49m\u001b[43m]\u001b[49m.dtype\n\u001b[32m    200\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.is_valid_dtype_n_method(dtype):\n\u001b[32m    201\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m    202\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mColumn \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(column)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m has dtype \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    203\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mcannot use method \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(method)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m with this dtype\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    204\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dias3\\miniconda3\\envs\\geoenv\\Lib\\site-packages\\pandas\\core\\frame.py:4113\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4112\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4113\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4114\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4115\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dias3\\miniconda3\\envs\\geoenv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3819\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3814\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3815\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3816\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3817\u001b[39m     ):\n\u001b[32m   3818\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3819\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3820\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3821\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3822\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3823\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3824\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'R2_ros_p_model'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from adjustText import adjust_text\n",
    "\n",
    "# Lendo o arquivo CSV\n",
    "df = pd.read_csv('..\\\\..\\\\Data\\\\Data_Exploration\\\\all_ros_p_correlations.csv')\n",
    "\n",
    "# Ordenando pelos maiores R² para cada modelo\n",
    "top15_linear = df.nlargest(15, 'R2_ros_p_model')[['variable', 'R2_ros_p_model']]\n",
    "top15_log = df.nlargest(15, 'R2_ros_p_model_log')[['variable', 'R2_ros_p_model_log']]\n",
    "\n",
    "# Juntando todos os candidatos únicos\n",
    "all_top_vars = set(top15_linear['variable']).union(set(top15_log['variable']))\n",
    "comparison_data = df[df['variable'].isin(all_top_vars)]\n",
    "\n",
    "# Classificando os pontos\n",
    "comparison_data = comparison_data.copy()\n",
    "comparison_data['category'] = 'Other'\n",
    "comparison_data.loc[comparison_data['variable'].isin(top15_linear['variable']), 'category'] = 'Top Linear'\n",
    "comparison_data.loc[comparison_data['variable'].isin(top15_log['variable']), 'category'] = 'Top Log'\n",
    "comparison_data.loc[comparison_data['variable'].isin(top15_linear['variable']) & \n",
    "                   comparison_data['variable'].isin(top15_log['variable']), 'category'] = 'Top Both'\n",
    "\n",
    "# Criando scatter plot\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "# Definindo cores e marcadores para cada categoria\n",
    "colors = {'Top Linear': 'blue', 'Top Log': 'red', 'Top Both': 'purple', 'Other': 'gray'}\n",
    "markers = {'Top Linear': 'o', 'Top Log': 's', 'Top Both': 'D', 'Other': 'o'}\n",
    "sizes = {'Top Linear': 80, 'Top Log': 80, 'Top Both': 100, 'Other': 60}\n",
    "\n",
    "# Plotando cada categoria separadamente\n",
    "for category in ['Other', 'Top Linear', 'Top Log', 'Top Both']:\n",
    "    cat_data = comparison_data[comparison_data['category'] == category]\n",
    "    ax.scatter(cat_data['R2_ros_p_model'], \n",
    "               cat_data['R2_ros_p_model_log'], \n",
    "               alpha=0.8, s=sizes[category],\n",
    "               c=colors[category], marker=markers[category],\n",
    "               label=category, edgecolors='black', linewidth=0.5)\n",
    "\n",
    "# Linha de igualdade\n",
    "max_val = max(comparison_data[['R2_ros_p_model', 'R2_ros_p_model_log']].max().max(), 0.15)\n",
    "ax.plot([0, max_val], [0, max_val], 'k--', alpha=0.5, label='y = x')\n",
    "\n",
    "ax.set_xlabel('R² - Modelo Linear', fontsize=12, fontweight='bold')\n",
    "ax.set_ylabel('R² - Modelo Log', fontsize=12, fontweight='bold')\n",
    "ax.set_title('Comparação R²: Modelo Linear vs Log (Top 15 cada)', fontsize=14, fontweight='bold')\n",
    "ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "ax.grid(alpha=0.3)\n",
    "\n",
    "# SOLUÇÃO: Usar adjust_text sem arrowprops ou com configurações específicas\n",
    "texts = []\n",
    "for i, row in comparison_data.iterrows():\n",
    "    if row['category'] in ['Top Linear', 'Top Log', 'Top Both']:\n",
    "        text = ax.annotate(row['variable'], \n",
    "                          (row['R2_ros_p_model'], row['R2_ros_p_model_log']),\n",
    "                          fontsize=8,\n",
    "                          bbox=dict(boxstyle=\"round,pad=0.2\", facecolor='white', alpha=0.8, edgecolor='gray'))\n",
    "        texts.append(text)\n",
    "\n",
    "# Opção 1: Sem arrowprops (mais simples)\n",
    "adjust_text(texts,\n",
    "            expand_points=(1.5, 1.5),\n",
    "            expand_text=(1.2, 1.2), \n",
    "            force_points=0.5,\n",
    "            force_text=0.5,\n",
    "            lim=1000)\n",
    "\n",
    "plt.xlim(0, max_val + 0.02)\n",
    "plt.ylim(0, max_val + 0.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
