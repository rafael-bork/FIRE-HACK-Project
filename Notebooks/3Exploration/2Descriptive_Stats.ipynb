{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2634feaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "from scipy import stats\n",
    "from pathlib import Path\n",
    "\n",
    "# Configurações\n",
    "CATEGORICAL_VARIABLES = [\n",
    "    'burn_perio', 'land_use', 'zp_link', \n",
    "    'year', 'fuel_model', 'landform'\n",
    "]\n",
    "\n",
    "# Shapefile específico\n",
    "SHP_FILE = r'../../Data/Processed/PT-FireSprd_v3.0/L2_FireBehavior/PT-FireSprd_v3.0_L2_model.shp'\n",
    "\n",
    "# Diretório de saída\n",
    "OUTPUT_DIR = r'../../Data/Data_Exploration'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "aea697e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carregando shapefile: ../../Data/Processed/PT-FireSprd_v2.1/L2_FireBehavior/PT-FireProg_v2.1_L2_short.shp...\n",
      "Colunas: ['fid', 'fname', 'year', 'id', 'type', 'sdate', 'edate', 'inidoy', 'enddoy', 'source', 'zp_link', 'burn_perio', 'area', 'growth_rat', 'ros_i', 'ros_p', 'spdir_i', 'spdir_p', 'int_i', 'int_p', 'duration_i', 'duration_p', 'qc', 'elev_av', 'aspect_av', 'landform', 'land_use', 'land_use_d', '1_3y_fir_p', '3_8y_fir_p', '8_ny_fir_p', 'fuel_model', 'f_load_av', 'sW_1m_av', 'sW_3m_av', 'sW_7_av', 'sW_28_av', 'sW_100_av', 'sW_289_av', 't_2m_C_av', 'd_2m_C_av', 'rh_2m_av', 'VPD_Pa_av', 'sP_hPa_av', 'gp_m2s2_av', 'dfmc_av', 'HDW_av', 'Haines_av', 'FWI_12h_av', 'DC_12h_av', 'FFMC_12h_a', 'wv10_kh_av', 'wdir10_av', 'wv100_k_av', 'wdir100_av', 'Recirc', 'CircVar', 't_950_av', 't_850_av', 't_700_av', 't_500_av', 't_300_av', 'rh_950_av', 'rh_850_av', 'rh_700_av', 'rh_500_av', 'rh_300_av', 'wv_950_av', 'wv_850_av', 'wv_700_av', 'wv_500_av', 'wv_300_av', 'wdi_950_av', 'wdi_850_av', 'wdi_700_av', 'wdi_500_av', 'wdi_300_av', 'vwv_950_av', 'vwv_850_av', 'vwv_700_av', 'vwv_500_av', 'vwv_300_av', 'gp_950_av', 'gp_850_av', 'gp_700_av', 'gp_500_av', 'gp_300_av', 'gT_s_9_av', 'gT_9_8_av', 'gT_8_7_av', 'gT_7_5_av', 'gT_5_3_av', 'wSv_9_av', 'wSdir_9_av', 'wSv_7_av', 'wSdir_7_av', 'wSv_5_av', 'wSdir_5_av', 'wSv_1_av', 'wSdir_1_av', 'CBH_m_av', 'HigCC_p_av', 'LowCC_p_av', 'MidCC_p_av', 'TotCC_p_av', 'Cape_av', 'Cin_av', 'BLH_m_av', 'BLH_m_rt', 'LCL_hPa_av', 'LFC_hPa_av', 'CCL_hPa_av', 'EL_m_av', 'LiftIdx_av', 'VentIdx_av', 'CMLG_av', 'ros_p_lg1', 'f_start', 'geometry']\n",
      "Número de linhas: 1173\n"
     ]
    }
   ],
   "source": [
    "print(f\"Carregando shapefile: {SHP_FILE}...\")\n",
    "df = gpd.read_file(SHP_FILE)\n",
    "print(f\"Colunas: {list(df.columns)}\")\n",
    "print(f\"Número de linhas: {len(df)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d8c8a4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converter colunas numéricas\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == 'object' and col not in CATEGORICAL_VARIABLES:\n",
    "        converted = pd.to_numeric(df[col], errors='coerce')\n",
    "        if not converted.isna().all():\n",
    "            df[col] = converted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e4108137",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colunas numéricas: ['1_3y_fir_p', '3_8y_fir_p', '8_ny_fir_p', 'BLH_m_av', 'BLH_m_rt', 'CBH_m_av', 'CCL_hPa_av', 'CMLG_av', 'Cape_av', 'Cin_av', 'CircVar', 'DC_12h_av', 'EL_m_av', 'FFMC_12h_a', 'FWI_12h_av', 'HDW_av', 'HigCC_p_av', 'LCL_hPa_av', 'LFC_hPa_av', 'LiftIdx_av', 'LowCC_p_av', 'MidCC_p_av', 'Recirc', 'TotCC_p_av', 'VPD_Pa_av', 'VentIdx_av', 'area', 'aspect_av', 'd_2m_C_av', 'dfmc_av', 'duration_i', 'duration_p', 'elev_av', 'enddoy', 'f_load_av', 'f_start', 'fid', 'gT_5_3_av', 'gT_7_5_av', 'gT_8_7_av', 'gT_9_8_av', 'gT_s_9_av', 'gp_300_av', 'gp_500_av', 'gp_700_av', 'gp_850_av', 'gp_950_av', 'gp_m2s2_av', 'growth_rat', 'id', 'inidoy', 'int_i', 'int_p', 'qc', 'rh_2m_av', 'rh_300_av', 'rh_500_av', 'rh_700_av', 'rh_850_av', 'rh_950_av', 'ros_i', 'ros_p', 'ros_p_lg1', 'sP_hPa_av', 'sW_100_av', 'sW_1m_av', 'sW_289_av', 'sW_28_av', 'sW_3m_av', 'sW_7_av', 'spdir_i', 'spdir_p', 't_2m_C_av', 't_300_av', 't_500_av', 't_700_av', 't_850_av', 't_950_av', 'vwv_300_av', 'vwv_500_av', 'vwv_700_av', 'vwv_850_av', 'vwv_950_av', 'wSdir_1_av', 'wSdir_5_av', 'wSdir_7_av', 'wSdir_9_av', 'wSv_1_av', 'wSv_5_av', 'wSv_7_av', 'wSv_9_av', 'wdi_300_av', 'wdi_500_av', 'wdi_700_av', 'wdi_850_av', 'wdi_950_av', 'wdir100_av', 'wdir10_av', 'wv100_k_av', 'wv10_kh_av', 'wv_300_av', 'wv_500_av', 'wv_700_av', 'wv_850_av', 'wv_950_av']\n",
      "Colunas categóricas: ['Haines_av', 'burn_perio', 'land_use', 'zp_link', 'year', 'fuel_model', 'landform']\n"
     ]
    }
   ],
   "source": [
    "categorical_cols = [col for col in CATEGORICAL_VARIABLES if col in df.columns]\n",
    "numeric_cols = df.select_dtypes(include=['number']).columns.difference(['sdate'] + categorical_cols).tolist()\n",
    "\n",
    "print(f\"Colunas numéricas: {numeric_cols}\")\n",
    "print(f\"Colunas categóricas: {categorical_cols}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "63c4c161",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_stats = pd.DataFrame(index=numeric_cols)\n",
    "\n",
    "# Conversão para numérico\n",
    "df_numeric = df[numeric_cols].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Estatísticas básicas\n",
    "numeric_stats['n'] = df_numeric.count()\n",
    "numeric_stats['n_total'] = len(df)\n",
    "numeric_stats['n_missing'] = df_numeric.isna().sum()\n",
    "numeric_stats['pct_missing'] = (numeric_stats['n_missing'] / len(df)) * 100\n",
    "numeric_stats['pct_complete'] = (numeric_stats['n'] / len(df)) * 100\n",
    "numeric_stats['mean'] = df_numeric.mean()\n",
    "numeric_stats['median'] = df_numeric.median()\n",
    "numeric_stats['std'] = df_numeric.std()\n",
    "numeric_stats['var'] = df_numeric.var()\n",
    "numeric_stats['sem'] = df_numeric.sem()\n",
    "numeric_stats['cv'] = (numeric_stats['std'] / numeric_stats['mean']) * 100\n",
    "numeric_stats['min'] = df_numeric.min()\n",
    "numeric_stats['max'] = df_numeric.max()\n",
    "numeric_stats['range'] = numeric_stats['max'] - numeric_stats['min']\n",
    "numeric_stats['q25'] = df_numeric.quantile(0.25)\n",
    "numeric_stats['q75'] = df_numeric.quantile(0.75)\n",
    "numeric_stats['AIQ'] = numeric_stats['q75'] - numeric_stats['q25']\n",
    "numeric_stats['skewness'] = df_numeric.skew()\n",
    "numeric_stats['kurtosis'] = df_numeric.kurtosis()\n",
    "numeric_stats['n_zeros'] = (df_numeric == 0).sum()\n",
    "numeric_stats['pct_zeros'] = (numeric_stats['n_zeros'] / len(df)) * 100\n",
    "numeric_stats['n_negative'] = (df_numeric < 0).sum()\n",
    "numeric_stats['pct_negative'] = (numeric_stats['n_negative'] / len(df)) * 100\n",
    "numeric_stats['n_positive'] = (df_numeric > 0).sum()\n",
    "numeric_stats['pct_positive'] = (numeric_stats['n_positive'] / len(df)) * 100\n",
    "\n",
    "# Testes de normalidade\n",
    "for col in numeric_cols:\n",
    "    col_series = df_numeric[col].dropna()\n",
    "    if len(col_series) >= 8:\n",
    "        try:\n",
    "            stat, p = stats.normaltest(col_series)\n",
    "            numeric_stats.loc[col, 'normality_stat'] = stat\n",
    "            numeric_stats.loc[col, 'normality_p'] = p\n",
    "            if len(col_series) <= 5000:\n",
    "                shapiro_stat, shapiro_p = stats.shapiro(col_series)\n",
    "                numeric_stats.loc[col, 'shapiro_stat'] = shapiro_stat\n",
    "                numeric_stats.loc[col, 'shapiro_p'] = shapiro_p\n",
    "            else:\n",
    "                numeric_stats.loc[col, 'shapiro_stat'] = np.nan\n",
    "                numeric_stats.loc[col, 'shapiro_p'] = np.nan\n",
    "        except:\n",
    "            numeric_stats.loc[col, 'normality_stat'] = np.nan\n",
    "            numeric_stats.loc[col, 'normality_p'] = np.nan\n",
    "            numeric_stats.loc[col, 'shapiro_stat'] = np.nan\n",
    "            numeric_stats.loc[col, 'shapiro_p'] = np.nan\n",
    "    else:\n",
    "        numeric_stats.loc[col, 'normality_stat'] = np.nan\n",
    "        numeric_stats.loc[col, 'normality_p'] = np.nan\n",
    "        numeric_stats.loc[col, 'shapiro_stat'] = np.nan\n",
    "        numeric_stats.loc[col, 'shapiro_p'] = np.nan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "237a52b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_stats = pd.DataFrame(index=categorical_cols)\n",
    "categorical_stats['n_total'] = len(df)\n",
    "categorical_stats['n'] = df[categorical_cols].notna().sum()\n",
    "categorical_stats['n_missing'] = df[categorical_cols].isna().sum()\n",
    "categorical_stats['pct_missing'] = (categorical_stats['n_missing'] / len(df)) * 100\n",
    "categorical_stats['pct_complete'] = (categorical_stats['n'] / len(df)) * 100\n",
    "\n",
    "for col in categorical_cols:\n",
    "    value_counts = df[col].value_counts()\n",
    "    categorical_stats.loc[col, 'n_unique'] = df[col].nunique()\n",
    "    categorical_stats.loc[col, 'pct_unique'] = (categorical_stats.loc[col, 'n_unique'] / categorical_stats.loc[col, 'n']) * 100\n",
    "    mode_val = df[col].mode()\n",
    "    if len(mode_val) > 0:\n",
    "        categorical_stats.loc[col, 'mode'] = mode_val[0]\n",
    "        categorical_stats.loc[col, 'mode_freq'] = value_counts.iloc[0]\n",
    "        categorical_stats.loc[col, 'mode_pct'] = (value_counts.iloc[0] / categorical_stats.loc[col, 'n']) * 100\n",
    "        if len(value_counts) > 1:\n",
    "            categorical_stats.loc[col, 'mode2'] = value_counts.index[1]\n",
    "            categorical_stats.loc[col, 'mode2_freq'] = value_counts.iloc[1]\n",
    "            categorical_stats.loc[col, 'mode2_pct'] = (value_counts.iloc[1] / categorical_stats.loc[col, 'n']) * 100\n",
    "        else:\n",
    "            categorical_stats.loc[col, 'mode2'] = np.nan\n",
    "            categorical_stats.loc[col, 'mode2_freq'] = np.nan\n",
    "            categorical_stats.loc[col, 'mode2_pct'] = np.nan\n",
    "    else:\n",
    "        categorical_stats.loc[col, ['mode', 'mode_freq', 'mode_pct', 'mode2', 'mode2_freq', 'mode2_pct']] = np.nan\n",
    "\n",
    "    # Entropia\n",
    "    probs = df[col].value_counts(normalize=True)\n",
    "    entropy = -np.sum(probs * np.log2(probs))\n",
    "    categorical_stats.loc[col, 'entropy'] = entropy\n",
    "    categorical_stats.loc[col, 'max_entropy'] = np.log2(df[col].nunique()) if df[col].nunique() > 0 else 0\n",
    "    categorical_stats.loc[col, 'rel_entropy'] = entropy / categorical_stats.loc[col, 'max_entropy'] if categorical_stats.loc[col, 'max_entropy'] > 0 else 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c1ac70dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sign_log(series):\n",
    "    s = pd.to_numeric(series, errors='coerce')\n",
    "    return np.sign(s) * np.log1p(np.abs(s))\n",
    "\n",
    "all_cols = numeric_cols + categorical_cols\n",
    "ros_corrs = pd.DataFrame(index=all_cols)\n",
    "\n",
    "if 'ros_p' in df.columns:\n",
    "    ros_series = pd.to_numeric(df['ros_p'], errors='coerce')\n",
    "    ros_log_series = sign_log(df['ros_p'])\n",
    "\n",
    "    # Numéricas\n",
    "    for col in numeric_cols:\n",
    "        if col != 'ros_p':\n",
    "            col_series = pd.to_numeric(df[col], errors='coerce')\n",
    "            valid_idx = ros_series.notna() & col_series.notna()\n",
    "            if valid_idx.sum() > 1:\n",
    "                corr = ros_series[valid_idx].corr(col_series[valid_idx])\n",
    "                ros_corrs.loc[col, 'corr_ros_p'] = corr\n",
    "                ros_corrs.loc[col, 'R2_ros_p'] = corr**2\n",
    "            valid_log_idx = ros_log_series.notna() & col_series.notna()\n",
    "            if valid_log_idx.sum() > 1:\n",
    "                corr_log = ros_log_series[valid_log_idx].corr(col_series[valid_log_idx])\n",
    "                ros_corrs.loc[col, 'corr_log_ros_p'] = corr_log\n",
    "                ros_corrs.loc[col, 'R2_log_ros_p'] = corr_log**2\n",
    "\n",
    "    # Categóricas (eta²)\n",
    "    for col in categorical_cols:\n",
    "        valid_idx = ros_series.notna() & df[col].notna()\n",
    "        if valid_idx.sum() > 1 and df.loc[valid_idx, col].nunique() >= 2:\n",
    "            groups = df.loc[valid_idx, col]\n",
    "            values = ros_series[valid_idx]\n",
    "            group_means = values.groupby(groups).mean()\n",
    "            overall_mean = values.mean()\n",
    "            ss_between = sum(values.groupby(groups).size() * (group_means - overall_mean) ** 2)\n",
    "            ss_total = sum((values - overall_mean) ** 2)\n",
    "            if ss_total > 0:\n",
    "                eta_sq = ss_between / ss_total\n",
    "                ros_corrs.loc[col, 'R2_ros_p'] = eta_sq\n",
    "                ros_corrs.loc[col, 'corr_ros_p'] = np.sqrt(eta_sq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5eee454a",
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_stats = numeric_stats.combine_first(categorical_stats)\n",
    "desc_stats = desc_stats.combine_first(ros_corrs)\n",
    "\n",
    "# VIF\n",
    "for col in desc_stats.index:\n",
    "    r2 = desc_stats.loc[col].get('R2_ros_p', np.nan)\n",
    "    if pd.notna(r2) and r2 < 1:\n",
    "        desc_stats.loc[col, 'VIF'] = 1 / (1 - r2)\n",
    "    else:\n",
    "        desc_stats.loc[col, 'VIF'] = np.nan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "222bbac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estatísticas salvas em: ..\\..\\Data\\Data_Exploration\\Descriptive_stats_PT-FireProg_v2.1_L2_short.csv\n"
     ]
    }
   ],
   "source": [
    "# Adiciona coluna de tipo de variável\n",
    "desc_stats['var_type'] = 'numeric'\n",
    "desc_stats.loc[categorical_cols, 'var_type'] = 'categorical'\n",
    "\n",
    "# Cria diretório de saída se não existir\n",
    "Path(OUTPUT_DIR).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Gera nome de arquivo baseado no nome do shapefile\n",
    "shp_name = Path(SHP_FILE).stem\n",
    "output_file = Path(OUTPUT_DIR) / f'Descriptive_stats_{shp_name}.csv'\n",
    "\n",
    "# Salva CSV\n",
    "desc_stats.to_csv(output_file)\n",
    "print(f\"Estatísticas salvas em: {output_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
